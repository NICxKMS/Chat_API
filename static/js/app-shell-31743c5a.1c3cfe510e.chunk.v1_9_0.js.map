{"version":3,"file":"static/js/app-shell-31743c5a.1c3cfe510e.chunk.v1_9_0.js","mappings":"0LAGA,MAAMA,GAAeC,EAAAA,EAAAA,MAGRC,EAAWA,KACtB,MAAMC,GAAUC,EAAAA,EAAAA,IAAWJ,GAC3B,QAAgBK,IAAZF,EACF,MAAM,IAAIG,MAAM,gDAElB,OAAOH,CAAO,EAIHI,EAAgBC,IAAmB,IAAlB,SAAEC,GAAUD,EAExC,MAAOE,EAAOC,IAAYC,EAAAA,EAAAA,KAAS,IACdC,aAAaC,QAAQ,UACnB,SAIjBC,GAAcC,EAAAA,EAAAA,KAAY,KAC9BL,GAASM,IACP,MAAMC,EAAyB,SAAdD,EAAuB,QAAU,OAElD,OADAJ,aAAaM,QAAQ,QAASD,GACvBA,CAAQ,GACf,GACD,KAGHE,EAAAA,EAAAA,KAAU,KACRC,SAASC,KAAKC,UAAUC,OAAO,aAAc,aAC7CH,SAASC,KAAKC,UAAUE,IAAI,GAAGf,SAAa,GAC3C,CAACA,IAGJ,MAAMgB,GAAQC,EAAAA,EAAAA,KAAQ,MACpBjB,QACAK,cACAa,OAAkB,SAAVlB,KACN,CAACA,EAAOK,IAEZ,OACEc,EAAAA,EAAAA,GAAC7B,EAAa8B,SAAQ,CAACJ,MAAOA,EAAMjB,SACjCA,GACqB,C,gFC3C5B,MAAMsB,GAA4B9B,EAAAA,EAAAA,MAGrB+B,EAAwBA,KACnC,MAAM7B,GAAUC,EAAAA,EAAAA,IAAW2B,GAC3B,QAAgB1B,IAAZF,EACF,MAAM,IAAIG,MAAM,0EAElB,OAAOH,CAAO,EAIH8B,EAA6BzB,IAAmB,IAAlB,SAAEC,GAAUD,EACrD,MAAM,eAAE0B,IAAmBC,EAAAA,EAAAA,MACpBC,EAAuBC,IAA4BzB,EAAAA,EAAAA,IAAS,CACjE0B,UAAW,KACXC,QAAS,KACTC,YAAa,KACbC,WAAY,KACZC,gBAAiB,KACjBC,YAAY,EACZC,iBAAkB,KAClBC,aAAc,KACdC,iBAAkB,KAClBC,YAAa,KACbC,aAAc,OAGVC,GAA0BjC,EAAAA,EAAAA,KAAY,KAC1CqB,EAAyB,CACvBC,UAAW,KACXC,QAAS,KACTC,YAAa,KACbC,WAAY,KACZC,gBAAiB,KACjBC,YAAY,EACZC,iBAAkB,KAClBC,aAAc,KACdC,iBAAkB,KAClBC,YAAa,KACbC,aAAc,MACd,GACD,IAEGE,GAAwBlC,EAAAA,EAAAA,KAAY,KACxCqB,GAAyBc,IAAI,IACxBA,EACHb,UAAWc,KAAKC,MAChBV,YAAY,KACX,GACF,IAGGW,GAA2BtC,EAAAA,EAAAA,KAAY,SAACuC,GAA8E,IAA/DZ,EAAUa,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,IAAAA,UAAA,GAAUE,EAASF,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,KAAMR,EAAYQ,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,KAChHnB,GAAyBc,IACvB,MAAMZ,EAAUa,KAAKC,MACfb,EAAcW,EAAKb,UAAYC,EAAUY,EAAKb,UAAY,EAC1DI,EAAkBa,GAAiBf,EACvCmB,KAAKC,MAAOL,GAAiBf,EAAc,KAAS,IAAM,GAC1DW,EAAKT,gBACDE,EAAmBO,EAAKP,mBAC3BW,EAAgB,EAAIf,EAAc,MAgBrC,MAdmB,CACjBF,UAAWa,EAAKb,UAChBC,UACAC,cACAC,WAAYc,EACZb,kBACAC,aACAC,mBACAC,cAAca,aAAS,EAATA,EAAWb,eAAgBM,EAAKN,aAC9CC,kBAAkBY,aAAS,EAATA,EAAWZ,mBAAoBK,EAAKL,iBACtDC,aAAaW,aAAS,EAATA,EAAWX,cAAeI,EAAKJ,YAC5CC,aAAcA,GAAgBG,EAAKH,aAGpB,GAErB,GAAG,KAGH5B,EAAAA,EAAAA,KAAU,KAC6B,MAAjCgB,EAAsBG,SACxBL,GAAe2B,IACb,MAAMC,EAAa,IAAID,GACjBE,EAAUD,EAAWA,EAAWL,OAAS,GAI/C,OAHIM,GAA4B,cAAjBA,EAAQC,OACrBD,EAAQE,QAAU,IAAK7B,IAElB0B,CAAU,GAErB,GACC,CAAC1B,EAAuBF,IAG3B,MAAMgC,GAAgClD,EAAAA,EAAAA,KAAaiD,IACjD/B,GAAe2B,IACb,MAAMC,EAAa,IAAID,GACjBE,EAAUD,EAAWA,EAAWL,OAAS,GAQ/C,OAPIM,GAA4B,cAAjBA,EAAQC,OACrBD,EAAQE,QAAU,IACZF,EAAQE,SAAW,CAAC,KACrBA,EACHtB,YAAY,IAGTmB,CAAU,GACjB,GACD,CAAC5B,IAEER,GAAQC,EAAAA,EAAAA,KAAQ,MACpBS,wBACAa,0BACAC,wBACAI,2BACAY,mCACE,CAAC9B,EAAuBa,EAAyBC,EAAuBI,EAA0BY,IAEtG,OACErC,EAAAA,EAAAA,GAACE,EAA0BD,SAAQ,CAACJ,MAAOA,EAAMjB,SAC9CA,GACkC,C,gFC1HzC,MAAM0D,EAAmB,CACvBC,YAAa,GACbC,MAAO,EACPC,WAAY,KACZC,kBAAmB,EACnBC,iBAAkB,EAClBC,WAAW,EACXC,aAAc,45CAyBVC,GAAkB1E,EAAAA,EAAAA,MAGX2E,EAAcA,KACzB,MAAMzE,GAAUC,EAAAA,EAAAA,IAAWuE,GAC3B,QAAgBtE,IAAZF,EACF,MAAM,IAAIG,MAAM,sDAElB,OAAOH,CAAO,EAIH0E,EAAmBrE,IAAmB,IAAlB,SAAEC,GAAUD,EAE3C,MAAOsE,EAAUC,IAAeC,EAAAA,EAAAA,GAAgB,cAAeb,GAGzDc,GAAgBjE,EAAAA,EAAAA,KAAY,CAACkE,EAAKxD,KAElCwD,KAAOf,GACTY,GAAY5B,IAAI,IACXA,EACH,CAAC+B,GAAMxD,KAEX,GACC,CAACqD,IAGEI,GAAgBnE,EAAAA,EAAAA,KAAY,KAChC+D,EAAYZ,EAAiB,GAC5B,CAACY,IAGEK,GAA4BpE,EAAAA,EAAAA,KAAaqE,KACxCA,KAKgC,IAAnCA,EAAMC,0BACLD,EAAME,YAAcF,EAAME,WAAWC,SAAS,sBAC9CH,EAAMI,IAAMJ,EAAMI,GAAGC,cAAcC,WAAW,MAC9CN,EAAMO,QAAyC,aAA/BP,EAAMO,OAAOF,gBAE/B,IAGGG,GAA2B7E,EAAAA,EAAAA,KAAaqE,GACxCD,EAA0BC,GACrB,IACFP,EACHV,YAAa,GAGVU,GACN,CAACA,EAAUM,IAGR1D,GAAQC,EAAAA,EAAAA,KAAQ,MACpBmD,WACAG,gBACAE,gBACAC,4BACAS,8BACE,CACFf,EACAG,EACAE,EACAC,EACAS,IAGF,OACEhE,EAAAA,EAAAA,GAAC8C,EAAgB7C,SAAQ,CAACJ,MAAOA,EAAMjB,SACpCA,GACwB,C,sDCzG/B,MAAMqF,EAAoB,CACxBC,UAAW,YACXC,aAAc,eACdC,eAAgB,iBAChBC,4BAA6B,8BAC7BC,6BAA8B,+BAC9BC,iCAAkC,mCAClCC,YAAa,cACbC,uBAAwB,yBACxBC,gBAAiB,kBACjBC,UAAW,aAIPC,EAAuB,CAC3BC,WAAY,kBACZV,aAAc,oBACdC,eAAgB,sBAChBU,oBAAqB,sBACrBC,oBAAqB,sBACrBC,qBAAsB,uBACtBC,yBAA0B,4BA2HrB,MAAMC,EAAqB,IAxHlC,MACEC,WAAAA,GACEC,KAAKC,MAAQ,IAAIC,IACjBF,KAAKG,SAAW,IAAID,IAGE,oBAAXE,QAA0B,gBAAiBA,QAAU,wBAAyBA,QACvFJ,KAAKK,mBAET,CAKAA,iBAAAA,GACE,IAEwB,IAAIC,qBAAqBC,IAC7CA,EAAQC,aAAaC,SAAQC,IAC3B,MAAMC,EAA0B,gBAAfD,EAAME,KACnB/B,EAAkBO,YAClBP,EAAkBQ,uBAGtBwB,YAAYC,KAAKH,GACjBX,KAAKC,MAAMzF,IAAImG,GAGf,MAAMI,EAA6B,gBAAfL,EAAME,KACtB,sBACA,iCAEJ,IACEC,YAAYG,QAAQD,EAAalC,EAAkBC,UAAW6B,GAC9DX,KAAKG,SAAS3F,IAAIuG,EACpB,CAAE,MAAOE,GAGT,IACA,IAIUC,QAAQ,CAAEC,WAAY,CAAC,UACvC,CAAE,MAAOF,GAET,CACF,CAMAH,IAAAA,CAAKH,GACCE,aAAeA,YAAYC,OAC7BD,YAAYC,KAAKH,GACjBX,KAAKC,MAAMzF,IAAImG,GAEnB,CAQAK,OAAAA,CAAQD,EAAaK,EAAWC,GAC9B,GAAIR,aAAeA,YAAYG,QAC7B,IACEH,YAAYG,QAAQD,EAAaK,EAAWC,GAC5CrB,KAAKG,SAAS3F,IAAIuG,EACpB,CAAE,MAAOE,GAET,CAEJ,CAMAK,WAAAA,GACE,OAAIT,aAAeA,YAAYU,iBACtBV,YAAYU,iBAAiB,WAE/B,EACT,CAKAC,KAAAA,GACMX,cACFA,YAAYY,aACZZ,YAAYa,gBACZ1B,KAAKC,MAAMuB,QACXxB,KAAKG,SAASqB,QAElB,CAKAG,UAAAA,GACmB3B,KAAKsB,cAEbb,SAAQO,QAKGZ,MAKtB,E,uQCtIF,MAAMwB,GAAyB5I,EAAAA,EAAAA,MAElB6I,EAAqBA,KAChC,MAAM3I,GAAUC,EAAAA,EAAAA,IAAWyI,GAC3B,QAAgBxI,IAAZF,EACF,MAAM,IAAIG,MAAM,oEAElB,OAAOH,CAAO,EAGH4I,EAA0BvI,IAAmB,IAAlB,SAAEC,GAAUD,EAClD,MAAM,OAAEwI,IAAWC,EAAAA,EAAAA,MACb,cAAEC,IAAkBC,EAAAA,EAAAA,OACpB,yBAAEtD,IAA6BjB,EAAAA,EAAAA,MAC/B,QAAEwE,IAAYC,EAAAA,EAAAA,MACd,eAAEC,EAAc,eAAEpH,EAAc,oBAAEqH,EAAmB,sBAAEC,IAA0BrH,EAAAA,EAAAA,MACjF,wBAAEsH,EAAuB,SAAEC,IAAaC,EAAAA,EAAAA,MACxC,wBAAE1G,EAAuB,sBAAEC,EAAqB,yBAAEI,IAA6BtB,EAAAA,EAAAA,KAG/E4H,GAAmBC,EAAAA,EAAAA,IAAO,IAC1BC,GAAsBD,EAAAA,EAAAA,IAAO,MAC7BE,GAAqBF,EAAAA,EAAAA,IAAO,MAC5BG,GAAiBH,EAAAA,EAAAA,KAAO,GACxBI,GAAwBJ,EAAAA,EAAAA,KAAO,GAG/BK,GAAsBvI,EAAAA,EAAAA,KAC1B,IAAMwI,KAAUC,GAAYZ,EAAsBY,IAAU,KAC5D,CAACZ,IAIGa,GAAqBR,EAAAA,EAAAA,IAAO,MAC5BS,GAAkBT,EAAAA,EAAAA,IAAO,MACzBU,GAA0BvJ,EAAAA,EAAAA,KAAY,KACrCsJ,EAAgBE,UACdH,EAAmBG,UACtBH,EAAmBG,QAAU,IAAIC,IAAI,eAEvCH,EAAgBE,QAAU,IAAIE,OAAOL,EAAmBG,QAAS,CAAEG,KAAM,YAEpEL,EAAgBE,UACtB,IAEGI,GAAmB5J,EAAAA,EAAAA,KAAa6J,GAAU,IAAIC,SAAQ,CAACC,EAASC,KACpE,MAAMC,EAASV,IACfU,EAAOC,UAAaC,GAAMJ,EAAQI,EAAEC,MACpCH,EAAOI,QAAUL,EACjBC,EAAOK,YAAYT,EAAM,KACvB,CAACN,IAGCgB,GAAyBvK,EAAAA,EAAAA,KAAYwK,eAAOC,GAA+B,IAAtBC,EAASlI,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,KAErE,MAAMmI,EAA+B,oBAAXC,QAA0BA,OAAOC,WACvDD,OAAOC,aACPlI,KAAKmI,SAASC,SAAS,IAAIC,UAAU,GAAK5I,KAAKC,MAAM0I,SAAS,IAClEjC,EAAoBU,QAAUmB,EAC9B,MAAMM,EAA0B,OAAdP,GAAsBQ,OAAOC,UAAUT,IAAcA,GAAa,EACpF,IAAKD,IAAYvC,EAEf,OADAQ,EAAS,6CACF,KAET,MAAM0C,EAAU,GAAGlD,EAAcmD,YAAYnD,EAAczD,KAC3D,IAAK2G,EAEH,OADA1C,EAAS,2BACF,KAET,IAAI4C,EACAL,EACF/J,GAAeiB,IACb,MAAMoJ,EAAYpJ,EAAKqJ,MAAM,EAAGd,GAC1Be,EAAWtJ,EAAKuI,GAGtB,OADAY,EAAc,IAAKG,EAAUrC,QAASqB,GAC/B,IAAIc,EAAWD,EAAY,IAGpCA,EAAc/C,EAAoB,OAAQkC,GAE5CxI,IACAC,IACA+G,EAAsBO,SAAU,EAChCf,GAAwB,GACxBC,EAAS,MACTE,EAAiBY,QAAU,GAC3BR,EAAeQ,SAAU,EACzBjB,EAAoB,YAAa,IACjC,IAAImD,EAAYC,YAAW,KAAO,IAADC,EACL,QAA1BA,EAAA7C,EAAmBS,eAAO,IAAAoC,GAA1BA,EAA4BC,MAAM,WAClCnD,EAAS,wBACTD,GAAwB,EAAM,GAC7B,KACH,MAAMqD,EAAkB,IAAIC,gBAC5BhD,EAAmBS,QAAUsC,EAC7B,IACE,MAAME,EAAWnH,EAAyBqD,GACpC+D,EAAgB3D,EAAekB,QAAQ0C,KAAIC,IAAA,IAAC,QAAElJ,KAAYmJ,GAAGD,EAAA,OAAKC,CAAC,KACrEJ,EAAStI,cAAkBuI,EAAcxJ,QAAoC,WAA1BwJ,EAAc,GAAGjJ,MACtEiJ,EAAcI,QAAQ,CAAErJ,KAAM,SAAUoG,QAAS4C,EAAStI,aAAc4I,UAAWlK,KAAKC,MAAQ,IAElG4J,EAAcM,KAAKjB,GACnB,MAAMkB,EAAU,CACd7B,YACAtG,MAAO+G,EACPqB,SAAUR,EACV7I,YAAa4I,EAAS5I,YACtBE,WAAY0I,EAAS1I,WACrBD,MAAO2I,EAAS3I,MAChBE,kBAAmByI,EAASzI,kBAC5BC,iBAAkBwI,EAASxI,kBAEvBkJ,EAAU,CAAE,eAAgB,mBAAoB,OAAU,oBAAqB,gBAAiB,YAClGtE,IAASsE,EAAuB,cAAI,UAAUtE,KAClD,MAAMuE,QAAiBC,EAAAA,EAAAA,GAAe,IAAInD,IAAI,mBAAoBzB,GAAQ+C,WAAY,CACpF8B,OAAQ,OAAQH,UAASpM,KAAMwM,KAAKC,UAAUP,GAAUQ,OAAQlB,EAAgBkB,OAAQC,MAAO,aAEjG,IAAKN,EAASO,GAAI,MAAM,IAAI5N,MAAM,cAAcqN,EAASQ,UACzD,MAAMC,EAAST,EAASrM,KAAK+M,YACvBC,EAAU,IAAIC,YAAY,SAChC,IAAIC,EAAqB,GACzB,OAAa,CACX,MAAM,KAAEC,EAAI,MAAE/M,SAAgB0M,EAAOM,OAOrC,GANAC,aAAajC,GACbA,EAAYC,YAAW,KAAO,IAADiC,EACD,QAA1BA,EAAA7E,EAAmBS,eAAO,IAAAoE,GAA1BA,EAA4B/B,QAC5BnD,EAAS,wBACTD,GAAwB,EAAM,GAC7B,KACCgF,EAEF,MAEF,MAAM5D,EAAQyD,EAAQO,OAAOnN,EAAO,CAAEoN,QAAQ,IAI9C,IACE,MAAMC,QAAanE,EAAiBC,GACpC,IAAK,MAAMmE,KAAOD,EAAM,CAAC,IAADE,EAAAC,EAAAC,EAEtB,GAAgB,QAAZF,EAAAD,EAAII,gBAAQ,IAAAH,GAAZA,EAAc/G,OAA8B,UAArB8G,EAAIhM,aAA0B,CAAC,IAADqM,EAAAC,EACvD,MAAMC,GAAqB,QAAZF,EAAAL,EAAII,gBAAQ,IAAAC,GAAO,QAAPC,EAAZD,EAAcnH,aAAK,IAAAoH,OAAP,EAAZA,EAAqB7D,UAAW,mCAe/C,OAbA/B,EAAS6F,GACTrN,GAAeiB,IACb,MAAMW,EAAa,IAAIX,GACjBY,EAAUD,EAAWA,EAAWL,OAAS,GAQ/C,OAPIM,GAA4B,cAAjBA,EAAQC,OACrBD,EAAQqG,SAAW,kBAAkBmF,IACjCxL,EAAQE,UACVF,EAAQE,QAAQtB,YAAa,EAC7BoB,EAAQE,QAAQiE,OAAQ,IAGrBpE,CAAU,IAEZ,IACT,CAEIkL,EAAI5E,UAEDH,EAAsBO,UACzBlH,EAAyB,GACzB2G,EAAsBO,SAAU,GAElCgE,GAAsBQ,EAAI5E,QAC1BR,EAAiBY,QAAUgE,EAC3BtE,EAAoBsE,IAGtB,MAAM1L,EAA8C,QAA9BoM,EAAY,QAAZC,EAAGH,EAAIQ,aAAK,IAAAL,OAAA,EAATA,EAAWrM,wBAAgB,IAAAoM,EAAAA,EAAI,EACxD5L,EAAyBR,EAAkBkM,EAAIS,OAAQT,EAAIQ,MAAOR,EAAIhM,aACxE,CACF,CAAE,MAAO,CACX,CAGA,OAFAkH,EAAoBwF,QACpBlG,EAAsBI,EAAiBY,SAChCZ,EAAiBY,OAC1B,CAAE,MAAOtC,GAgBP,OAdAwB,EAASxB,EAAMuD,SAEfvJ,GAAeiB,IACb,MAAMW,EAAa,IAAIX,GACjBY,EAAUD,EAAWA,EAAWL,OAAS,GAQ/C,OAPIM,GAA4B,cAAjBA,EAAQC,OACrBD,EAAQqG,SAAW,kBAAkBlC,EAAMuD,SAAW,qCAClD1H,EAAQE,UACVF,EAAQE,QAAQtB,YAAa,EAC7BoB,EAAQE,QAAQiE,OAAQ,IAGrBpE,CAAU,IAEZ,IACT,CAAC,QACC6K,aAAajC,GACb1C,EAAeQ,SAAU,EACzBf,GAAwB,GAExBK,EAAoBU,QAAU,IAChC,CACF,GAAG,CACDxB,EAAQE,EAAerD,EAA0BuD,EACjDE,EAAgBpH,EAAgBqH,EAAqBC,EACrDU,EAAqBR,EAAUD,EAC/BxG,EAAyBC,EAAuBI,EAChDsH,IAGI+E,GAAgB3O,EAAAA,EAAAA,KAAYwK,UAC5BzB,EAAmBS,SAAST,EAAmBS,QAAQqC,MAAM,gBACjE,MAAM+C,EAAQ9F,EAAoBU,QAClC,GAAIoF,EAAO,CACT,MAAMlC,EAAU,CAAE,eAAgB,oBAC9BtE,IAASsE,EAAuB,cAAI,UAAUtE,KAClD,UACQwE,EAAAA,EAAAA,GAAe,IAAInD,IAAI,iBAAkBzB,GAAQ+C,WAAY,CACjE8B,OAAQ,OAAQH,UAASpM,KAAMwM,KAAKC,UAAU,CAAEpC,UAAWiE,KAE/D,CAAE,MAAO,CAAC,QACR9F,EAAoBU,QAAU,KAC9BT,EAAmBS,QAAU,IAC/B,CACF,CAGA,OAFAR,EAAeQ,SAAU,EACzBf,GAAwB,IACjB,CAAI,GACV,CAACT,EAAQI,EAASK,IAEf/H,GAAQC,EAAAA,EAAAA,KAAQ,MACpB4J,yBACAoE,gBACA/E,mBACAhB,mBACAiG,YAAaA,IAAM7F,EAAeQ,WAChC,CAACe,EAAwBoE,EAAe/E,IAE5C,OACE/I,EAAAA,EAAAA,GAACgH,EAAuB/G,SAAQ,CAACJ,MAAOA,EAAMjB,SAC3CA,GAC+B,C,6DCxP/B,MAAMqP,EAAiBA,KAE5B,MAAOC,EAAcC,IAAmBhL,EAAAA,EAAAA,GAAgB,qBAAqB,GAGvEiL,GAAkBjP,EAAAA,EAAAA,KAAY,KAClC,IACEH,aAAaqP,WAAW,qBAE1B,CAAE,MAAOhI,GAET,IACC,IAGGiI,GAAcnP,EAAAA,EAAAA,KAAaoP,IAC/B,MAAMC,EAA8B,kBAAZD,EAAwBA,GAAWL,EAQ3D,OALKM,GACHJ,IAGFD,EAAgBK,GACTA,CAAQ,GACd,CAACN,EAAcC,EAAiBC,IAG7BK,GAAgBtP,EAAAA,EAAAA,KAAY,KAChCiP,GAAiB,GAEhB,CAACA,IAuCJ,OApCA7O,EAAAA,EAAAA,KAAU,KAER,GAAsB,oBAAXiG,OAAwB,OAGnC,MAAMkJ,EAAelJ,OAAOmJ,aAyB5B,OAtBAnJ,OAAOmJ,aAAe,SAA6BvC,GAGjD,MAAgB,UADApN,aAAaC,QAAQ,uBAIT,mBAAjByP,EACFA,EAAatC,GAKpBA,GACAA,EAAMX,WACNlK,KAAKC,MAAQ4K,EAAMX,UAAY,KAC/BW,EAAMwC,WACNxC,EAAMyC,iBACNzC,EAAM0C,mBAEV,EAGO,KACLtJ,OAAOmJ,aAAeD,CAAY,CACnC,GACA,IAGI,CACLR,eACAI,cACAF,kBACAK,gBACD,C,kBClFI9E,eAAeoC,EAAegD,GAA+C,IAAxCC,EAAIrN,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,CAAC,EAAGsN,EAAOtN,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,EAAGuN,EAAOvN,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,IACxEwN,EAAU,EACd,OACE,IACE,MAAMrD,QAAiBsD,MAAML,EAAOC,GACpC,IAAKlD,EAASO,GACZ,MAAM,IAAI5N,MAAM,kBAAkBqN,EAASQ,UAE7C,OAAOR,CACT,CAAE,MAAOzF,GACP,GAAI8I,GAAWF,EACb,MAAM5I,EAGR,MAAMgJ,EAAQH,EAAUpN,KAAKwN,IAAI,EAAGH,GAA2B,IAAhBrN,KAAKmI,eAC9C,IAAIhB,SAAQsG,GAAOzE,WAAWyE,EAAKF,KACzCF,GACF,CAEJ,C,kECXO,MAAMhM,EAAkBA,CAACE,EAAKmM,KAEnC,MAAMC,GAAkBzH,EAAAA,EAAAA,IAAOwH,IAGxBE,EAAaC,IAAkB5Q,EAAAA,EAAAA,KAAS,KAC7C,IAEE,MAAM6Q,EAAOpK,OAAOxG,aAAaC,QAAQoE,GAEzC,OAAOuM,EAAO3D,KAAK4D,MAAMD,GAAQH,EAAgB9G,OACnD,CAAE,MAAOtC,GAEP,OAAOoJ,EAAgB9G,OACzB,KAKImH,GAAW3Q,EAAAA,EAAAA,KAAaU,IAC5B,IAEE,MAAMkQ,EACJlQ,aAAiBmQ,SAAWnQ,EAAM6P,GAAe7P,EAGnD8P,EAAeI,GAGfvK,OAAOxG,aAAaM,QAAQ+D,EAAK4I,KAAKC,UAAU6D,GAClD,CAAE,MAAO1J,GAET,IACC,CAAChD,EAAKqM,IAaT,OAVAnQ,EAAAA,EAAAA,KAAU,KACR,IACE,MAAMqQ,EAAOpK,OAAOxG,aAAaC,QAAQoE,GACzCsM,EAAeC,EAAO3D,KAAK4D,MAAMD,GAAQH,EAAgB9G,QAC3D,CAAE,MAAOtC,GAEPsJ,EAAeF,EAAgB9G,QACjC,IACC,CAACtF,IAEG,CAACqM,EAAaI,EAAS,C,kJC7ChC,MAGMG,GAAe7R,EAAAA,EAAAA,MACf8R,GAAqB9R,EAAAA,EAAAA,MAGdkJ,EAAWA,KACtB,MAAMhJ,GAAUC,EAAAA,EAAAA,IAAW0R,GAC3B,QAAgBzR,IAAZF,EACF,MAAM,IAAIG,MAAM,gDAElB,OAAOH,CAAO,EAIH6R,EAAiBA,KAC5B,MAAM7R,GAAUC,EAAAA,EAAAA,IAAW2R,GAC3B,QAAgB1R,IAAZF,EACF,MAAM,IAAIG,MAAM,sDAElB,OAAOH,CAAO,EAIH8R,EAAgBzR,IAAmB,IAAlB,SAAEC,GAAUD,EACxC,MAAM,aAAEuP,IAAiBD,EAAAA,EAAAA,MACnB,OAAE9G,IAAWC,EAAAA,EAAAA,MACb,QAAEG,IAAYC,EAAAA,EAAAA,MACd,UAAE6I,IAAcC,EAAAA,EAAAA,MAGf1B,EAAW2B,IAAgBxR,EAAAA,EAAAA,IAAS,KACpC8P,EAAiB2B,IAAsBzR,EAAAA,EAAAA,IAAS,CAAC,IACjD+P,EAAoB2B,IAAyB1R,EAAAA,EAAAA,IAAS,KACtDsI,EAAeqJ,IAAoBvN,EAAAA,EAAAA,GAAgB,gBAAiB,OACpEwN,EAAWC,IAAgB7R,EAAAA,EAAAA,KAAS,IACpCsH,EAAOwB,IAAY9I,EAAAA,EAAAA,IAAS,OAG5B8R,EAAkBC,IAAuB3N,EAAAA,EAAAA,GAAgB,oBAAoB,IAC7E4N,EAAaC,IAAkBjS,EAAAA,EAAAA,IAAS,CAC7CkS,OAAQ,GACRC,WAAY,CACV,MAAQ,EACR,OAAS,EACT,WAAa,MAKV,CAAEC,EAAoBC,IAAqBC,EAAAA,EAAAA,IAAW,WAC7D9R,EAAAA,EAAAA,KAAU,KACJoR,EAAWQ,IACVC,GAAmB,GACvB,CAACT,EAAWQ,EAAoBC,IAGnC,MAAMzC,GAAexP,EAAAA,EAAAA,KAAaiN,GAE9BA,GACAA,EAAMX,WACNlK,KAAKC,MAAQ4K,EAAMX,UA9DC,OA+DpBW,EAAMwC,WACNxC,EAAMyC,iBACNzC,EAAM0C,oBAEP,KAGHvP,EAAAA,EAAAA,KAAU,KAER,GAAsB,oBAAXiG,OAGX,OAFAA,OAAOmJ,aAAeA,EAEf,YACEnJ,OAAOmJ,YAAY,CAC3B,GACA,CAACA,IAGJ,MAAM2C,GAAcnS,EAAAA,EAAAA,KAAaoK,IAC/B,IACE,MAAM6C,EAAQ,CACZwC,UAAWrF,EAAKqF,UAChBC,gBAAiBtF,EAAKsF,gBACtBC,mBAAoBvF,EAAKuF,mBACzBrD,UAAWlK,KAAKC,OAGlBxC,aAAaM,QAAQ,qBAAsB2M,KAAKC,UAAUE,GAC5D,CAAE,MAAO/F,GAET,IACC,IAGGkL,GAAuBpS,EAAAA,EAAAA,KAAY,CAACqS,EAAUC,KAClDT,GAAe1P,IAAI,IACdA,EACH4P,WAAY,IACP5P,EAAK4P,WACR,CAACM,GAAWC,MAEb,GACF,IAGGC,GAAqBvS,EAAAA,EAAAA,KAAawS,IACtCX,GAAe1P,IAAI,IACdA,EACH2P,OAAQU,KACP,GACF,IAGGC,GAAczS,EAAAA,EAAAA,KAAaqE,KAE3B6D,aAAa,EAAbA,EAAezD,OAAOJ,aAAK,EAALA,EAAOI,KAC/B8M,EAAiBlN,EACnB,GACC,CAAC6D,EAAeqJ,IAGbmB,GAAc1S,EAAAA,EAAAA,KAAYwK,iBAAuD,IAAhDmI,EAAYnQ,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,IAAAA,UAAA,GAAUoQ,EAAapQ,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,KAC3EiP,GAAa,GACb/I,EAAS,MAGT,IACE,MAAMgE,EAAU,CAAE,OAAU,oBAC5B,GAAIiG,EAAc,CAEhB,MAAME,EAAaD,GAAiBxK,EAChCyK,IACFnG,EAAuB,cAAI,UAAUmG,IAEzC,CACA,MAAMC,EAAY,IAAIrJ,IAAI,yBAA0BzB,GAAQ+C,WACtD4B,QAAiBsD,MAAM6C,EAAW,CAAEpG,YAG1C,IAAKC,EAASO,GAAI,CAChB,IAAI6F,EAAW,0BAA0BpG,EAASQ,SAElD,MAAM,IAAI7N,MAAMyT,EAClB,CAEA,MAAMC,QAAgBrG,EAASsG,OAIzBhJ,EAAS,IAAIP,OAAO,IAAID,IAAI,8CAAkD,CAAEE,UAAM,IAC5FM,EAAOK,YAAY0I,GACnB/I,EAAOC,UAAYiC,IAAoB,IAAjB/B,KAAM4D,GAAK7B,EAC/B,GAAI6B,EAAI9G,MAENwB,EAASsF,EAAI9G,OACbgK,EAAU,CAAEvH,KAAM,QAASc,QAASuD,EAAI9G,YACnC,CACL,MACEuI,UAAWyD,EACXxD,gBAAiByD,EACjBxD,mBAAoByD,GAClBpF,EACJ,GAAIe,EAAc,CAChB,MAAMsE,EAAUxT,aAAaC,QAAQ,sBACrC,IAAIwT,EACJ,IAAMA,EAAYxG,KAAK4D,MAAM2C,EAAU,CAAE,MAAQC,EAAY,IAAM,GAClDA,GACfxG,KAAKC,UAAUuG,EAAU7D,aAAe3C,KAAKC,UAAUmG,IACvDpG,KAAKC,UAAUuG,EAAU5D,mBAAqB5C,KAAKC,UAAUoG,IAC7DrG,KAAKC,UAAUuG,EAAU3D,sBAAwB7C,KAAKC,UAAUqG,MAEhEhC,EAAa8B,GACb7B,EAAmB8B,GACnB7B,EAAsB8B,GACtBjB,EAAY,CAAE1C,UAAWyD,EAAkBxD,gBAAiByD,EAAwBxD,mBAAoByD,IAE5G,MACEhC,EAAa8B,GACb7B,EAAmB8B,GACnB7B,EAAsB8B,EAG1B,CACA3B,GAAa,GACbxH,EAAOsJ,WAAW,EAEpBtJ,EAAOI,QAAWmJ,IAEhB9K,EAAS8K,EAAI/I,SACbyG,EAAU,CAAEvH,KAAM,QAASc,QAAS+I,EAAI/I,UACxCgH,GAAa,GACbxH,EAAOsJ,WAAW,CAEtB,CAAE,MAAOC,GAEP9K,EAAS8K,EAAI/I,SAAW,6BACxByG,EAAU,CAAEvH,KAAM,QAASc,QAAS+I,EAAI/I,SAAW,6BAErD,CACF,GAAG,CAACzC,EAAQmK,EAAa/J,EAAS2G,EAAcmC,IAG1CuC,GAAsB5K,EAAAA,EAAAA,KAAO,GAE7B6K,GAAkB7K,EAAAA,EAAAA,KAAO,IAE/BzI,EAAAA,EAAAA,KAAU,KACR,IAAKqT,EAAoBjK,QAAS,CAChC,GAAIuF,EAAc,CAChB,MAAM4E,EAAW9T,aAAaC,QAAQ,sBACtC,IAAI8T,EACJ,IAAMA,EAAc9G,KAAK4D,MAAMiD,EAAW,CAAE,MAAQC,EAAc,IAAM,CACpEA,GAAevN,OAAOmJ,aAAaoE,KACrCxC,EAAawC,EAAYnE,WACzB4B,EAAmBuC,EAAYlE,iBAC/B4B,EAAsBsC,EAAYjE,oBAClC8B,GAAa,GAEjB,CACA,IAAIoC,EAAc,KAClB,IAAMA,EAAchU,aAAaC,QAAQ,UAAY,CAAE,MAAO,CAC1D+T,GAEFH,EAAgBlK,SAAU,EAC1BkJ,GAAY,EAAMmB,IAGlBnB,GAAY,GAEde,EAAoBjK,SAAU,CAChC,IAEC,KAGHpJ,EAAAA,EAAAA,KAAU,KAEJqT,EAAoBjK,SAAWpB,IAAYsL,EAAgBlK,UAC7DkK,EAAgBlK,SAAU,EAC1BkJ,GAAY,GACd,GACC,CAACtK,EAASsK,KAGbtS,EAAAA,EAAAA,KAAU,MAEH8H,GAAiBuH,EAAUhN,OAAS,GACvC8O,EAAiB9B,EAAU,GAC7B,GACC,CAACA,EAAWvH,EAAeqJ,IAG9B,MAAMuC,GAA2B9T,EAAAA,EAAAA,KAAY,KAC3C2R,GAAoBxP,IAASA,GAAK,GACjC,CAACwP,IAGEoC,GAAapT,EAAAA,EAAAA,KAAQ,MACzB8O,YACAC,kBACAC,qBACAzH,gBACAsJ,YACAtK,QACAwK,mBACAsC,4BAA6BtC,EAC7BoC,2BACAnC,sBACAc,cACAnD,cAAeoD,KACb,CACFjD,EACAC,EACAC,EACAzH,EACAsJ,EACAtK,EACAwK,EACAoC,EACAnC,EACAc,EACAC,IAIIuB,GAActT,EAAAA,EAAAA,KAAQ,MAC1BiR,cACAQ,uBACAG,wBACE,CACFX,EACAQ,EACAG,IAGF,OACE1R,EAAAA,EAAAA,GAACiQ,EAAahQ,SAAQ,CAACJ,MAAOqT,EAAWtU,UACvCoB,EAAAA,EAAAA,GAACkQ,EAAmBjQ,SAAQ,CAACJ,MAAOuT,EAAYxU,SAC7CA,KAEmB,C","sources":["contexts/ThemeContext.js","contexts/PerformanceMetricsContext.js","contexts/SettingsContext.js","utils/performance.js","contexts/StreamingEventsContext.js","hooks/useCacheToggle.js","utils/network.js","hooks/useLocalStorage.js","contexts/ModelContext.js"],"sourcesContent":["import { createContext, useContext, useState, useEffect, useCallback, useMemo } from 'react';\n\n// Create theme context\nconst ThemeContext = createContext();\n\n// Custom hook for using theme\nexport const useTheme = () => {\n  const context = useContext(ThemeContext);\n  if (context === undefined) {\n    throw new Error('useTheme must be used within a ThemeProvider');\n  }\n  return context;\n};\n\n// Theme provider component\nexport const ThemeProvider = ({ children }) => {\n  // Initialize theme from localStorage or default to 'dark'\n  const [theme, setTheme] = useState(() => {\n    const savedTheme = localStorage.getItem('theme');\n    return savedTheme || 'dark';\n  });\n\n  // Toggle between light and dark themes\n  const toggleTheme = useCallback(() => {\n    setTheme(prevTheme => {\n      const newTheme = prevTheme === 'dark' ? 'light' : 'dark';\n      localStorage.setItem('theme', newTheme);\n      return newTheme;\n    });\n  }, []);\n\n  // Apply theme class to body element\n  useEffect(() => {\n    document.body.classList.remove('light-mode', 'dark-mode');\n    document.body.classList.add(`${theme}-mode`);\n  }, [theme]);\n\n  // Context value - memoized to prevent unnecessary re-renders\n  const value = useMemo(() => ({\n    theme,\n    toggleTheme,\n    isDark: theme === 'dark'\n  }), [theme, toggleTheme]);\n\n  return (\n    <ThemeContext.Provider value={value}>\n      {children}\n    </ThemeContext.Provider>\n  );\n}; ","import React, { createContext, useContext, useState, useCallback, useMemo, useEffect } from 'react';\nimport { useChatHistory } from './ChatHistoryContext';\n\n// Create performance metrics context\nconst PerformanceMetricsContext = createContext();\n\n// Hook to use performance metrics context\nexport const usePerformanceMetrics = () => {\n  const context = useContext(PerformanceMetricsContext);\n  if (context === undefined) {\n    throw new Error('usePerformanceMetrics must be used within a PerformanceMetricsProvider');\n  }\n  return context;\n};\n\n// Provider component for performance metrics\nexport const PerformanceMetricsProvider = ({ children }) => {\n  const { setChatHistory } = useChatHistory();\n  const [currentMessageMetrics, setCurrentMessageMetrics] = useState({\n    startTime: null,\n    endTime: null,\n    elapsedTime: null,\n    tokenCount: null,\n    tokensPerSecond: null,\n    isComplete: false,\n    timeToFirstToken: null,\n    promptTokens: null,\n    completionTokens: null,\n    totalTokens: null,\n    finishReason: null\n  });\n\n  const resetPerformanceMetrics = useCallback(() => {\n    setCurrentMessageMetrics({\n      startTime: null,\n      endTime: null,\n      elapsedTime: null,\n      tokenCount: null,\n      tokensPerSecond: null,\n      isComplete: false,\n      timeToFirstToken: null,\n      promptTokens: null,\n      completionTokens: null,\n      totalTokens: null,\n      finishReason: null\n    });\n  }, []);\n\n  const startPerformanceTimer = useCallback(() => {\n    setCurrentMessageMetrics(prev => ({\n      ...prev,\n      startTime: Date.now(),\n      isComplete: false\n    }));\n  }, []);\n\n  // eslint-disable-next-line react-hooks/exhaustive-deps\n  const updatePerformanceMetrics = useCallback((newTokenCount, isComplete = false, tokenInfo = null, finishReason = null) => {\n    setCurrentMessageMetrics(prev => {\n      const endTime = Date.now();\n      const elapsedTime = prev.startTime ? endTime - prev.startTime : 0;\n      const tokensPerSecond = newTokenCount && elapsedTime ?\n        Math.round((newTokenCount / (elapsedTime / 1000)) * 10) / 10 :\n        prev.tokensPerSecond;\n      const timeToFirstToken = prev.timeToFirstToken ||\n        (newTokenCount > 0 ? elapsedTime : null);\n\n      const newMetrics = {\n        startTime: prev.startTime,\n        endTime,\n        elapsedTime,\n        tokenCount: newTokenCount,\n        tokensPerSecond,\n        isComplete,\n        timeToFirstToken,\n        promptTokens: tokenInfo?.promptTokens || prev.promptTokens,\n        completionTokens: tokenInfo?.completionTokens || prev.completionTokens,\n        totalTokens: tokenInfo?.totalTokens || prev.totalTokens,\n        finishReason: finishReason || prev.finishReason\n      };\n\n      return newMetrics;\n    });\n  }, []);\n\n  // Sync performance metrics into chat history after a metrics update\n  useEffect(() => {\n    if (currentMessageMetrics.endTime != null) {\n      setChatHistory(prevHistory => {\n        const newHistory = [...prevHistory];\n        const lastMsg = newHistory[newHistory.length - 1];\n        if (lastMsg && lastMsg.role === 'assistant') {\n          lastMsg.metrics = { ...currentMessageMetrics };\n        }\n        return newHistory;\n      });\n    }\n  }, [currentMessageMetrics, setChatHistory]);\n\n  // Direct function to set token metrics for the last message - for debugging/testing\n  const setTokenMetricsForLastMessage = useCallback((metrics) => {\n    setChatHistory(prevHistory => {\n      const newHistory = [...prevHistory];\n      const lastMsg = newHistory[newHistory.length - 1];\n      if (lastMsg && lastMsg.role === 'assistant') {\n        lastMsg.metrics = {\n          ...(lastMsg.metrics || {}),\n          ...metrics,\n          isComplete: true\n        };\n      }\n      return newHistory;\n    });\n  }, [setChatHistory]);\n\n  const value = useMemo(() => ({\n    currentMessageMetrics,\n    resetPerformanceMetrics,\n    startPerformanceTimer,\n    updatePerformanceMetrics,\n    setTokenMetricsForLastMessage\n  }), [currentMessageMetrics, resetPerformanceMetrics, startPerformanceTimer, updatePerformanceMetrics, setTokenMetricsForLastMessage]);\n\n  return (\n    <PerformanceMetricsContext.Provider value={value}>\n      {children}\n    </PerformanceMetricsContext.Provider>\n  );\n}; ","import { createContext, useContext, useCallback, useMemo } from 'react';\nimport { useLocalStorage } from '../hooks/useLocalStorage';\n\n// Default settings values\nconst DEFAULT_SETTINGS = {\n  temperature: 0.7,\n  top_p: 1.0,\n  max_tokens: 8191,\n  frequency_penalty: 0,\n  presence_penalty: 0,\n  streaming: true,\n  systemPrompt: `You are a knowledgeable, friendly, and supportive university-level assistant.\n\nFor every question or topic, provide a clear, engaging, and well-structured answer, styled like an expert mentor or senior student.\n\nStyle and Structure:\n\nBegin with a welcoming, positive intro (e.g., \"Alright! I'll break this down for you in detail section by section, with clear explanations and important points.\").\nOrganize your response into numbered sections, each with a descriptive header and an emoji (e.g., # 📚 1. Core Concept).\nIn each section, explain:\nCore ideas and definitions\nHow things work (step-by-step, or process overview)\nAny relevant formulas, code, or examples\nKey points, tips, or comparisons\nUse subheadings, bullet points, tables, and diagrams (ASCII or LaTeX) for clarity when helpful.\nAt the end, summarize with a \"Key Takeaways\" or \"Next Steps/Related Topics\" section, with quick revision notes, further reading, or suggestions for deeper exploration if relevant.\nAlways offer to provide summary tables, code snippets, or quick revision notes if the user wants them.\nTone: Friendly, supportive, and approachable—like a helpful peer or mentor. Formatting: Use bold, italics, emojis, markdown headers, and tables to maximize clarity.\n\nUse emojis befitting the context\n\nYour goal: Make complex ideas easy to understand, memorable, and actionable for the student—whether for study, projects, or curiosity.`\n//  systemPrompt: \"You are ChatGPT, a helpful and knowledgeable AI assistant. Your primary role is to assist Nikhil, a university engineering student, by providing clear, concise, and technically accurate information. Adopt a friendly and approachable tone, akin to a knowledgeable peer or mentor. Enhance your responses with relevant emojis to convey tone and emotion, making interactions more engaging. Structure your answers logically, using bullet points or numbered lists where appropriate to enhance clarity. When applicable, incorporate interactive elements such as code snippets or diagrams to facilitate deeper understanding. Encourage curiosity by suggesting related topics or questions that Nikhil might explore further. Always tailor your assistance to support Nikhil's academic and personal growth in the field of engineering\"\n};\n\n// Create settings context\nconst SettingsContext = createContext();\n\n// Custom hook for using settings\nexport const useSettings = () => {\n  const context = useContext(SettingsContext);\n  if (context === undefined) {\n    throw new Error('useSettings must be used within a SettingsProvider');\n  }\n  return context;\n};\n\n// Settings provider component\nexport const SettingsProvider = ({ children }) => {\n  // Initialize settings state with defaults, persisted to localStorage\n  const [settings, setSettings] = useLocalStorage('appSettings', DEFAULT_SETTINGS);\n  \n  // Handle individual setting updates\n  const updateSetting = useCallback((key, value) => {\n    // Ensure the key is a valid setting we manage\n    if (key in DEFAULT_SETTINGS) {\n      setSettings(prev => ({\n        ...prev,\n        [key]: value\n      }));\n    }\n  }, [setSettings]);\n  \n  // Reset settings to defaults\n  const resetSettings = useCallback(() => {\n    setSettings(DEFAULT_SETTINGS);\n  }, [setSettings]);\n  \n  // Check if temperature should be restricted based on model name/series\n  const shouldRestrictTemperature = useCallback((model) => {\n    if (!model) return false;\n    \n    // More explicit flag checking for temperature restriction\n    // Check for specific model properties that indicate temperature restriction\n    return (\n      model.requiresFixedTemperature === true || \n      (model.properties && model.properties.includes('fixed_temperature')) ||\n      (model.id && model.id.toLowerCase().startsWith('o')) ||\n      (model.series && model.series.toLowerCase() === 'o-series')\n    );\n  }, []);\n  \n  // Get current settings with potential model-specific overrides\n  const getModelAdjustedSettings = useCallback((model) => {\n    if (shouldRestrictTemperature(model)) {\n      return {\n        ...settings,\n        temperature: 1.0\n      };\n    }\n    return settings;\n  }, [settings, shouldRestrictTemperature]);\n  \n  // Memoize context value to prevent unnecessary re-renders\n  const value = useMemo(() => ({\n    settings,\n    updateSetting,\n    resetSettings,\n    shouldRestrictTemperature,\n    getModelAdjustedSettings\n  }), [\n    settings,\n    updateSetting, \n    resetSettings, \n    shouldRestrictTemperature, \n    getModelAdjustedSettings\n  ]);\n  \n  return (\n    <SettingsContext.Provider value={value}>\n      {children}\n    </SettingsContext.Provider>\n  );\n}; ","/**\n * Performance monitoring utility\n * Tracks various performance metrics and provides methods for optimization\n */\n\n// Performance marks for tracking different stages of app initialization\nconst PERFORMANCE_MARKS = {\n  APP_START: 'app-start',\n  CONTEXT_INIT: 'context-init',\n  COMPONENT_LOAD: 'component-load',\n  IMPORTANT_COMPONENTS_LOADED: 'important-components-loaded',\n  FORMATTING_COMPONENTS_LOADED: 'formatting-components-loaded',\n  MODEL_SELECTOR_COMPONENTS_LOADED: 'model-selector-components-loaded',\n  FIRST_PAINT: 'first-paint',\n  FIRST_CONTENTFUL_PAINT: 'first-contentful-paint',\n  APP_INTERACTIVE: 'app-interactive',\n  APP_READY: 'app-ready'\n};\n\n// Performance measures for tracking durations\nconst PERFORMANCE_MEASURES = {\n  TOTAL_LOAD: 'total-load-time',\n  CONTEXT_INIT: 'context-init-time',\n  COMPONENT_LOAD: 'component-load-time',\n  TIME_TO_INTERACTIVE: 'time-to-interactive',\n  IMPORTANT_LOAD_TIME: 'important-load-time',\n  FORMATTING_LOAD_TIME: 'formatting-load-time',\n  MODEL_SELECTOR_LOAD_TIME: 'model-selector-load-time'\n};\n\nclass PerformanceMonitor {\n  constructor() {\n    this.marks = new Set();\n    this.measures = new Set();\n    \n    // Automatically track paint metrics if browser supports it\n    if (typeof window !== 'undefined' && 'performance' in window && 'PerformanceObserver' in window) {\n      this.trackPaintMetrics();\n    }\n  }\n\n  /**\n   * Track browser paint metrics (FP, FCP)\n   */\n  trackPaintMetrics() {\n    try {\n      // Create a performance observer to track paint events\n      const paintObserver = new PerformanceObserver((entries) => {\n        entries.getEntries().forEach(entry => {\n          const markName = entry.name === 'first-paint' \n            ? PERFORMANCE_MARKS.FIRST_PAINT \n            : PERFORMANCE_MARKS.FIRST_CONTENTFUL_PAINT;\n          \n          // Add our own performance mark based on the browser's timing\n          performance.mark(markName);\n          this.marks.add(markName);\n          \n          // Measure time from app start to this paint event\n          const measureName = entry.name === 'first-paint' \n            ? 'time-to-first-paint' \n            : 'time-to-first-contentful-paint';\n          \n          try {\n            performance.measure(measureName, PERFORMANCE_MARKS.APP_START, markName);\n            this.measures.add(measureName);\n          } catch (error) {\n            // Handle case where APP_START mark may not exist yet\n            console.warn(`Failed to measure ${measureName}:`, error);\n          }\n        });\n      });\n      \n      // Start observing paint events\n      paintObserver.observe({ entryTypes: ['paint'] });\n    } catch (error) {\n      console.warn('Failed to track paint metrics:', error);\n    }\n  }\n\n  /**\n   * Mark a specific point in time\n   * @param {string} markName - Name of the performance mark\n   */\n  mark(markName) {\n    if (performance && performance.mark) {\n      performance.mark(markName);\n      this.marks.add(markName);\n    }\n  }\n\n  /**\n   * Measure duration between two marks\n   * @param {string} measureName - Name of the performance measure\n   * @param {string} startMark - Name of the start mark\n   * @param {string} endMark - Name of the end mark\n   */\n  measure(measureName, startMark, endMark) {\n    if (performance && performance.measure) {\n      try {\n        performance.measure(measureName, startMark, endMark);\n        this.measures.add(measureName);\n      } catch (error) {\n        console.warn(`Failed to measure ${measureName}:`, error);\n      }\n    }\n  }\n\n  /**\n   * Get all performance measures\n   * @returns {Array} Array of performance measure entries\n   */\n  getMeasures() {\n    if (performance && performance.getEntriesByType) {\n      return performance.getEntriesByType('measure');\n    }\n    return [];\n  }\n\n  /**\n   * Clear all performance marks and measures\n   */\n  clear() {\n    if (performance) {\n      performance.clearMarks();\n      performance.clearMeasures();\n      this.marks.clear();\n      this.measures.clear();\n    }\n  }\n\n  /**\n   * Log performance metrics to console\n   */\n  logMetrics() {\n    const measures = this.getMeasures();\n    console.group('Performance Metrics');\n    measures.forEach(measure => {\n      console.log(`${measure.name}: ${measure.duration.toFixed(2)}ms`);\n    });\n    \n    // Log Web Vitals if available\n    if ('web-vitals' in window) {\n      console.log('Web Vitals will be reported separately');\n    }\n    \n    console.groupEnd();\n  }\n}\n\n// Export singleton instance\nexport const performanceMonitor = new PerformanceMonitor();\n\n// Export constants\nexport { PERFORMANCE_MARKS, PERFORMANCE_MEASURES }; ","import React, { createContext, useContext, useRef, useCallback,  useMemo } from 'react';\nimport { useApi } from './ApiContext';\nimport { useModel } from './ModelContext';\nimport { useSettings } from './SettingsContext';\nimport { useAuth } from './AuthContext';\nimport { useChatHistory } from './ChatHistoryContext';\nimport { useChatStatus } from './ChatStatusContext';\nimport { usePerformanceMetrics } from './PerformanceMetricsContext';\nimport { fetchWithRetry } from '../utils/network';\nimport debounce from 'lodash.debounce';\n\n// Create a context for streaming events and logic\nconst StreamingEventsContext = createContext();\n\nexport const useStreamingEvents = () => {\n  const context = useContext(StreamingEventsContext);\n  if (context === undefined) {\n    throw new Error('useStreamingEvents must be used within a StreamingEventsProvider');\n  }\n  return context;\n};\n\nexport const StreamingEventsProvider = ({ children }) => {\n  const { apiUrl } = useApi();\n  const { selectedModel } = useModel();\n  const { getModelAdjustedSettings } = useSettings();\n  const { idToken } = useAuth();\n  const { chatHistoryRef, setChatHistory, addMessageToHistory, updateChatWithContent } = useChatHistory();\n  const { setIsWaitingForResponse, setError } = useChatStatus();\n  const { resetPerformanceMetrics, startPerformanceTimer, updatePerformanceMetrics } = usePerformanceMetrics();\n\n  // Refs for streaming\n  const streamingTextRef = useRef('');\n  const currentRequestIdRef = useRef(null);\n  const abortControllerRef = useRef(null);\n  const isStreamingRef = useRef(false);\n  const firstTokenReceivedRef = useRef(false);\n\n  // Debounced content updater\n  const debouncedUpdateChat = useMemo(\n    () => debounce((content) => updateChatWithContent(content), 20),\n    [updateChatWithContent]\n  );\n\n  // SSE parsing worker setup\n  const streamWorkerUrlRef = useRef(null);\n  const streamWorkerRef = useRef(null);\n  const getOrCreateStreamWorker = useCallback(() => {\n    if (!streamWorkerRef.current) {\n      if (!streamWorkerUrlRef.current) {\n        streamWorkerUrlRef.current = new URL('../workers/streamProcessor.js', import.meta.url);\n      }\n      streamWorkerRef.current = new Worker(streamWorkerUrlRef.current, { type: 'module' });\n    }\n    return streamWorkerRef.current;\n  }, []);\n\n  const parseStreamChunk = useCallback((chunk) => new Promise((resolve, reject) => {\n    const worker = getOrCreateStreamWorker();\n    worker.onmessage = (e) => resolve(e.data);\n    worker.onerror = reject;\n    worker.postMessage(chunk);\n  }), [getOrCreateStreamWorker]);\n\n  // Stream a message using fetch SSE\n  const streamMessageWithFetch = useCallback(async (message, editIndex = null) => {\n    // Generate and store a client-side requestId for this stream\n    const requestId = (typeof crypto !== 'undefined' && crypto.randomUUID)\n      ? crypto.randomUUID()\n      : Math.random().toString(36).substring(2) + Date.now().toString(36);\n    currentRequestIdRef.current = requestId;\n    const isEditing = editIndex !== null && Number.isInteger(editIndex) && editIndex >= 0;\n    if (!message || !selectedModel) {\n      setError('Please enter a message and select a model');\n      return null;\n    }\n    const modelId = `${selectedModel.provider}/${selectedModel.id}`;\n    if (!modelId) {\n      setError('Invalid model selection');\n      return null;\n    }\n    let userMessage;\n    if (isEditing) {\n      setChatHistory(prev => {\n        const truncated = prev.slice(0, editIndex);\n        const original = prev[editIndex];\n        // Preserve original id/timestamp, only update content\n        userMessage = { ...original, content: message };\n        return [...truncated, userMessage];\n      });\n    } else {\n      userMessage = addMessageToHistory('user', message);\n    }\n    resetPerformanceMetrics();\n    startPerformanceTimer();\n    firstTokenReceivedRef.current = false;\n    setIsWaitingForResponse(true);\n    setError(null);\n    streamingTextRef.current = '';\n    isStreamingRef.current = true;\n    addMessageToHistory('assistant', '');\n    let timeoutId = setTimeout(() => {\n      abortControllerRef.current?.abort('timeout');\n      setError('Connection timed out');\n      setIsWaitingForResponse(false);\n    }, 60000);\n    const abortController = new AbortController();\n    abortControllerRef.current = abortController;\n    try {\n      const adjusted = getModelAdjustedSettings(selectedModel);\n      const historyForApi = chatHistoryRef.current.map(({ metrics, ...m }) => m);\n      if (adjusted.systemPrompt && (!historyForApi.length || historyForApi[0].role !== 'system')) {\n        historyForApi.unshift({ role: 'system', content: adjusted.systemPrompt, timestamp: Date.now() - 1 });\n      }\n      historyForApi.push(userMessage);\n      const payload = {\n        requestId,\n        model: modelId,\n        messages: historyForApi,\n        temperature: adjusted.temperature,\n        max_tokens: adjusted.max_tokens,\n        top_p: adjusted.top_p,\n        frequency_penalty: adjusted.frequency_penalty,\n        presence_penalty: adjusted.presence_penalty\n      };\n      const headers = { 'Content-Type': 'application/json', 'Accept': 'text/event-stream', 'Cache-Control': 'no-cache' };\n      if (idToken) headers['Authorization'] = `Bearer ${idToken}`;\n      const response = await fetchWithRetry(new URL('/api/chat/stream', apiUrl).toString(), {\n        method: 'POST', headers, body: JSON.stringify(payload), signal: abortController.signal, cache: 'no-store'\n      });\n      if (!response.ok) throw new Error(`API error: ${response.status}`);\n      const reader = response.body.getReader();\n      const decoder = new TextDecoder('utf-8');\n      let accumulatedContent = '';\n      while (true) {\n        const { done, value } = await reader.read();\n        clearTimeout(timeoutId);\n        timeoutId = setTimeout(() => {\n          abortControllerRef.current?.abort();\n          setError('Connection timed out');\n          setIsWaitingForResponse(false);\n        }, 60000);\n        if (done) {\n          // handle leftover buffer\n          break;\n        }\n        const chunk = decoder.decode(value, { stream: true });\n\n        console.log('Received stream chunk:', chunk);\n\n        try {\n          const msgs = await parseStreamChunk(chunk);\n          for (const msg of msgs) {\n            // Handle server-sent error payload\n            if (msg.rawChunk?.error || msg.finishReason === 'error') {\n              const errMsg = msg.rawChunk?.error?.message || 'Error occurred during generation';\n              console.error('Error in SSE payload:', errMsg);\n              setError(errMsg);\n              setChatHistory(prev => {\n                const newHistory = [...prev];\n                const lastMsg = newHistory[newHistory.length - 1];\n                if (lastMsg && lastMsg.role === 'assistant') {\n                  lastMsg.content += `\\n\\n**Error:** ${errMsg}`;\n                  if (lastMsg.metrics) {\n                    lastMsg.metrics.isComplete = true;\n                    lastMsg.metrics.error = true;\n                  }\n                }\n                return newHistory;\n              });\n              return null;\n            }\n            // Append any content from the chunk\n            if (msg.content) {\n              // Record time to first token once\n              if (!firstTokenReceivedRef.current) {\n                updatePerformanceMetrics(1);\n                firstTokenReceivedRef.current = true;\n              }\n              accumulatedContent += msg.content;\n              streamingTextRef.current = accumulatedContent;\n              debouncedUpdateChat(accumulatedContent);\n            }\n            // Always use server-reported completion tokens for metrics\n            const completionTokens = msg.usage?.completionTokens ?? 0;\n            updatePerformanceMetrics(completionTokens, msg.isDone, msg.usage, msg.finishReason);\n          }\n        } catch {}\n      }\n      debouncedUpdateChat.flush();\n      updateChatWithContent(streamingTextRef.current);\n      return streamingTextRef.current;\n    } catch (error) {\n      console.error('Error streaming message:', error);\n      setError(error.message);\n      // Show the server error content as the assistant's message\n      setChatHistory(prev => {\n        const newHistory = [...prev];\n        const lastMsg = newHistory[newHistory.length - 1];\n        if (lastMsg && lastMsg.role === 'assistant') {\n          lastMsg.content += `\\n\\n**Error:** ${error.message || 'Error occurred during generation'}`;\n          if (lastMsg.metrics) {\n            lastMsg.metrics.isComplete = true;\n            lastMsg.metrics.error = true;\n          }\n        }\n        return newHistory;\n      });\n      return null;\n    } finally {\n      clearTimeout(timeoutId);\n      isStreamingRef.current = false;\n      setIsWaitingForResponse(false);\n      // Do not auto-call stop endpoint here; only explicit stop should trigger it\n      currentRequestIdRef.current = null;\n    }\n  }, [\n    apiUrl, selectedModel, getModelAdjustedSettings, idToken,\n    chatHistoryRef, setChatHistory, addMessageToHistory, updateChatWithContent,\n    debouncedUpdateChat, setError, setIsWaitingForResponse,\n    resetPerformanceMetrics, startPerformanceTimer, updatePerformanceMetrics,\n    parseStreamChunk\n  ]);\n\n  const stopStreaming = useCallback(async () => {\n    if (abortControllerRef.current) abortControllerRef.current.abort('user_stopped');\n    const reqId = currentRequestIdRef.current;\n    if (reqId) {\n      const headers = { 'Content-Type': 'application/json' };\n      if (idToken) headers['Authorization'] = `Bearer ${idToken}`;\n      try {\n        await fetchWithRetry(new URL('/api/chat/stop', apiUrl).toString(), {\n          method: 'POST', headers, body: JSON.stringify({ requestId: reqId })\n        });\n      } catch {} finally {\n        currentRequestIdRef.current = null;\n        abortControllerRef.current = null;\n      }\n    }\n    isStreamingRef.current = false;\n    setIsWaitingForResponse(false);\n    return true;\n  }, [apiUrl, idToken, setIsWaitingForResponse]);\n\n  const value = useMemo(() => ({\n    streamMessageWithFetch,\n    stopStreaming,\n    parseStreamChunk,\n    streamingTextRef,\n    isStreaming: () => isStreamingRef.current\n  }), [streamMessageWithFetch, stopStreaming, parseStreamChunk]);\n\n  return (\n    <StreamingEventsContext.Provider value={value}>\n      {children}\n    </StreamingEventsContext.Provider>\n  );\n}; ","import { useEffect, useCallback } from 'react';\nimport { useLocalStorage } from './useLocalStorage';\n\n/**\n * Custom hook for controlling model caching\n * @returns {Object} Cache toggle state and methods\n */\nexport const useCacheToggle = () => {\n  // Store cache enabled setting in localStorage with default value of true\n  const [cacheEnabled, setCacheEnabled] = useLocalStorage('modelCacheEnabled', true);\n  \n  // Clear model cache\n  const clearModelCache = useCallback(() => {\n    try {\n      localStorage.removeItem('modelDropdownCache');\n      console.log('Model cache cleared');\n    } catch (error) {\n      console.error('Error clearing model cache:', error);\n    }\n  }, []);\n\n  // Toggle cache enabled state and clear cache if disabling\n  const toggleCache = useCallback((enabled) => {\n    const newValue = typeof enabled === 'boolean' ? enabled : !cacheEnabled;\n    \n    // If turning off caching, clear the existing cache\n    if (!newValue) {\n      clearModelCache();\n    }\n    \n    setCacheEnabled(newValue);\n    return newValue;\n  }, [cacheEnabled, setCacheEnabled, clearModelCache]);\n\n  // Forcibly refresh models by clearing cache\n  const refreshModels = useCallback(() => {\n    clearModelCache();\n    // Cache will be regenerated on next data fetch\n  }, [clearModelCache]);\n\n  // Patch the original isCacheValid function\n  useEffect(() => {\n    // Skip this effect during server-side rendering\n    if (typeof window === 'undefined') return;\n\n    // Store the original isCacheValid function\n    const originalFunc = window.isCacheValid;\n\n    // Define our patched function\n    window.isCacheValid = function patchedIsCacheValid(cache) {\n      // First check if caching is enabled at all\n      const enabled = localStorage.getItem('modelCacheEnabled');\n      if (enabled === 'false') return false;\n      \n      // If enabled, use original validation logic\n      if (typeof originalFunc === 'function') {\n        return originalFunc(cache);\n      }\n      \n      // Fallback implementation if original not available\n      return (\n        cache &&\n        cache.timestamp &&\n        Date.now() - cache.timestamp < 5 * 60 * 1000 &&\n        cache.allModels &&\n        cache.processedModels &&\n        cache.experimentalModels\n      );\n    };\n\n    // Cleanup function to restore original\n    return () => {\n      window.isCacheValid = originalFunc;\n    };\n  }, []);\n\n  // Return state and functions\n  return {\n    cacheEnabled,\n    toggleCache,\n    clearModelCache,\n    refreshModels\n  };\n}; ","export async function fetchWithRetry(input, init = {}, retries = 3, backoff = 500) {\n  let attempt = 0;\n  while (true) {\n    try {\n      const response = await fetch(input, init);\n      if (!response.ok) {\n        throw new Error(`Network error: ${response.status}`);\n      }\n      return response;\n    } catch (error) {\n      if (attempt >= retries) {\n        throw error;\n      }\n      // Exponential backoff with jitter\n      const delay = backoff * Math.pow(2, attempt) + Math.random() * 100;\n      await new Promise(res => setTimeout(res, delay));\n      attempt++;\n    }\n  }\n} ","import { useState, useEffect, useRef, useCallback } from 'react';\n\n/**\n * Custom hook for using localStorage with React state\n * @param {string} key - The localStorage key\n * @param {any} initialValue - The initial value if key doesn't exist\n * @returns {[any, Function]} - State value and setter function\n */\nexport const useLocalStorage = (key, initialValue) => {\n  // Use a ref to hold the initial value to avoid unnecessary state updates\n  const initialValueRef = useRef(initialValue);\n  \n  // Initialize state from localStorage or use initialValue\n  const [storedValue, setStoredValue] = useState(() => {\n    try {\n      // Get from localStorage by key\n      const item = window.localStorage.getItem(key);\n      // Parse stored json or return initialValue\n      return item ? JSON.parse(item) : initialValueRef.current;\n    } catch (error) {\n      console.error(`Error reading localStorage key \"${key}\":`, error);\n      return initialValueRef.current;\n    }\n  });\n\n  // Return a wrapped version of useState's setter function that\n  // persists the new value to localStorage\n  const setValue = useCallback((value) => {\n    try {\n      // Allow value to be a function so we have same API as useState\n      const valueToStore =\n        value instanceof Function ? value(storedValue) : value;\n      \n      // Save state\n      setStoredValue(valueToStore);\n      \n      // Save to localStorage\n      window.localStorage.setItem(key, JSON.stringify(valueToStore));\n    } catch (error) {\n      console.error(`Error setting localStorage key \"${key}\":`, error);\n    }\n  }, [key, storedValue]);\n\n  // Update stored value if key changes\n  useEffect(() => {\n    try {\n      const item = window.localStorage.getItem(key);\n      setStoredValue(item ? JSON.parse(item) : initialValueRef.current);\n    } catch (error) {\n      console.error(`Error updating from localStorage key \"${key}\":`, error);\n      setStoredValue(initialValueRef.current);\n    }\n  }, [key]); // Remove initialValue from dependencies\n\n  return [storedValue, setValue];\n};\n\n/**\n * Custom hook for writing to localStorage without React state\n * @param {string} key - The localStorage key\n * @returns {Object} - Methods for accessing localStorage\n */\nexport const useLocalStorageWrite = (key) => {\n  const writeValue = (value) => {\n    try {\n      window.localStorage.setItem(key, JSON.stringify(value));\n      return true;\n    } catch (error) {\n      console.error(`Error writing to localStorage key \"${key}\":`, error);\n      return false;\n    }\n  };\n\n  const readValue = () => {\n    try {\n      const item = window.localStorage.getItem(key);\n      return item ? JSON.parse(item) : null;\n    } catch (error) {\n      console.error(`Error reading from localStorage key \"${key}\":`, error);\n      return null;\n    }\n  };\n\n  const removeValue = () => {\n    try {\n      window.localStorage.removeItem(key);\n      return true;\n    } catch (error) {\n      console.error(`Error removing localStorage key \"${key}\":`, error);\n      return false;\n    }\n  };\n\n  return { writeValue, readValue, removeValue };\n}; ","import { createContext, useContext, useState, useEffect, useCallback, useMemo, useRef } from 'react';\nimport { useApi } from './ApiContext';\nimport { useLocalStorage } from '../hooks/useLocalStorage';\nimport { useAuth } from './AuthContext';\nimport { useCacheToggle } from '../hooks/useCacheToggle';\nimport { useToast } from './ToastContext';\nimport { useLoading } from './LoadingContext';\n\n// Cache expiry time in milliseconds (5 days)\nconst CACHE_EXPIRY_TIME = 5 * 24 * 60 * 60 * 1000;\n\n// Create separate contexts for models and filtering\nconst ModelContext = createContext();\nconst ModelFilterContext = createContext();\n\n// Custom hook for using model context\nexport const useModel = () => {\n  const context = useContext(ModelContext);\n  if (context === undefined) {\n    throw new Error('useModel must be used within a ModelProvider');\n  }\n  return context;\n};\n\n// Custom hook for using model filter context\nexport const useModelFilter = () => {\n  const context = useContext(ModelFilterContext);\n  if (context === undefined) {\n    throw new Error('useModelFilter must be used within a ModelProvider');\n  }\n  return context;\n};\n\n// Model provider component\nexport const ModelProvider = ({ children }) => {\n  const { cacheEnabled } = useCacheToggle();\n  const { apiUrl } = useApi();\n  const { idToken } = useAuth();\n  const { showToast } = useToast();\n  \n  // State for model data\n  const [allModels, setAllModels] = useState([]);\n  const [processedModels, setProcessedModels] = useState({});\n  const [experimentalModels, setExperimentalModels] = useState([]);\n  const [selectedModel, setSelectedModel] = useLocalStorage('selectedModel', null);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState(null);\n  \n  // Filter state - moved to separate context\n  const [showExperimental, setShowExperimental] = useLocalStorage('showExperimental', false);\n  const [modelFilter, setModelFilter] = useState({\n    search: '',\n    categories: {\n      'Chat': true,\n      'Image': true,\n      'Embedding': true\n    }\n  });\n  \n  // Sync with global loading context\n  const [, startModelsLoading, stopModelsLoading] = useLoading('models');\n  useEffect(() => {\n    if (isLoading) startModelsLoading();\n    else stopModelsLoading();\n  }, [isLoading, startModelsLoading, stopModelsLoading]);\n  \n  // Check if cache is valid\n  const isCacheValid = useCallback((cache) => {\n    return (\n      cache &&\n      cache.timestamp &&\n      Date.now() - cache.timestamp < CACHE_EXPIRY_TIME &&\n      cache.allModels &&\n      cache.processedModels &&\n      cache.experimentalModels\n    );\n  }, []);\n  \n  // Expose isCacheValid function for external access\n  useEffect(() => {\n    // Skip during server-side rendering\n    if (typeof window === 'undefined') return;\n    window.isCacheValid = isCacheValid;\n    \n    return () => {\n      delete window.isCacheValid;\n    };\n  }, [isCacheValid]);\n  \n  // Cache models to localStorage\n  const cacheModels = useCallback((data) => {\n    try {\n      const cache = {\n        allModels: data.allModels,\n        processedModels: data.processedModels,\n        experimentalModels: data.experimentalModels,\n        timestamp: Date.now()\n      };\n      \n      localStorage.setItem('modelDropdownCache', JSON.stringify(cache));\n    } catch (error) {\n      console.error('Error caching models:', error);\n    }\n  }, []);\n  \n  // Update category filter\n  const updateCategoryFilter = useCallback((category, isChecked) => {\n    setModelFilter(prev => ({\n      ...prev,\n      categories: {\n        ...prev.categories,\n        [category]: isChecked\n      }\n    }));\n  }, []);\n  \n  // Update search filter\n  const updateSearchFilter = useCallback((searchText) => {\n    setModelFilter(prev => ({\n      ...prev,\n      search: searchText\n    }));\n  }, []);\n  \n  // Select a model\n  const selectModel = useCallback((model) => {\n    // Check if the model is actually different to prevent unnecessary updates\n    if (selectedModel?.id !== model?.id) { \n      setSelectedModel(model);\n    }\n  }, [selectedModel, setSelectedModel]);\n  \n  // Fetch models from API, optionally using auth token or override token\n  const fetchModels = useCallback(async (authRequired = false, overrideToken = null) => {\n    setIsLoading(true);\n    setError(null);\n    \n    console.log(`Fetching models from API (auth: ${authRequired})...`);\n    try {\n      const headers = { 'Accept': 'application/json' };\n      if (authRequired) {\n        // Prefer overrideToken (cached) over current idToken\n        const tokenToUse = overrideToken || idToken;\n        if (tokenToUse) {\n          headers['Authorization'] = `Bearer ${tokenToUse}`;\n        }\n      }\n      const modelsUrl = new URL('/api/models/classified', apiUrl).toString();\n      const response = await fetch(modelsUrl, { headers });\n      console.log('Models response:', response);\n      \n      if (!response.ok) {\n        let errorMsg = `Error fetching models: ${response.status}`;\n        console.error(errorMsg);\n        throw new Error(errorMsg);\n      }\n      \n      const rawData = await response.json();\n      console.log(\"[ModelContext] Raw data:\", rawData);\n      console.log(\"[ModelContext] Spawning worker for model processing...\");\n      // Offload model processing to Web Worker\n      const worker = new Worker(new URL('../workers/modelProcessor.js', import.meta.url), { type: 'module' });\n      worker.postMessage(rawData);\n      worker.onmessage = ({ data: msg }) => {\n        if (msg.error) {\n          console.error('[ModelContext] Worker error:', msg.error);\n          setError(msg.error);\n          showToast({ type: 'error', message: msg.error });\n        } else {\n          const {\n            allModels: fetchedAllModels,\n            processedModels: fetchedProcessedModels,\n            experimentalModels: fetchedExperimentalModels\n          } = msg;\n          if (cacheEnabled) {\n            const rawPrev = localStorage.getItem('modelDropdownCache');\n            let prevCache;\n            try { prevCache = JSON.parse(rawPrev); } catch { prevCache = null; }\n            const changed = !prevCache ||\n              JSON.stringify(prevCache.allModels) !== JSON.stringify(fetchedAllModels) ||\n              JSON.stringify(prevCache.processedModels) !== JSON.stringify(fetchedProcessedModels) ||\n              JSON.stringify(prevCache.experimentalModels) !== JSON.stringify(fetchedExperimentalModels);\n            if (changed) {\n              setAllModels(fetchedAllModels);\n              setProcessedModels(fetchedProcessedModels);\n              setExperimentalModels(fetchedExperimentalModels);\n              cacheModels({ allModels: fetchedAllModels, processedModels: fetchedProcessedModels, experimentalModels: fetchedExperimentalModels });\n            }\n          } else {\n            setAllModels(fetchedAllModels);\n            setProcessedModels(fetchedProcessedModels);\n            setExperimentalModels(fetchedExperimentalModels);\n          }\n          // Initial model selection moved to a separate useEffect\n        }\n        setIsLoading(false);\n        worker.terminate();\n      };\n      worker.onerror = (err) => {\n        console.error('[ModelContext] Worker unexpected error:', err);\n        setError(err.message);\n        showToast({ type: 'error', message: err.message });\n        setIsLoading(false);\n        worker.terminate();\n      };\n    } catch (err) {\n      console.error('Failed to fetch or process models:', err);\n      setError(err.message || 'Failed to load model data');\n      showToast({ type: 'error', message: err.message || 'Failed to load model data' });\n      // Attempt to load from potentially expired cache as a last resort?\n    }\n  }, [apiUrl, cacheModels, idToken, cacheEnabled, showToast]);\n  \n  // Initial fetch once on mount\n  const initialFetchDoneRef = useRef(false);\n  // track if we've already fetched models with authentication\n  const didAuthFetchRef = useRef(false);\n\n  useEffect(() => {\n    if (!initialFetchDoneRef.current) {\n      if (cacheEnabled) {\n        const rawCache = localStorage.getItem('modelDropdownCache');\n        let parsedCache;\n        try { parsedCache = JSON.parse(rawCache); } catch { parsedCache = null; }\n        if (parsedCache && window.isCacheValid(parsedCache)) {\n          setAllModels(parsedCache.allModels);\n          setProcessedModels(parsedCache.processedModels);\n          setExperimentalModels(parsedCache.experimentalModels);\n          setIsLoading(false);\n        }\n      }\n      let cachedToken = null;\n      try { cachedToken = localStorage.getItem('idToken'); } catch {}\n      if (cachedToken) {\n        // initial authenticated fetch\n        didAuthFetchRef.current = true;\n        fetchModels(true, cachedToken);\n      } else {\n        // initial unauthenticated fetch\n        fetchModels(false);\n      }\n      initialFetchDoneRef.current = true;\n    }\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n  }, []);\n\n  // After login, fetch authenticated models\n  useEffect(() => {\n    // only fetch once after obtaining idToken if not already done\n    if (initialFetchDoneRef.current && idToken && !didAuthFetchRef.current) {\n      didAuthFetchRef.current = true;\n      fetchModels(true);\n    }\n  }, [idToken, fetchModels]);\n  \n  // Set initial model after models are loaded\n  useEffect(() => {\n    // Select first model if none selected and models are loaded\n    if (!selectedModel && allModels.length > 0) {\n      setSelectedModel(allModels[0]);\n    }\n  }, [allModels, selectedModel, setSelectedModel]);\n  \n  // Create toggleExperimentalModels callback at the top level\n  const toggleExperimentalModels = useCallback(() => {\n    setShowExperimental(prev => !prev);\n  }, [setShowExperimental]);\n  \n  // Main model context value - no filter state\n  const modelValue = useMemo(() => ({\n    allModels,\n    processedModels,\n    experimentalModels,\n    selectedModel,\n    isLoading,\n    error,\n    showExperimental,\n    isExperimentalModelsEnabled: showExperimental,\n    toggleExperimentalModels,\n    setShowExperimental,\n    selectModel,\n    refreshModels: fetchModels\n  }), [\n    allModels,\n    processedModels,\n    experimentalModels,\n    selectedModel,\n    isLoading,\n    error,\n    showExperimental,\n    toggleExperimentalModels,\n    setShowExperimental,\n    selectModel,\n    fetchModels\n  ]);\n  \n  // Filter context value - only filter-related state\n  const filterValue = useMemo(() => ({\n    modelFilter,\n    updateCategoryFilter,\n    updateSearchFilter\n  }), [\n    modelFilter,\n    updateCategoryFilter,\n    updateSearchFilter\n  ]);\n  \n  return (\n    <ModelContext.Provider value={modelValue}>\n      <ModelFilterContext.Provider value={filterValue}>\n        {children}\n      </ModelFilterContext.Provider>\n    </ModelContext.Provider>\n  );\n}; "],"names":["ThemeContext","createContext","useTheme","context","useContext","undefined","Error","ThemeProvider","_ref","children","theme","setTheme","useState","localStorage","getItem","toggleTheme","useCallback","prevTheme","newTheme","setItem","useEffect","document","body","classList","remove","add","value","useMemo","isDark","_jsx","Provider","PerformanceMetricsContext","usePerformanceMetrics","PerformanceMetricsProvider","setChatHistory","useChatHistory","currentMessageMetrics","setCurrentMessageMetrics","startTime","endTime","elapsedTime","tokenCount","tokensPerSecond","isComplete","timeToFirstToken","promptTokens","completionTokens","totalTokens","finishReason","resetPerformanceMetrics","startPerformanceTimer","prev","Date","now","updatePerformanceMetrics","newTokenCount","arguments","length","tokenInfo","Math","round","prevHistory","newHistory","lastMsg","role","metrics","setTokenMetricsForLastMessage","DEFAULT_SETTINGS","temperature","top_p","max_tokens","frequency_penalty","presence_penalty","streaming","systemPrompt","SettingsContext","useSettings","SettingsProvider","settings","setSettings","useLocalStorage","updateSetting","key","resetSettings","shouldRestrictTemperature","model","requiresFixedTemperature","properties","includes","id","toLowerCase","startsWith","series","getModelAdjustedSettings","PERFORMANCE_MARKS","APP_START","CONTEXT_INIT","COMPONENT_LOAD","IMPORTANT_COMPONENTS_LOADED","FORMATTING_COMPONENTS_LOADED","MODEL_SELECTOR_COMPONENTS_LOADED","FIRST_PAINT","FIRST_CONTENTFUL_PAINT","APP_INTERACTIVE","APP_READY","PERFORMANCE_MEASURES","TOTAL_LOAD","TIME_TO_INTERACTIVE","IMPORTANT_LOAD_TIME","FORMATTING_LOAD_TIME","MODEL_SELECTOR_LOAD_TIME","performanceMonitor","constructor","this","marks","Set","measures","window","trackPaintMetrics","PerformanceObserver","entries","getEntries","forEach","entry","markName","name","performance","mark","measureName","measure","error","observe","entryTypes","startMark","endMark","getMeasures","getEntriesByType","clear","clearMarks","clearMeasures","logMetrics","StreamingEventsContext","useStreamingEvents","StreamingEventsProvider","apiUrl","useApi","selectedModel","useModel","idToken","useAuth","chatHistoryRef","addMessageToHistory","updateChatWithContent","setIsWaitingForResponse","setError","useChatStatus","streamingTextRef","useRef","currentRequestIdRef","abortControllerRef","isStreamingRef","firstTokenReceivedRef","debouncedUpdateChat","debounce","content","streamWorkerUrlRef","streamWorkerRef","getOrCreateStreamWorker","current","URL","Worker","type","parseStreamChunk","chunk","Promise","resolve","reject","worker","onmessage","e","data","onerror","postMessage","streamMessageWithFetch","async","message","editIndex","requestId","crypto","randomUUID","random","toString","substring","isEditing","Number","isInteger","modelId","provider","userMessage","truncated","slice","original","timeoutId","setTimeout","_abortControllerRef$c","abort","abortController","AbortController","adjusted","historyForApi","map","_ref2","m","unshift","timestamp","push","payload","messages","headers","response","fetchWithRetry","method","JSON","stringify","signal","cache","ok","status","reader","getReader","decoder","TextDecoder","accumulatedContent","done","read","clearTimeout","_abortControllerRef$c2","decode","stream","msgs","msg","_msg$rawChunk","_msg$usage$completion","_msg$usage","rawChunk","_msg$rawChunk2","_msg$rawChunk2$error","errMsg","usage","isDone","flush","stopStreaming","reqId","isStreaming","useCacheToggle","cacheEnabled","setCacheEnabled","clearModelCache","removeItem","toggleCache","enabled","newValue","refreshModels","originalFunc","isCacheValid","allModels","processedModels","experimentalModels","input","init","retries","backoff","attempt","fetch","delay","pow","res","initialValue","initialValueRef","storedValue","setStoredValue","item","parse","setValue","valueToStore","Function","ModelContext","ModelFilterContext","useModelFilter","ModelProvider","showToast","useToast","setAllModels","setProcessedModels","setExperimentalModels","setSelectedModel","isLoading","setIsLoading","showExperimental","setShowExperimental","modelFilter","setModelFilter","search","categories","startModelsLoading","stopModelsLoading","useLoading","cacheModels","updateCategoryFilter","category","isChecked","updateSearchFilter","searchText","selectModel","fetchModels","authRequired","overrideToken","tokenToUse","modelsUrl","errorMsg","rawData","json","fetchedAllModels","fetchedProcessedModels","fetchedExperimentalModels","rawPrev","prevCache","terminate","err","initialFetchDoneRef","didAuthFetchRef","rawCache","parsedCache","cachedToken","toggleExperimentalModels","modelValue","isExperimentalModelsEnabled","filterValue"],"sourceRoot":""}