{"version":3,"file":"static/js/vendors-node_modules_micromark-extension-gfm-autolink-literal_lib_syntax_js-node_modules_micr-143c10.01dff165be.chunk.v1_9_5.js","mappings":"+QA8BO,SAASA,EAAiBC,GAE/B,IAAIC,GADaD,GAAW,CAAC,GACPE,YACtB,MAAMC,EAAY,CAChBC,SA8GF,SAA+BC,EAASC,EAAIC,GAC1C,MAAMC,EAAWC,KAAKD,SAChBE,EAASD,KAAKC,OACpB,IAAIC,EAAO,EACX,OAGA,SAAeC,GACb,OACe,MAAbJ,GACsC,oBAAtCE,EAAOA,EAAOG,OAAS,GAAG,GAAGC,KAEtBP,EAAIK,IAEbP,EAAQU,MAAM,kCACPC,EAAKJ,GACd,EAGA,SAASI,EAAKJ,GACZ,MAAMK,GAASC,EAAAA,EAAAA,GAAkBV,GACjC,GAAa,MAATI,EAEF,OAAID,EAAO,EAAUJ,EAAIK,IACzBP,EAAQc,QAAQP,GAChBD,IACOK,GAET,GAAIL,EAAO,IAAMV,EAAQ,OAAOM,EAAIK,GACpC,MAAMQ,EAAQf,EAAQgB,KAAK,kCACrBC,GAAQJ,EAAAA,EAAAA,GAAkBN,GAGhC,OAFAQ,EAAMG,OAASD,GAAoB,IAAVA,GAAeE,QAAQP,GAChDG,EAAMK,QAAUR,GAAsB,IAAXA,GAAgBO,QAAQF,GAC5ChB,EAAGM,EACZ,CACF,EAhJEc,WAsBF,SAAiChB,EAAQiB,GACvC,IAAIC,GAAS,EAGb,OAASA,EAAQlB,EAAOG,QAEtB,GACuB,UAArBH,EAAOkB,GAAO,IACY,mCAA1BlB,EAAOkB,GAAO,GAAGd,MACjBJ,EAAOkB,GAAO,GAAGH,OACjB,CACA,IAAII,EAAOD,EAGX,KAAOC,KAEL,GACsB,SAApBnB,EAAOmB,GAAM,IACY,mCAAzBnB,EAAOmB,GAAM,GAAGf,MAChBJ,EAAOmB,GAAM,GAAGN,OAEhBb,EAAOkB,GAAO,GAAGE,IAAIC,OAASrB,EAAOkB,GAAO,GAAGI,MAAMD,QACnDrB,EAAOmB,GAAM,GAAGC,IAAIC,OAASrB,EAAOmB,GAAM,GAAGG,MAAMD,OACrD,CACArB,EAAOkB,GAAO,GAAGd,KAAO,wBACxBJ,EAAOmB,GAAM,GAAGf,KAAO,wBAGvB,MAAMmB,EAAgB,CACpBnB,KAAM,gBACNkB,MAAOE,OAAOC,OAAO,CAAC,EAAGzB,EAAOmB,GAAM,GAAGG,OACzCF,IAAKI,OAAOC,OAAO,CAAC,EAAGzB,EAAOkB,GAAO,GAAGE,MAIpCM,EAAO,CACXtB,KAAM,oBACNkB,MAAOE,OAAOC,OAAO,CAAC,EAAGzB,EAAOmB,GAAM,GAAGC,KACzCA,IAAKI,OAAOC,OAAO,CAAC,EAAGzB,EAAOkB,GAAO,GAAGI,QAKpCK,EAAa,CACjB,CAAC,QAASJ,EAAeN,GACzB,CAAC,QAASjB,EAAOmB,GAAM,GAAIF,GAC3B,CAAC,OAAQjB,EAAOmB,GAAM,GAAIF,GAC1B,CAAC,QAASS,EAAMT,IAEZW,EAAaX,EAAQY,OAAOC,WAAWF,WAAWG,KACpDH,IAEFI,EAAAA,EAAAA,GACEL,EACAA,EAAWxB,OACX,GACAa,EAAAA,EAAAA,GAAWY,EAAY5B,EAAOiC,MAAMd,EAAO,EAAGD,GAAQD,KAK1De,EAAAA,EAAAA,GAAOL,EAAYA,EAAWxB,OAAQ,EAAG,CACvC,CAAC,OAAQuB,EAAMT,GACf,CAAC,QAASjB,EAAOkB,GAAO,GAAID,GAC5B,CAAC,OAAQjB,EAAOkB,GAAO,GAAID,GAC3B,CAAC,OAAQM,EAAeN,MAE1Be,EAAAA,EAAAA,GAAOhC,EAAQmB,EAAO,EAAGD,EAAQC,EAAO,EAAGQ,GAC3CT,EAAQC,EAAOQ,EAAWxB,OAAS,EACnC,KACF,CAEJ,CAGF,IADAe,GAAS,IACAA,EAAQlB,EAAOG,QACQ,mCAA1BH,EAAOkB,GAAO,GAAGd,OACnBJ,EAAOkB,GAAO,GAAGd,KAAO,QAG5B,OAAOJ,CACT,GAlGA,OAHIT,UACFA,GAAS,GAEJ,CACLmC,KAAM,CACJ,IAAOjC,GAETmC,WAAY,CACVG,KAAM,CAACtC,IAETyC,iBAAkB,CAChBH,KAAM,CAAC,MAoIb,C,mCC1KO,MCaMI,EAAaC,EAAW,YAcxBC,EAAoBD,EAAW,cAwHrC,SAASE,EAA0BpC,GACxC,OAAgB,OAATA,IAAkBA,EAAO,GAAc,KAATA,EACvC,CAnG0BkC,EAAW,uBAgCXA,EAAW,MAoBRA,EAAW,cAeRA,EAAW,kBA0EpC,MAAMG,EAAqBH,ED9LhC,wwCCoNWI,EAAoBJ,EAAW,MAQ5C,SAASA,EAAWK,GAClB,OAUA,SAAevC,GACb,OAAgB,OAATA,GAAiBuC,EAAMC,KAAKC,OAAOC,aAAa1C,GACzD,CACF,CClOA,MAAM2C,EAAY,CAChBnD,SAiaF,SAA2BC,EAASC,EAAIC,GACtC,IAAII,EAAO,EACX,OAYA,SAAS6C,EAAgB5C,GACvB,OAAc,KAATA,GAAwB,MAATA,IAAiBD,EAAO,GAC1CA,IACAN,EAAQc,QAAQP,GACT4C,GAEI,KAAT5C,GAAwB,IAATD,GACjBN,EAAQc,QAAQP,GACT6C,GAEFlD,EAAIK,EACb,EAYA,SAAS6C,EAAe7C,GAEtB,OAAgB,OAATA,EAAgBL,EAAIK,GAAQN,EAAGM,EACxC,CACF,EAzcE8C,SAAS,GAELC,EAAS,CACbvD,SAmdF,SAAwBC,EAASC,EAAIC,GAEnC,IAAIqD,EAEAC,EAEAC,EACJ,OAAOC,EAYP,SAASA,EAAanD,GAIpB,OAAa,KAATA,GAAwB,KAATA,EACVP,EAAQ2D,MAAMC,EAAOC,EAAaC,EAAlC9D,CAAuDO,GAUrD,OAATA,GACAoC,EAA0BpC,IAC1BsC,EAAkBtC,IACR,KAATA,GAAeqC,EAAmBrC,GAE5BsD,EAAYtD,IAErBkD,GAAO,EACPzD,EAAQc,QAAQP,GACTmD,EACT,CAYA,SAASI,EAAoBvD,GAY3B,OAVa,KAATA,EACFgD,GAA0B,GAK1BC,EAA8BD,EAC9BA,OAA0BQ,GAE5B/D,EAAQc,QAAQP,GACTmD,CACT,CAWA,SAASG,EAAYtD,GAGnB,OAAIiD,GAA+BD,IAA4BE,EACtDvD,EAAIK,GAENN,EAAGM,EACZ,CACF,EA1iBE8C,SAAS,GAELW,EAAO,CACXjE,SAojBF,SAAsBC,EAASC,GAC7B,IAAIgE,EAAW,EACXC,EAAY,EAChB,OAAOC,EAYP,SAASA,EAAW5D,GAClB,OAAa,KAATA,GACF0D,IACAjE,EAAQc,QAAQP,GACT4D,GAMI,KAAT5D,GAAe2D,EAAYD,EACtBG,EAAkB7D,GAOhB,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,MAATA,EAEOP,EAAQ2D,MAAMC,EAAO3D,EAAImE,EAAzBpE,CAA4CO,GAG1C,OAATA,GACAoC,EAA0BpC,IAC1BsC,EAAkBtC,GAEXN,EAAGM,IAEZP,EAAQc,QAAQP,GACT4D,EACT,CAYA,SAASC,EAAkB7D,GAMzB,OAJa,KAATA,GACF2D,IAEFlE,EAAQc,QAAQP,GACT4D,CACT,CACF,EAnoBEd,SAAS,GAELO,EAAQ,CACZ7D,SAipBF,SAAuBC,EAASC,EAAIC,GAClC,OAAO0D,EAYP,SAASA,EAAMrD,GAEb,OACW,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,MAATA,GAEAP,EAAQc,QAAQP,GACTqD,GAMI,KAATrD,GACFP,EAAQc,QAAQP,GACT8D,GAMI,KAAT9D,GACFP,EAAQc,QAAQP,GACT+D,GAIE,KAAT/D,GAES,OAATA,GACAoC,EAA0BpC,IAC1BsC,EAAkBtC,GAEXN,EAAGM,GAELL,EAAIK,EACb,CAeA,SAAS+D,EAAkB/D,GAGzB,OACW,OAATA,GACS,KAATA,GACS,KAATA,GACAoC,EAA0BpC,IAC1BsC,EAAkBtC,GAEXN,EAAGM,GAELqD,EAAMrD,EACf,CAYA,SAAS8D,EAAkB9D,GAEzB,OAAOiC,EAAWjC,GAAQgE,EAAmBhE,GAAQL,EAAIK,EAC3D,CAYA,SAASgE,EAAmBhE,GAE1B,OAAa,KAATA,GACFP,EAAQc,QAAQP,GACTqD,GAELpB,EAAWjC,IACbP,EAAQc,QAAQP,GACTgE,GAIFrE,EAAIK,EACb,CACF,EAhxBE8C,SAAS,GAELmB,EAAsB,CAC1BzE,SA8xBF,SAAqCC,EAASC,EAAIC,GAChD,OAYA,SAAeK,GAGb,OADAP,EAAQc,QAAQP,GACTU,CACT,EAYA,SAASA,EAAMV,GAEb,OAAOmC,EAAkBnC,GAAQL,EAAIK,GAAQN,EAAGM,EAClD,CACF,EA9zBE8C,SAAS,GAELoB,EAAc,CAClB1E,SA6MF,SAA6BC,EAASC,EAAIC,GACxC,MAAMwE,EAAOtE,KACb,OAYA,SAAkBG,GAChB,OACY,KAATA,GAAwB,MAATA,IACfoE,EAAYC,KAAKF,EAAMA,EAAKvE,WAC7B0E,EAAmBH,EAAKrE,QAEjBH,EAAIK,IAEbP,EAAQU,MAAM,mBACdV,EAAQU,MAAM,sBAGPV,EAAQ2D,MACbT,EACAlD,EAAQ8E,QAAQxB,EAAQtD,EAAQ8E,QAAQd,EAAMe,GAAW7E,GACzDA,EAHKF,CAILO,GACJ,EAYA,SAASwE,EAASxE,GAGhB,OAFAP,EAAQgB,KAAK,sBACbhB,EAAQgB,KAAK,mBACNf,EAAGM,EACZ,CACF,EA5PEJ,SAAUwE,GAENK,EAAmB,CACvBjF,SAsQF,SAAkCC,EAASC,EAAIC,GAC7C,MAAMwE,EAAOtE,KACb,IAAI6E,EAAS,GACTxB,GAAO,EACX,OAYA,SAAuBlD,GACrB,OACY,KAATA,GAAwB,MAATA,IAChB2E,EAAiBN,KAAKF,EAAMA,EAAKvE,WAChC0E,EAAmBH,EAAKrE,QAQpBH,EAAIK,IANTP,EAAQU,MAAM,mBACdV,EAAQU,MAAM,uBACduE,GAAUjC,OAAOmC,cAAc5E,GAC/BP,EAAQc,QAAQP,GACT6E,EAGX,EAYA,SAASA,EAAqB7E,GAE5B,GAAIiC,EAAWjC,IAAS0E,EAAOzE,OAAS,EAItC,OAFAyE,GAAUjC,OAAOmC,cAAc5E,GAC/BP,EAAQc,QAAQP,GACT6E,EAET,GAAa,KAAT7E,EAAa,CACf,MAAM8E,EAAWJ,EAAOK,cACxB,GAAiB,SAAbD,GAAoC,UAAbA,EAEzB,OADArF,EAAQc,QAAQP,GACTgF,CAEX,CACA,OAAOrF,EAAIK,EACb,CAYA,SAASgF,EAAsBhF,GAC7B,OAAa,KAATA,GACFP,EAAQc,QAAQP,GACZkD,EACK+B,GAET/B,GAAO,EACA8B,IAEFrF,EAAIK,EACb,CAYA,SAASiF,EAAcjF,GAGrB,OAAgB,OAATA,GDvUJ,SAAsBA,GAC3B,OAGW,OAATA,IAAkBA,EAAO,IAAe,MAATA,EAEnC,CCkUMkF,CAAalF,IACboC,EAA0BpC,IAC1BsC,EAAkBtC,IAClBqC,EAAmBrC,GACjBL,EAAIK,GACJP,EAAQ8E,QAAQxB,EAAQtD,EAAQ8E,QAAQd,EAAM0B,GAAgBxF,EAA9DF,CAAmEO,EACzE,CAYA,SAASmF,EAAcnF,GAGrB,OAFAP,EAAQgB,KAAK,uBACbhB,EAAQgB,KAAK,mBACNf,EAAGM,EACZ,CACF,EA3XEJ,SAAU+E,GAENS,EAAgB,CACpB5F,SAuDF,SAA+BC,EAASC,EAAIC,GAC1C,MAAMwE,EAAOtE,KAEb,IAAIwF,EAEAC,EACJ,OAYA,SAAetF,GACb,OACGuF,EAASvF,IACTwF,EAAcnB,KAAKF,EAAMA,EAAKvE,YAC/B0E,EAAmBH,EAAKrE,SAI1BL,EAAQU,MAAM,mBACdV,EAAQU,MAAM,wBACPsF,EAAMzF,IAJJL,EAAIK,EAKf,EAYA,SAASyF,EAAMzF,GACb,OAAIuF,EAASvF,IACXP,EAAQc,QAAQP,GACTyF,GAEI,KAATzF,GACFP,EAAQc,QAAQP,GACT0F,GAEF/F,EAAIK,EACb,CAgBA,SAAS0F,EAAY1F,GAEnB,OAAa,KAATA,EACKP,EAAQ2D,MACba,EACA0B,EACAC,EAHKnG,CAILO,GAIS,KAATA,GAAwB,KAATA,GAAemC,EAAkBnC,IAClDsF,GAAO,EACP7F,EAAQc,QAAQP,GACT0F,GASFC,EAAiB3F,EAC1B,CAYA,SAAS4F,EAAe5F,GAGtB,OAFAP,EAAQc,QAAQP,GAChBqF,GAAM,EACCK,CACT,CAYA,SAASC,EAAiB3F,GAGxB,OAAIsF,GAAQD,GAAOpD,EAAWkC,EAAKvE,WACjCH,EAAQgB,KAAK,wBACbhB,EAAQgB,KAAK,mBACNf,EAAGM,IAELL,EAAIK,EACb,CACF,EAvLEJ,SAAU4F,GAINhE,EAAO,CAAC,EAUDqE,EAAqB,CAChCrE,KAAIA,GAIN,IAAIxB,EAAO,GAGX,KAAOA,EAAO,KACZwB,EAAKxB,GAAQoF,EACbpF,IACa,KAATA,EAAaA,EAAO,GACN,KAATA,IAAaA,EAAO,IAgyB/B,SAASoE,EAAYpE,GACnB,OACW,OAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,MAATA,GACAoC,EAA0BpC,EAE9B,CAQA,SAAS2E,EAAiB3E,GACxB,OAAQiC,EAAWjC,EACrB,CAMA,SAASwF,EAAcxF,GAKrB,QAAkB,KAATA,GAAeuF,EAASvF,GACnC,CAMA,SAASuF,EAASvF,GAChB,OACW,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACAmC,EAAkBnC,EAEtB,CAMA,SAASsE,EAAmBxE,GAC1B,IAAIkB,EAAQlB,EAAOG,OACf6F,GAAS,EACb,KAAO9E,KAAS,CACd,MAAMR,EAAQV,EAAOkB,GAAO,GAC5B,IACkB,cAAfR,EAAMN,MAAuC,eAAfM,EAAMN,QACpCM,EAAMuF,UACP,CACAD,GAAS,EACT,KACF,CAIA,GAAItF,EAAMwF,8BAA+B,CACvCF,GAAS,EACT,KACF,CACF,CAMA,OALIhG,EAAOG,OAAS,IAAM6F,IAGxBhG,EAAOA,EAAOG,OAAS,GAAG,GAAG+F,+BAAgC,GAExDF,CACT,CA72BAtE,EAAK,IAAM4D,EACX5D,EAAK,IAAM4D,EACX5D,EAAK,IAAM4D,EACX5D,EAAK,IAAM4D,EACX5D,EAAK,IAAM,CAAC4D,EAAeX,GAC3BjD,EAAK,KAAO,CAAC4D,EAAeX,GAC5BjD,EAAK,IAAM,CAAC4D,EAAelB,GAC3B1C,EAAK,KAAO,CAAC4D,EAAelB,E,6DCyErB,SAAS9B,EAA0BpC,GACxC,OAAgB,OAATA,IAAkBA,EAAO,GAAc,KAATA,EACvC,CAwEA,SAASkC,EAAWK,GAClB,OAUA,SAAevC,GACb,OAAgB,OAATA,GAAiBuC,EAAMC,KAAKC,OAAOC,aAAa1C,GACzD,CACF,CA9N0BkC,EAAW,YAcJA,EAAW,cAuBlBA,EAAW,uBAgCXA,EAAW,MAoBRA,EAAW,cAeRA,EAAW,kBA0ETA,EC9LhC,wwCDoN+BA,EAAW,M,eEhN5C,MAAM+D,EAAS,CACbzG,SAkfF,SAAwBC,EAASC,EAAIC,GACnC,MAAMwE,EAAOtE,KACb,OAAOqG,EAAAA,EAAAA,GACLzG,GASF,SAAqBO,GACnB,MAAMmG,EAAOhC,EAAKrE,OAAOqE,EAAKrE,OAAOG,OAAS,GAC9C,OAAOkG,GACY,gCAAjBA,EAAK,GAAGjG,MACyC,IAAjDiG,EAAK,GAAGC,eAAeD,EAAK,IAAI,GAAMlG,OACpCP,EAAGM,GACHL,EAAIK,EACV,GAdE,8BACA,EAcJ,EArgBE8C,SAAS,GAgBJ,SAASuD,IAEd,MAAO,CACLC,SAAU,CACR,GAAM,CACJ9G,SAAU+G,EACVC,aAAc,CACZhH,SAAUiH,GAEZhG,KAAMiG,IAGVlF,KAAM,CACJ,GAAM,CACJhC,SAAUmH,GAEZ,GAAM,CACJC,IAAK,QACLpH,SAAUqH,EACVC,UAAWC,IAInB,CAOA,SAASF,EAAiCpH,EAASC,EAAIC,GACrD,MAAMwE,EAAOtE,KACb,IAAImB,EAAQmD,EAAKrE,OAAOG,OAGxB,MAAM+G,EAAU7C,EAAKxC,OAAOsF,eAAiB9C,EAAKxC,OAAOsF,aAAe,IAExE,IAAIC,EAGJ,KAAOlG,KAAS,CACd,MAAMR,EAAQ2D,EAAKrE,OAAOkB,GAAO,GACjC,GAAmB,eAAfR,EAAMN,KAAuB,CAC/BgH,EAAa1G,EACb,KACF,CAGA,GACiB,oBAAfA,EAAMN,MACS,cAAfM,EAAMN,MACS,UAAfM,EAAMN,MACS,UAAfM,EAAMN,MACS,SAAfM,EAAMN,KAEN,KAEJ,CACA,OAKA,SAAeF,GACb,IAAKkH,IAAeA,EAAWnB,UAC7B,OAAOpG,EAAIK,GAEb,MAAMmH,GAAKC,EAAAA,EAAAA,GACTjD,EAAKiC,eAAe,CAClBhF,MAAO8F,EAAWhG,IAClBA,IAAKiD,EAAKkD,SAGd,OAA0B,KAAtBF,EAAGG,YAAY,IAAcN,EAAQO,SAASJ,EAAGpF,MAAM,KAG3DtC,EAAQU,MAAM,8BACdV,EAAQc,QAAQP,GAChBP,EAAQgB,KAAK,8BACNf,EAAGM,IALDL,EAAIK,EAMf,CACF,CAIA,SAAS+G,EAAkCjH,EAAQiB,GACjD,IAEImG,EAFAlG,EAAQlB,EAAOG,OAKnB,KAAOe,KACL,GAC4B,eAA1BlB,EAAOkB,GAAO,GAAGd,MACI,UAArBJ,EAAOkB,GAAO,GACd,CACAkG,EAAapH,EAAOkB,GAAO,GAC3B,KACF,CAGFlB,EAAOkB,EAAQ,GAAG,GAAGd,KAAO,OAC5BJ,EAAOkB,EAAQ,GAAG,GAAGd,KAAO,6BAI5B,MAAMmE,EAAO,CACXnE,KAAM,kBACNkB,MAAOE,OAAOC,OAAO,CAAC,EAAGzB,EAAOkB,EAAQ,GAAG,GAAGI,OAC9CF,IAAKI,OAAOC,OAAO,CAAC,EAAGzB,EAAOA,EAAOG,OAAS,GAAG,GAAGiB,MAIhDsG,EAAS,CACbtH,KAAM,wBACNkB,MAAOE,OAAOC,OAAO,CAAC,EAAGzB,EAAOkB,EAAQ,GAAG,GAAGE,KAC9CA,IAAKI,OAAOC,OAAO,CAAC,EAAGzB,EAAOkB,EAAQ,GAAG,GAAGE,MAG9CsG,EAAOtG,IAAIuG,SACXD,EAAOtG,IAAIC,SACXqG,EAAOtG,IAAIwG,eAEX,MAAMC,EAAS,CACbzH,KAAM,wBACNkB,MAAOE,OAAOC,OAAO,CAAC,EAAGiG,EAAOtG,KAChCA,IAAKI,OAAOC,OAAO,CAAC,EAAGzB,EAAOA,EAAOG,OAAS,GAAG,GAAGmB,QAGhDwG,EAAQ,CACZ1H,KAAM,cACN2H,YAAa,SACbzG,MAAOE,OAAOC,OAAO,CAAC,EAAGoG,EAAOvG,OAChCF,IAAKI,OAAOC,OAAO,CAAC,EAAGoG,EAAOzG,MAI1B4G,EAAc,CAElBhI,EAAOkB,EAAQ,GACflB,EAAOkB,EAAQ,GACf,CAAC,QAASqD,EAAMtD,GAEhBjB,EAAOkB,EAAQ,GACflB,EAAOkB,EAAQ,GAEf,CAAC,QAASwG,EAAQzG,GAClB,CAAC,OAAQyG,EAAQzG,GAEjB,CAAC,QAAS4G,EAAQ5G,GAClB,CAAC,QAAS6G,EAAO7G,GACjB,CAAC,OAAQ6G,EAAO7G,GAChB,CAAC,OAAQ4G,EAAQ5G,GAEjBjB,EAAOA,EAAOG,OAAS,GACvBH,EAAOA,EAAOG,OAAS,GACvB,CAAC,OAAQoE,EAAMtD,IAGjB,OADAjB,EAAOgC,OAAOd,EAAOlB,EAAOG,OAASe,EAAQ,KAAM8G,GAC5ChI,CACT,CAMA,SAAS6G,EAAwBlH,EAASC,EAAIC,GAC5C,MAAMwE,EAAOtE,KAGPmH,EAAU7C,EAAKxC,OAAOsF,eAAiB9C,EAAKxC,OAAOsF,aAAe,IACxE,IAEI3B,EAFAvF,EAAO,EASX,OAYA,SAAeC,GAKb,OAJAP,EAAQU,MAAM,mBACdV,EAAQU,MAAM,8BACdV,EAAQc,QAAQP,GAChBP,EAAQgB,KAAK,8BACNsH,CACT,EAYA,SAASA,EAAU/H,GACjB,OAAa,KAATA,EAAoBL,EAAIK,IAC5BP,EAAQU,MAAM,yBACdV,EAAQc,QAAQP,GAChBP,EAAQgB,KAAK,yBACbhB,EAAQU,MAAM,yBACdV,EAAQU,MAAM,eAAe0H,YAAc,SACpCG,EACT,CAYA,SAASA,EAAShI,GAChB,GAEED,EAAO,KAEG,KAATC,IAAgBsF,GAGR,OAATtF,GACS,KAATA,GACAoC,EAA0BpC,GAE1B,OAAOL,EAAIK,GAEb,GAAa,KAATA,EAAa,CACfP,EAAQgB,KAAK,eACb,MAAMD,EAAQf,EAAQgB,KAAK,yBAC3B,OAAKuG,EAAQO,UAASH,EAAAA,EAAAA,GAAoBjD,EAAKiC,eAAe5F,MAG9Df,EAAQU,MAAM,8BACdV,EAAQc,QAAQP,GAChBP,EAAQgB,KAAK,8BACbhB,EAAQgB,KAAK,mBACNf,GANEC,EAAIK,EAOf,CAMA,OALKoC,EAA0BpC,KAC7BsF,GAAO,GAETvF,IACAN,EAAQc,QAAQP,GACA,KAATA,EAAciI,EAAaD,CACpC,CAYA,SAASC,EAAWjI,GAClB,OAAa,KAATA,GAAwB,KAATA,GAAwB,KAATA,GAChCP,EAAQc,QAAQP,GAChBD,IACOiI,GAEFA,EAAShI,EAClB,CACF,CAMA,SAASuG,EAAwB9G,EAASC,EAAIC,GAC5C,MAAMwE,EAAOtE,KAGPmH,EAAU7C,EAAKxC,OAAOsF,eAAiB9C,EAAKxC,OAAOsF,aAAe,IAExE,IAAIiB,EAGA5C,EAFAvF,EAAO,EAGX,OAYA,SAAeC,GAMb,OALAP,EAAQU,MAAM,yBAAyBgI,YAAa,EACpD1I,EAAQU,MAAM,8BACdV,EAAQU,MAAM,oCACdV,EAAQc,QAAQP,GAChBP,EAAQgB,KAAK,oCACN2H,CACT,EAYA,SAASA,EAAcpI,GACrB,OAAa,KAATA,GACFP,EAAQU,MAAM,+BACdV,EAAQc,QAAQP,GAChBP,EAAQgB,KAAK,+BACbhB,EAAQU,MAAM,oCACdV,EAAQU,MAAM,eAAe0H,YAAc,SACpCQ,GAEF1I,EAAIK,EACb,CAeA,SAASqI,EAAYrI,GACnB,GAEED,EAAO,KAEG,KAATC,IAAgBsF,GAGR,OAATtF,GACS,KAATA,GACAoC,EAA0BpC,GAE1B,OAAOL,EAAIK,GAEb,GAAa,KAATA,EAAa,CACfP,EAAQgB,KAAK,eACb,MAAMD,EAAQf,EAAQgB,KAAK,oCAM3B,OALAyH,GAAad,EAAAA,EAAAA,GAAoBjD,EAAKiC,eAAe5F,IACrDf,EAAQU,MAAM,oCACdV,EAAQc,QAAQP,GAChBP,EAAQgB,KAAK,oCACbhB,EAAQgB,KAAK,8BACN6H,CACT,CAMA,OALKlG,EAA0BpC,KAC7BsF,GAAO,GAETvF,IACAN,EAAQc,QAAQP,GACA,KAATA,EAAcuI,EAAcF,CACrC,CAeA,SAASE,EAAYvI,GACnB,OAAa,KAATA,GAAwB,KAATA,GAAwB,KAATA,GAChCP,EAAQc,QAAQP,GAChBD,IACOsI,GAEFA,EAAYrI,EACrB,CAYA,SAASsI,EAAWtI,GAClB,OAAa,KAATA,GACFP,EAAQU,MAAM,oBACdV,EAAQc,QAAQP,GAChBP,EAAQgB,KAAK,oBACRuG,EAAQO,SAASW,IACpBlB,EAAQwB,KAAKN,IAMRhC,EAAAA,EAAAA,GACLzG,EACAgJ,EACA,oCAGG9I,EAAIK,EACb,CAYA,SAASyI,EAAgBzI,GAEvB,OAAON,EAAGM,EACZ,CACF,CAMA,SAASyG,EAA+BhH,EAASC,EAAIC,GAUnD,OAAOF,EAAQ2D,MAAMsF,EAAAA,EAAWhJ,EAAID,EAAQ8E,QAAQ0B,EAAQvG,EAAIC,GAClE,CAGA,SAAS+G,EAAyBjH,GAChCA,EAAQgB,KAAK,wBACf,C","sources":["../node_modules/micromark-extension-gfm-strikethrough/lib/syntax.js","../node_modules/micromark-extension-gfm-autolink-literal/node_modules/micromark-util-character/lib/unicode-punctuation-regex.js","../node_modules/micromark-extension-gfm-autolink-literal/node_modules/micromark-util-character/index.js","../node_modules/micromark-extension-gfm-autolink-literal/lib/syntax.js","../node_modules/micromark-extension-gfm-footnote/node_modules/micromark-util-character/index.js","../node_modules/micromark-extension-gfm-footnote/node_modules/micromark-util-character/lib/unicode-punctuation-regex.js","../node_modules/micromark-extension-gfm-footnote/lib/syntax.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Extension} Extension\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n *\n * @typedef Options\n *   Configuration (optional).\n * @property {boolean} [singleTilde=true]\n *   Whether to support strikethrough with a single tilde.\n *\n *   Single tildes work on github.com, but are technically prohibited by the\n *   GFM spec.\n */\n\nimport {splice} from 'micromark-util-chunked'\nimport {classifyCharacter} from 'micromark-util-classify-character'\nimport {resolveAll} from 'micromark-util-resolve-all'\n/**\n * Create an extension for `micromark` to enable GFM strikethrough syntax.\n *\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {Extension}\n *   Extension for `micromark` that can be passed in `extensions`, to\n *   enable GFM strikethrough syntax.\n */\nexport function gfmStrikethrough(options) {\n  const options_ = options || {}\n  let single = options_.singleTilde\n  const tokenizer = {\n    tokenize: tokenizeStrikethrough,\n    resolveAll: resolveAllStrikethrough\n  }\n  if (single === null || single === undefined) {\n    single = true\n  }\n  return {\n    text: {\n      [126]: tokenizer\n    },\n    insideSpan: {\n      null: [tokenizer]\n    },\n    attentionMarkers: {\n      null: [126]\n    }\n  }\n\n  /**\n   * Take events and resolve strikethrough.\n   *\n   * @type {Resolver}\n   */\n  function resolveAllStrikethrough(events, context) {\n    let index = -1\n\n    // Walk through all events.\n    while (++index < events.length) {\n      // Find a token that can close.\n      if (\n        events[index][0] === 'enter' &&\n        events[index][1].type === 'strikethroughSequenceTemporary' &&\n        events[index][1]._close\n      ) {\n        let open = index\n\n        // Now walk back to find an opener.\n        while (open--) {\n          // Find a token that can open the closer.\n          if (\n            events[open][0] === 'exit' &&\n            events[open][1].type === 'strikethroughSequenceTemporary' &&\n            events[open][1]._open &&\n            // If the sizes are the same:\n            events[index][1].end.offset - events[index][1].start.offset ===\n              events[open][1].end.offset - events[open][1].start.offset\n          ) {\n            events[index][1].type = 'strikethroughSequence'\n            events[open][1].type = 'strikethroughSequence'\n\n            /** @type {Token} */\n            const strikethrough = {\n              type: 'strikethrough',\n              start: Object.assign({}, events[open][1].start),\n              end: Object.assign({}, events[index][1].end)\n            }\n\n            /** @type {Token} */\n            const text = {\n              type: 'strikethroughText',\n              start: Object.assign({}, events[open][1].end),\n              end: Object.assign({}, events[index][1].start)\n            }\n\n            // Opening.\n            /** @type {Array<Event>} */\n            const nextEvents = [\n              ['enter', strikethrough, context],\n              ['enter', events[open][1], context],\n              ['exit', events[open][1], context],\n              ['enter', text, context]\n            ]\n            const insideSpan = context.parser.constructs.insideSpan.null\n            if (insideSpan) {\n              // Between.\n              splice(\n                nextEvents,\n                nextEvents.length,\n                0,\n                resolveAll(insideSpan, events.slice(open + 1, index), context)\n              )\n            }\n\n            // Closing.\n            splice(nextEvents, nextEvents.length, 0, [\n              ['exit', text, context],\n              ['enter', events[index][1], context],\n              ['exit', events[index][1], context],\n              ['exit', strikethrough, context]\n            ])\n            splice(events, open - 1, index - open + 3, nextEvents)\n            index = open + nextEvents.length - 2\n            break\n          }\n        }\n      }\n    }\n    index = -1\n    while (++index < events.length) {\n      if (events[index][1].type === 'strikethroughSequenceTemporary') {\n        events[index][1].type = 'data'\n      }\n    }\n    return events\n  }\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Tokenizer}\n   */\n  function tokenizeStrikethrough(effects, ok, nok) {\n    const previous = this.previous\n    const events = this.events\n    let size = 0\n    return start\n\n    /** @type {State} */\n    function start(code) {\n      if (\n        previous === 126 &&\n        events[events.length - 1][1].type !== 'characterEscape'\n      ) {\n        return nok(code)\n      }\n      effects.enter('strikethroughSequenceTemporary')\n      return more(code)\n    }\n\n    /** @type {State} */\n    function more(code) {\n      const before = classifyCharacter(previous)\n      if (code === 126) {\n        // If this is the third marker, exit.\n        if (size > 1) return nok(code)\n        effects.consume(code)\n        size++\n        return more\n      }\n      if (size < 2 && !single) return nok(code)\n      const token = effects.exit('strikethroughSequenceTemporary')\n      const after = classifyCharacter(code)\n      token._open = !after || (after === 2 && Boolean(before))\n      token._close = !before || (before === 2 && Boolean(after))\n      return ok(code)\n    }\n  }\n}\n","// This module is generated by `script/`.\n//\n// CommonMark handles attention (emphasis, strong) markers based on what comes\n// before or after them.\n// One such difference is if those characters are Unicode punctuation.\n// This script is generated from the Unicode data.\n\n/**\n * Regular expression that matches a unicode punctuation character.\n */\nexport const unicodePunctuationRegex =\n  /[!-\\/:-@\\[-`\\{-~\\xA1\\xA7\\xAB\\xB6\\xB7\\xBB\\xBF\\u037E\\u0387\\u055A-\\u055F\\u0589\\u058A\\u05BE\\u05C0\\u05C3\\u05C6\\u05F3\\u05F4\\u0609\\u060A\\u060C\\u060D\\u061B\\u061D-\\u061F\\u066A-\\u066D\\u06D4\\u0700-\\u070D\\u07F7-\\u07F9\\u0830-\\u083E\\u085E\\u0964\\u0965\\u0970\\u09FD\\u0A76\\u0AF0\\u0C77\\u0C84\\u0DF4\\u0E4F\\u0E5A\\u0E5B\\u0F04-\\u0F12\\u0F14\\u0F3A-\\u0F3D\\u0F85\\u0FD0-\\u0FD4\\u0FD9\\u0FDA\\u104A-\\u104F\\u10FB\\u1360-\\u1368\\u1400\\u166E\\u169B\\u169C\\u16EB-\\u16ED\\u1735\\u1736\\u17D4-\\u17D6\\u17D8-\\u17DA\\u1800-\\u180A\\u1944\\u1945\\u1A1E\\u1A1F\\u1AA0-\\u1AA6\\u1AA8-\\u1AAD\\u1B5A-\\u1B60\\u1B7D\\u1B7E\\u1BFC-\\u1BFF\\u1C3B-\\u1C3F\\u1C7E\\u1C7F\\u1CC0-\\u1CC7\\u1CD3\\u2010-\\u2027\\u2030-\\u2043\\u2045-\\u2051\\u2053-\\u205E\\u207D\\u207E\\u208D\\u208E\\u2308-\\u230B\\u2329\\u232A\\u2768-\\u2775\\u27C5\\u27C6\\u27E6-\\u27EF\\u2983-\\u2998\\u29D8-\\u29DB\\u29FC\\u29FD\\u2CF9-\\u2CFC\\u2CFE\\u2CFF\\u2D70\\u2E00-\\u2E2E\\u2E30-\\u2E4F\\u2E52-\\u2E5D\\u3001-\\u3003\\u3008-\\u3011\\u3014-\\u301F\\u3030\\u303D\\u30A0\\u30FB\\uA4FE\\uA4FF\\uA60D-\\uA60F\\uA673\\uA67E\\uA6F2-\\uA6F7\\uA874-\\uA877\\uA8CE\\uA8CF\\uA8F8-\\uA8FA\\uA8FC\\uA92E\\uA92F\\uA95F\\uA9C1-\\uA9CD\\uA9DE\\uA9DF\\uAA5C-\\uAA5F\\uAADE\\uAADF\\uAAF0\\uAAF1\\uABEB\\uFD3E\\uFD3F\\uFE10-\\uFE19\\uFE30-\\uFE52\\uFE54-\\uFE61\\uFE63\\uFE68\\uFE6A\\uFE6B\\uFF01-\\uFF03\\uFF05-\\uFF0A\\uFF0C-\\uFF0F\\uFF1A\\uFF1B\\uFF1F\\uFF20\\uFF3B-\\uFF3D\\uFF3F\\uFF5B\\uFF5D\\uFF5F-\\uFF65]/\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n */\n\nimport {unicodePunctuationRegex} from './lib/unicode-punctuation-regex.js'\n\n/**\n * Check whether the character code represents an ASCII alpha (`a` through `z`,\n * case insensitive).\n *\n * An **ASCII alpha** is an ASCII upper alpha or ASCII lower alpha.\n *\n * An **ASCII upper alpha** is a character in the inclusive range U+0041 (`A`)\n * to U+005A (`Z`).\n *\n * An **ASCII lower alpha** is a character in the inclusive range U+0061 (`a`)\n * to U+007A (`z`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAlpha = regexCheck(/[A-Za-z]/)\n\n/**\n * Check whether the character code represents an ASCII alphanumeric (`a`\n * through `z`, case insensitive, or `0` through `9`).\n *\n * An **ASCII alphanumeric** is an ASCII digit (see `asciiDigit`) or ASCII alpha\n * (see `asciiAlpha`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAlphanumeric = regexCheck(/[\\dA-Za-z]/)\n\n/**\n * Check whether the character code represents an ASCII atext.\n *\n * atext is an ASCII alphanumeric (see `asciiAlphanumeric`), or a character in\n * the inclusive ranges U+0023 NUMBER SIGN (`#`) to U+0027 APOSTROPHE (`'`),\n * U+002A ASTERISK (`*`), U+002B PLUS SIGN (`+`), U+002D DASH (`-`), U+002F\n * SLASH (`/`), U+003D EQUALS TO (`=`), U+003F QUESTION MARK (`?`), U+005E\n * CARET (`^`) to U+0060 GRAVE ACCENT (`` ` ``), or U+007B LEFT CURLY BRACE\n * (`{`) to U+007E TILDE (`~`).\n *\n * See:\n * **\\[RFC5322]**:\n * [Internet Message Format](https://tools.ietf.org/html/rfc5322).\n * P. Resnick.\n * IETF.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAtext = regexCheck(/[#-'*+\\--9=?A-Z^-~]/)\n\n/**\n * Check whether a character code is an ASCII control character.\n *\n * An **ASCII control** is a character in the inclusive range U+0000 NULL (NUL)\n * to U+001F (US), or U+007F (DEL).\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function asciiControl(code) {\n  return (\n    // Special whitespace codes (which have negative values), C0 and Control\n    // character DEL\n    code !== null && (code < 32 || code === 127)\n  )\n}\n\n/**\n * Check whether the character code represents an ASCII digit (`0` through `9`).\n *\n * An **ASCII digit** is a character in the inclusive range U+0030 (`0`) to\n * U+0039 (`9`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiDigit = regexCheck(/\\d/)\n\n/**\n * Check whether the character code represents an ASCII hex digit (`a` through\n * `f`, case insensitive, or `0` through `9`).\n *\n * An **ASCII hex digit** is an ASCII digit (see `asciiDigit`), ASCII upper hex\n * digit, or an ASCII lower hex digit.\n *\n * An **ASCII upper hex digit** is a character in the inclusive range U+0041\n * (`A`) to U+0046 (`F`).\n *\n * An **ASCII lower hex digit** is a character in the inclusive range U+0061\n * (`a`) to U+0066 (`f`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiHexDigit = regexCheck(/[\\dA-Fa-f]/)\n\n/**\n * Check whether the character code represents ASCII punctuation.\n *\n * An **ASCII punctuation** is a character in the inclusive ranges U+0021\n * EXCLAMATION MARK (`!`) to U+002F SLASH (`/`), U+003A COLON (`:`) to U+0040 AT\n * SIGN (`@`), U+005B LEFT SQUARE BRACKET (`[`) to U+0060 GRAVE ACCENT\n * (`` ` ``), or U+007B LEFT CURLY BRACE (`{`) to U+007E TILDE (`~`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/)\n\n/**\n * Check whether a character code is a markdown line ending.\n *\n * A **markdown line ending** is the virtual characters M-0003 CARRIAGE RETURN\n * LINE FEED (CRLF), M-0004 LINE FEED (LF) and M-0005 CARRIAGE RETURN (CR).\n *\n * In micromark, the actual character U+000A LINE FEED (LF) and U+000D CARRIAGE\n * RETURN (CR) are replaced by these virtual characters depending on whether\n * they occurred together.\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownLineEnding(code) {\n  return code !== null && code < -2\n}\n\n/**\n * Check whether a character code is a markdown line ending (see\n * `markdownLineEnding`) or markdown space (see `markdownSpace`).\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownLineEndingOrSpace(code) {\n  return code !== null && (code < 0 || code === 32)\n}\n\n/**\n * Check whether a character code is a markdown space.\n *\n * A **markdown space** is the concrete character U+0020 SPACE (SP) and the\n * virtual characters M-0001 VIRTUAL SPACE (VS) and M-0002 HORIZONTAL TAB (HT).\n *\n * In micromark, the actual character U+0009 CHARACTER TABULATION (HT) is\n * replaced by one M-0002 HORIZONTAL TAB (HT) and between 0 and 3 M-0001 VIRTUAL\n * SPACE (VS) characters, depending on the column at which the tab occurred.\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownSpace(code) {\n  return code === -2 || code === -1 || code === 32\n}\n\n// Size note: removing ASCII from the regex and using `asciiPunctuation` here\n// In fact adds to the bundle size.\n/**\n * Check whether the character code represents Unicode punctuation.\n *\n * A **Unicode punctuation** is a character in the Unicode `Pc` (Punctuation,\n * Connector), `Pd` (Punctuation, Dash), `Pe` (Punctuation, Close), `Pf`\n * (Punctuation, Final quote), `Pi` (Punctuation, Initial quote), `Po`\n * (Punctuation, Other), or `Ps` (Punctuation, Open) categories, or an ASCII\n * punctuation (see `asciiPunctuation`).\n *\n * See:\n * **\\[UNICODE]**:\n * [The Unicode Standard](https://www.unicode.org/versions/).\n * Unicode Consortium.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const unicodePunctuation = regexCheck(unicodePunctuationRegex)\n\n/**\n * Check whether the character code represents Unicode whitespace.\n *\n * Note that this does handle micromark specific markdown whitespace characters.\n * See `markdownLineEndingOrSpace` to check that.\n *\n * A **Unicode whitespace** is a character in the Unicode `Zs` (Separator,\n * Space) category, or U+0009 CHARACTER TABULATION (HT), U+000A LINE FEED (LF),\n * U+000C (FF), or U+000D CARRIAGE RETURN (CR) (**\\[UNICODE]**).\n *\n * See:\n * **\\[UNICODE]**:\n * [The Unicode Standard](https://www.unicode.org/versions/).\n * Unicode Consortium.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const unicodeWhitespace = regexCheck(/\\s/)\n\n/**\n * Create a code check from a regex.\n *\n * @param {RegExp} regex\n * @returns {(code: Code) => boolean}\n */\nfunction regexCheck(regex) {\n  return check\n\n  /**\n   * Check whether a code matches the bound regex.\n   *\n   * @param {Code} code\n   *   Character code.\n   * @returns {boolean}\n   *   Whether the character code matches the bound regex.\n   */\n  function check(code) {\n    return code !== null && regex.test(String.fromCharCode(code))\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Extension} Extension\n * @typedef {import('micromark-util-types').Previous} Previous\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {\n  asciiAlpha,\n  asciiAlphanumeric,\n  asciiControl,\n  markdownLineEndingOrSpace,\n  unicodePunctuation,\n  unicodeWhitespace\n} from 'micromark-util-character'\nconst wwwPrefix = {\n  tokenize: tokenizeWwwPrefix,\n  partial: true\n}\nconst domain = {\n  tokenize: tokenizeDomain,\n  partial: true\n}\nconst path = {\n  tokenize: tokenizePath,\n  partial: true\n}\nconst trail = {\n  tokenize: tokenizeTrail,\n  partial: true\n}\nconst emailDomainDotTrail = {\n  tokenize: tokenizeEmailDomainDotTrail,\n  partial: true\n}\nconst wwwAutolink = {\n  tokenize: tokenizeWwwAutolink,\n  previous: previousWww\n}\nconst protocolAutolink = {\n  tokenize: tokenizeProtocolAutolink,\n  previous: previousProtocol\n}\nconst emailAutolink = {\n  tokenize: tokenizeEmailAutolink,\n  previous: previousEmail\n}\n\n/** @type {ConstructRecord} */\nconst text = {}\n\n// To do: next major: expose functions that yields extension.\n\n/**\n * Extension for `micromark` that can be passed in `extensions` to enable GFM\n * autolink literal syntax.\n *\n * @type {Extension}\n */\nexport const gfmAutolinkLiteral = {\n  text\n}\n\n/** @type {Code} */\nlet code = 48\n\n// Add alphanumerics.\nwhile (code < 123) {\n  text[code] = emailAutolink\n  code++\n  if (code === 58) code = 65\n  else if (code === 91) code = 97\n}\ntext[43] = emailAutolink\ntext[45] = emailAutolink\ntext[46] = emailAutolink\ntext[95] = emailAutolink\ntext[72] = [emailAutolink, protocolAutolink]\ntext[104] = [emailAutolink, protocolAutolink]\ntext[87] = [emailAutolink, wwwAutolink]\ntext[119] = [emailAutolink, wwwAutolink]\n\n// To do: perform email autolink literals on events, afterwards.\n// That’s where `markdown-rs` and `cmark-gfm` perform it.\n// It should look for `@`, then for atext backwards, and then for a label\n// forwards.\n// To do: `mailto:`, `xmpp:` protocol as prefix.\n\n/**\n * Email autolink literal.\n *\n * ```markdown\n * > | a contact@example.org b\n *       ^^^^^^^^^^^^^^^^^^^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeEmailAutolink(effects, ok, nok) {\n  const self = this\n  /** @type {boolean | undefined} */\n  let dot\n  /** @type {boolean} */\n  let data\n  return start\n\n  /**\n   * Start of email autolink literal.\n   *\n   * ```markdown\n   * > | a contact@example.org b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (\n      !gfmAtext(code) ||\n      !previousEmail.call(self, self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkEmail')\n    return atext(code)\n  }\n\n  /**\n   * In email atext.\n   *\n   * ```markdown\n   * > | a contact@example.org b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atext(code) {\n    if (gfmAtext(code)) {\n      effects.consume(code)\n      return atext\n    }\n    if (code === 64) {\n      effects.consume(code)\n      return emailDomain\n    }\n    return nok(code)\n  }\n\n  /**\n   * In email domain.\n   *\n   * The reference code is a bit overly complex as it handles the `@`, of which\n   * there may be just one.\n   * Source: <https://github.com/github/cmark-gfm/blob/ef1cfcb/extensions/autolink.c#L318>\n   *\n   * ```markdown\n   * > | a contact@example.org b\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailDomain(code) {\n    // Dot followed by alphanumerical (not `-` or `_`).\n    if (code === 46) {\n      return effects.check(\n        emailDomainDotTrail,\n        emailDomainAfter,\n        emailDomainDot\n      )(code)\n    }\n\n    // Alphanumerical, `-`, and `_`.\n    if (code === 45 || code === 95 || asciiAlphanumeric(code)) {\n      data = true\n      effects.consume(code)\n      return emailDomain\n    }\n\n    // To do: `/` if xmpp.\n\n    // Note: normally we’d truncate trailing punctuation from the link.\n    // However, email autolink literals cannot contain any of those markers,\n    // except for `.`, but that can only occur if it isn’t trailing.\n    // So we can ignore truncating!\n    return emailDomainAfter(code)\n  }\n\n  /**\n   * In email domain, on dot that is not a trail.\n   *\n   * ```markdown\n   * > | a contact@example.org b\n   *                      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailDomainDot(code) {\n    effects.consume(code)\n    dot = true\n    return emailDomain\n  }\n\n  /**\n   * After email domain.\n   *\n   * ```markdown\n   * > | a contact@example.org b\n   *                          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailDomainAfter(code) {\n    // Domain must not be empty, must include a dot, and must end in alphabetical.\n    // Source: <https://github.com/github/cmark-gfm/blob/ef1cfcb/extensions/autolink.c#L332>.\n    if (data && dot && asciiAlpha(self.previous)) {\n      effects.exit('literalAutolinkEmail')\n      effects.exit('literalAutolink')\n      return ok(code)\n    }\n    return nok(code)\n  }\n}\n\n/**\n * `www` autolink literal.\n *\n * ```markdown\n * > | a www.example.org b\n *       ^^^^^^^^^^^^^^^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeWwwAutolink(effects, ok, nok) {\n  const self = this\n  return wwwStart\n\n  /**\n   * Start of www autolink literal.\n   *\n   * ```markdown\n   * > | www.example.com/a?b#c\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function wwwStart(code) {\n    if (\n      (code !== 87 && code !== 119) ||\n      !previousWww.call(self, self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkWww')\n    // Note: we *check*, so we can discard the `www.` we parsed.\n    // If it worked, we consider it as a part of the domain.\n    return effects.check(\n      wwwPrefix,\n      effects.attempt(domain, effects.attempt(path, wwwAfter), nok),\n      nok\n    )(code)\n  }\n\n  /**\n   * After a www autolink literal.\n   *\n   * ```markdown\n   * > | www.example.com/a?b#c\n   *                          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function wwwAfter(code) {\n    effects.exit('literalAutolinkWww')\n    effects.exit('literalAutolink')\n    return ok(code)\n  }\n}\n\n/**\n * Protocol autolink literal.\n *\n * ```markdown\n * > | a https://example.org b\n *       ^^^^^^^^^^^^^^^^^^^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeProtocolAutolink(effects, ok, nok) {\n  const self = this\n  let buffer = ''\n  let seen = false\n  return protocolStart\n\n  /**\n   * Start of protocol autolink literal.\n   *\n   * ```markdown\n   * > | https://example.com/a?b#c\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function protocolStart(code) {\n    if (\n      (code === 72 || code === 104) &&\n      previousProtocol.call(self, self.previous) &&\n      !previousUnbalanced(self.events)\n    ) {\n      effects.enter('literalAutolink')\n      effects.enter('literalAutolinkHttp')\n      buffer += String.fromCodePoint(code)\n      effects.consume(code)\n      return protocolPrefixInside\n    }\n    return nok(code)\n  }\n\n  /**\n   * In protocol.\n   *\n   * ```markdown\n   * > | https://example.com/a?b#c\n   *     ^^^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function protocolPrefixInside(code) {\n    // `5` is size of `https`\n    if (asciiAlpha(code) && buffer.length < 5) {\n      // @ts-expect-error: definitely number.\n      buffer += String.fromCodePoint(code)\n      effects.consume(code)\n      return protocolPrefixInside\n    }\n    if (code === 58) {\n      const protocol = buffer.toLowerCase()\n      if (protocol === 'http' || protocol === 'https') {\n        effects.consume(code)\n        return protocolSlashesInside\n      }\n    }\n    return nok(code)\n  }\n\n  /**\n   * In slashes.\n   *\n   * ```markdown\n   * > | https://example.com/a?b#c\n   *           ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function protocolSlashesInside(code) {\n    if (code === 47) {\n      effects.consume(code)\n      if (seen) {\n        return afterProtocol\n      }\n      seen = true\n      return protocolSlashesInside\n    }\n    return nok(code)\n  }\n\n  /**\n   * After protocol, before domain.\n   *\n   * ```markdown\n   * > | https://example.com/a?b#c\n   *             ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterProtocol(code) {\n    // To do: this is different from `markdown-rs`:\n    // https://github.com/wooorm/markdown-rs/blob/b3a921c761309ae00a51fe348d8a43adbc54b518/src/construct/gfm_autolink_literal.rs#L172-L182\n    return code === null ||\n      asciiControl(code) ||\n      markdownLineEndingOrSpace(code) ||\n      unicodeWhitespace(code) ||\n      unicodePunctuation(code)\n      ? nok(code)\n      : effects.attempt(domain, effects.attempt(path, protocolAfter), nok)(code)\n  }\n\n  /**\n   * After a protocol autolink literal.\n   *\n   * ```markdown\n   * > | https://example.com/a?b#c\n   *                              ^\n   * ```\n   *\n   * @type {State}\n   */\n  function protocolAfter(code) {\n    effects.exit('literalAutolinkHttp')\n    effects.exit('literalAutolink')\n    return ok(code)\n  }\n}\n\n/**\n * `www` prefix.\n *\n * ```markdown\n * > | a www.example.org b\n *       ^^^^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeWwwPrefix(effects, ok, nok) {\n  let size = 0\n  return wwwPrefixInside\n\n  /**\n   * In www prefix.\n   *\n   * ```markdown\n   * > | www.example.com\n   *     ^^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function wwwPrefixInside(code) {\n    if ((code === 87 || code === 119) && size < 3) {\n      size++\n      effects.consume(code)\n      return wwwPrefixInside\n    }\n    if (code === 46 && size === 3) {\n      effects.consume(code)\n      return wwwPrefixAfter\n    }\n    return nok(code)\n  }\n\n  /**\n   * After www prefix.\n   *\n   * ```markdown\n   * > | www.example.com\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function wwwPrefixAfter(code) {\n    // If there is *anything*, we can link.\n    return code === null ? nok(code) : ok(code)\n  }\n}\n\n/**\n * Domain.\n *\n * ```markdown\n * > | a https://example.org b\n *               ^^^^^^^^^^^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeDomain(effects, ok, nok) {\n  /** @type {boolean | undefined} */\n  let underscoreInLastSegment\n  /** @type {boolean | undefined} */\n  let underscoreInLastLastSegment\n  /** @type {boolean | undefined} */\n  let seen\n  return domainInside\n\n  /**\n   * In domain.\n   *\n   * ```markdown\n   * > | https://example.com/a\n   *             ^^^^^^^^^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function domainInside(code) {\n    // Check whether this marker, which is a trailing punctuation\n    // marker, optionally followed by more trailing markers, and then\n    // followed by an end.\n    if (code === 46 || code === 95) {\n      return effects.check(trail, domainAfter, domainAtPunctuation)(code)\n    }\n\n    // GH documents that only alphanumerics (other than `-`, `.`, and `_`) can\n    // occur, which sounds like ASCII only, but they also support `www.點看.com`,\n    // so that’s Unicode.\n    // Instead of some new production for Unicode alphanumerics, markdown\n    // already has that for Unicode punctuation and whitespace, so use those.\n    // Source: <https://github.com/github/cmark-gfm/blob/ef1cfcb/extensions/autolink.c#L12>.\n    if (\n      code === null ||\n      markdownLineEndingOrSpace(code) ||\n      unicodeWhitespace(code) ||\n      (code !== 45 && unicodePunctuation(code))\n    ) {\n      return domainAfter(code)\n    }\n    seen = true\n    effects.consume(code)\n    return domainInside\n  }\n\n  /**\n   * In domain, at potential trailing punctuation, that was not trailing.\n   *\n   * ```markdown\n   * > | https://example.com\n   *                    ^\n   * ```\n   *\n   * @type {State}\n   */\n  function domainAtPunctuation(code) {\n    // There is an underscore in the last segment of the domain\n    if (code === 95) {\n      underscoreInLastSegment = true\n    }\n    // Otherwise, it’s a `.`: save the last segment underscore in the\n    // penultimate segment slot.\n    else {\n      underscoreInLastLastSegment = underscoreInLastSegment\n      underscoreInLastSegment = undefined\n    }\n    effects.consume(code)\n    return domainInside\n  }\n\n  /**\n   * After domain.\n   *\n   * ```markdown\n   * > | https://example.com/a\n   *                        ^\n   * ```\n   *\n   * @type {State} */\n  function domainAfter(code) {\n    // Note: that’s GH says a dot is needed, but it’s not true:\n    // <https://github.com/github/cmark-gfm/issues/279>\n    if (underscoreInLastLastSegment || underscoreInLastSegment || !seen) {\n      return nok(code)\n    }\n    return ok(code)\n  }\n}\n\n/**\n * Path.\n *\n * ```markdown\n * > | a https://example.org/stuff b\n *                          ^^^^^^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizePath(effects, ok) {\n  let sizeOpen = 0\n  let sizeClose = 0\n  return pathInside\n\n  /**\n   * In path.\n   *\n   * ```markdown\n   * > | https://example.com/a\n   *                        ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function pathInside(code) {\n    if (code === 40) {\n      sizeOpen++\n      effects.consume(code)\n      return pathInside\n    }\n\n    // To do: `markdown-rs` also needs this.\n    // If this is a paren, and there are less closings than openings,\n    // we don’t check for a trail.\n    if (code === 41 && sizeClose < sizeOpen) {\n      return pathAtPunctuation(code)\n    }\n\n    // Check whether this trailing punctuation marker is optionally\n    // followed by more trailing markers, and then followed\n    // by an end.\n    if (\n      code === 33 ||\n      code === 34 ||\n      code === 38 ||\n      code === 39 ||\n      code === 41 ||\n      code === 42 ||\n      code === 44 ||\n      code === 46 ||\n      code === 58 ||\n      code === 59 ||\n      code === 60 ||\n      code === 63 ||\n      code === 93 ||\n      code === 95 ||\n      code === 126\n    ) {\n      return effects.check(trail, ok, pathAtPunctuation)(code)\n    }\n    if (\n      code === null ||\n      markdownLineEndingOrSpace(code) ||\n      unicodeWhitespace(code)\n    ) {\n      return ok(code)\n    }\n    effects.consume(code)\n    return pathInside\n  }\n\n  /**\n   * In path, at potential trailing punctuation, that was not trailing.\n   *\n   * ```markdown\n   * > | https://example.com/a\"b\n   *                          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function pathAtPunctuation(code) {\n    // Count closing parens.\n    if (code === 41) {\n      sizeClose++\n    }\n    effects.consume(code)\n    return pathInside\n  }\n}\n\n/**\n * Trail.\n *\n * This calls `ok` if this *is* the trail, followed by an end, which means\n * the entire trail is not part of the link.\n * It calls `nok` if this *is* part of the link.\n *\n * ```markdown\n * > | https://example.com\").\n *                        ^^^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeTrail(effects, ok, nok) {\n  return trail\n\n  /**\n   * In trail of domain or path.\n   *\n   * ```markdown\n   * > | https://example.com\").\n   *                        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function trail(code) {\n    // Regular trailing punctuation.\n    if (\n      code === 33 ||\n      code === 34 ||\n      code === 39 ||\n      code === 41 ||\n      code === 42 ||\n      code === 44 ||\n      code === 46 ||\n      code === 58 ||\n      code === 59 ||\n      code === 63 ||\n      code === 95 ||\n      code === 126\n    ) {\n      effects.consume(code)\n      return trail\n    }\n\n    // `&` followed by one or more alphabeticals and then a `;`, is\n    // as a whole considered as trailing punctuation.\n    // In all other cases, it is considered as continuation of the URL.\n    if (code === 38) {\n      effects.consume(code)\n      return trailCharRefStart\n    }\n\n    // Needed because we allow literals after `[`, as we fix:\n    // <https://github.com/github/cmark-gfm/issues/278>.\n    // Check that it is not followed by `(` or `[`.\n    if (code === 93) {\n      effects.consume(code)\n      return trailBracketAfter\n    }\n    if (\n      // `<` is an end.\n      code === 60 ||\n      // So is whitespace.\n      code === null ||\n      markdownLineEndingOrSpace(code) ||\n      unicodeWhitespace(code)\n    ) {\n      return ok(code)\n    }\n    return nok(code)\n  }\n\n  /**\n   * In trail, after `]`.\n   *\n   * > 👉 **Note**: this deviates from `cmark-gfm` to fix a bug.\n   * > See end of <https://github.com/github/cmark-gfm/issues/278> for more.\n   *\n   * ```markdown\n   * > | https://example.com](\n   *                         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function trailBracketAfter(code) {\n    // Whitespace or something that could start a resource or reference is the end.\n    // Switch back to trail otherwise.\n    if (\n      code === null ||\n      code === 40 ||\n      code === 91 ||\n      markdownLineEndingOrSpace(code) ||\n      unicodeWhitespace(code)\n    ) {\n      return ok(code)\n    }\n    return trail(code)\n  }\n\n  /**\n   * In character-reference like trail, after `&`.\n   *\n   * ```markdown\n   * > | https://example.com&amp;).\n   *                         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function trailCharRefStart(code) {\n    // When non-alpha, it’s not a trail.\n    return asciiAlpha(code) ? trailCharRefInside(code) : nok(code)\n  }\n\n  /**\n   * In character-reference like trail.\n   *\n   * ```markdown\n   * > | https://example.com&amp;).\n   *                         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function trailCharRefInside(code) {\n    // Switch back to trail if this is well-formed.\n    if (code === 59) {\n      effects.consume(code)\n      return trail\n    }\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return trailCharRefInside\n    }\n\n    // It’s not a trail.\n    return nok(code)\n  }\n}\n\n/**\n * Dot in email domain trail.\n *\n * This calls `ok` if this *is* the trail, followed by an end, which means\n * the trail is not part of the link.\n * It calls `nok` if this *is* part of the link.\n *\n * ```markdown\n * > | contact@example.org.\n *                        ^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeEmailDomainDotTrail(effects, ok, nok) {\n  return start\n\n  /**\n   * Dot.\n   *\n   * ```markdown\n   * > | contact@example.org.\n   *                    ^   ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // Must be dot.\n    effects.consume(code)\n    return after\n  }\n\n  /**\n   * After dot.\n   *\n   * ```markdown\n   * > | contact@example.org.\n   *                     ^   ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    // Not a trail if alphanumeric.\n    return asciiAlphanumeric(code) ? nok(code) : ok(code)\n  }\n}\n\n/**\n * See:\n * <https://github.com/github/cmark-gfm/blob/ef1cfcb/extensions/autolink.c#L156>.\n *\n * @type {Previous}\n */\nfunction previousWww(code) {\n  return (\n    code === null ||\n    code === 40 ||\n    code === 42 ||\n    code === 95 ||\n    code === 91 ||\n    code === 93 ||\n    code === 126 ||\n    markdownLineEndingOrSpace(code)\n  )\n}\n\n/**\n * See:\n * <https://github.com/github/cmark-gfm/blob/ef1cfcb/extensions/autolink.c#L214>.\n *\n * @type {Previous}\n */\nfunction previousProtocol(code) {\n  return !asciiAlpha(code)\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Previous}\n */\nfunction previousEmail(code) {\n  // Do not allow a slash “inside” atext.\n  // The reference code is a bit weird, but that’s what it results in.\n  // Source: <https://github.com/github/cmark-gfm/blob/ef1cfcb/extensions/autolink.c#L307>.\n  // Other than slash, every preceding character is allowed.\n  return !(code === 47 || gfmAtext(code))\n}\n\n/**\n * @param {Code} code\n * @returns {boolean}\n */\nfunction gfmAtext(code) {\n  return (\n    code === 43 ||\n    code === 45 ||\n    code === 46 ||\n    code === 95 ||\n    asciiAlphanumeric(code)\n  )\n}\n\n/**\n * @param {Array<Event>} events\n * @returns {boolean}\n */\nfunction previousUnbalanced(events) {\n  let index = events.length\n  let result = false\n  while (index--) {\n    const token = events[index][1]\n    if (\n      (token.type === 'labelLink' || token.type === 'labelImage') &&\n      !token._balanced\n    ) {\n      result = true\n      break\n    }\n\n    // If we’ve seen this token, and it was marked as not having any unbalanced\n    // bracket before it, we can exit.\n    if (token._gfmAutolinkLiteralWalkedInto) {\n      result = false\n      break\n    }\n  }\n  if (events.length > 0 && !result) {\n    // Mark the last token as “walked into” w/o finding\n    // anything.\n    events[events.length - 1][1]._gfmAutolinkLiteralWalkedInto = true\n  }\n  return result\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n */\n\nimport {unicodePunctuationRegex} from './lib/unicode-punctuation-regex.js'\n\n/**\n * Check whether the character code represents an ASCII alpha (`a` through `z`,\n * case insensitive).\n *\n * An **ASCII alpha** is an ASCII upper alpha or ASCII lower alpha.\n *\n * An **ASCII upper alpha** is a character in the inclusive range U+0041 (`A`)\n * to U+005A (`Z`).\n *\n * An **ASCII lower alpha** is a character in the inclusive range U+0061 (`a`)\n * to U+007A (`z`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAlpha = regexCheck(/[A-Za-z]/)\n\n/**\n * Check whether the character code represents an ASCII alphanumeric (`a`\n * through `z`, case insensitive, or `0` through `9`).\n *\n * An **ASCII alphanumeric** is an ASCII digit (see `asciiDigit`) or ASCII alpha\n * (see `asciiAlpha`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAlphanumeric = regexCheck(/[\\dA-Za-z]/)\n\n/**\n * Check whether the character code represents an ASCII atext.\n *\n * atext is an ASCII alphanumeric (see `asciiAlphanumeric`), or a character in\n * the inclusive ranges U+0023 NUMBER SIGN (`#`) to U+0027 APOSTROPHE (`'`),\n * U+002A ASTERISK (`*`), U+002B PLUS SIGN (`+`), U+002D DASH (`-`), U+002F\n * SLASH (`/`), U+003D EQUALS TO (`=`), U+003F QUESTION MARK (`?`), U+005E\n * CARET (`^`) to U+0060 GRAVE ACCENT (`` ` ``), or U+007B LEFT CURLY BRACE\n * (`{`) to U+007E TILDE (`~`).\n *\n * See:\n * **\\[RFC5322]**:\n * [Internet Message Format](https://tools.ietf.org/html/rfc5322).\n * P. Resnick.\n * IETF.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAtext = regexCheck(/[#-'*+\\--9=?A-Z^-~]/)\n\n/**\n * Check whether a character code is an ASCII control character.\n *\n * An **ASCII control** is a character in the inclusive range U+0000 NULL (NUL)\n * to U+001F (US), or U+007F (DEL).\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function asciiControl(code) {\n  return (\n    // Special whitespace codes (which have negative values), C0 and Control\n    // character DEL\n    code !== null && (code < 32 || code === 127)\n  )\n}\n\n/**\n * Check whether the character code represents an ASCII digit (`0` through `9`).\n *\n * An **ASCII digit** is a character in the inclusive range U+0030 (`0`) to\n * U+0039 (`9`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiDigit = regexCheck(/\\d/)\n\n/**\n * Check whether the character code represents an ASCII hex digit (`a` through\n * `f`, case insensitive, or `0` through `9`).\n *\n * An **ASCII hex digit** is an ASCII digit (see `asciiDigit`), ASCII upper hex\n * digit, or an ASCII lower hex digit.\n *\n * An **ASCII upper hex digit** is a character in the inclusive range U+0041\n * (`A`) to U+0046 (`F`).\n *\n * An **ASCII lower hex digit** is a character in the inclusive range U+0061\n * (`a`) to U+0066 (`f`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiHexDigit = regexCheck(/[\\dA-Fa-f]/)\n\n/**\n * Check whether the character code represents ASCII punctuation.\n *\n * An **ASCII punctuation** is a character in the inclusive ranges U+0021\n * EXCLAMATION MARK (`!`) to U+002F SLASH (`/`), U+003A COLON (`:`) to U+0040 AT\n * SIGN (`@`), U+005B LEFT SQUARE BRACKET (`[`) to U+0060 GRAVE ACCENT\n * (`` ` ``), or U+007B LEFT CURLY BRACE (`{`) to U+007E TILDE (`~`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/)\n\n/**\n * Check whether a character code is a markdown line ending.\n *\n * A **markdown line ending** is the virtual characters M-0003 CARRIAGE RETURN\n * LINE FEED (CRLF), M-0004 LINE FEED (LF) and M-0005 CARRIAGE RETURN (CR).\n *\n * In micromark, the actual character U+000A LINE FEED (LF) and U+000D CARRIAGE\n * RETURN (CR) are replaced by these virtual characters depending on whether\n * they occurred together.\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownLineEnding(code) {\n  return code !== null && code < -2\n}\n\n/**\n * Check whether a character code is a markdown line ending (see\n * `markdownLineEnding`) or markdown space (see `markdownSpace`).\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownLineEndingOrSpace(code) {\n  return code !== null && (code < 0 || code === 32)\n}\n\n/**\n * Check whether a character code is a markdown space.\n *\n * A **markdown space** is the concrete character U+0020 SPACE (SP) and the\n * virtual characters M-0001 VIRTUAL SPACE (VS) and M-0002 HORIZONTAL TAB (HT).\n *\n * In micromark, the actual character U+0009 CHARACTER TABULATION (HT) is\n * replaced by one M-0002 HORIZONTAL TAB (HT) and between 0 and 3 M-0001 VIRTUAL\n * SPACE (VS) characters, depending on the column at which the tab occurred.\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownSpace(code) {\n  return code === -2 || code === -1 || code === 32\n}\n\n// Size note: removing ASCII from the regex and using `asciiPunctuation` here\n// In fact adds to the bundle size.\n/**\n * Check whether the character code represents Unicode punctuation.\n *\n * A **Unicode punctuation** is a character in the Unicode `Pc` (Punctuation,\n * Connector), `Pd` (Punctuation, Dash), `Pe` (Punctuation, Close), `Pf`\n * (Punctuation, Final quote), `Pi` (Punctuation, Initial quote), `Po`\n * (Punctuation, Other), or `Ps` (Punctuation, Open) categories, or an ASCII\n * punctuation (see `asciiPunctuation`).\n *\n * See:\n * **\\[UNICODE]**:\n * [The Unicode Standard](https://www.unicode.org/versions/).\n * Unicode Consortium.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const unicodePunctuation = regexCheck(unicodePunctuationRegex)\n\n/**\n * Check whether the character code represents Unicode whitespace.\n *\n * Note that this does handle micromark specific markdown whitespace characters.\n * See `markdownLineEndingOrSpace` to check that.\n *\n * A **Unicode whitespace** is a character in the Unicode `Zs` (Separator,\n * Space) category, or U+0009 CHARACTER TABULATION (HT), U+000A LINE FEED (LF),\n * U+000C (FF), or U+000D CARRIAGE RETURN (CR) (**\\[UNICODE]**).\n *\n * See:\n * **\\[UNICODE]**:\n * [The Unicode Standard](https://www.unicode.org/versions/).\n * Unicode Consortium.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const unicodeWhitespace = regexCheck(/\\s/)\n\n/**\n * Create a code check from a regex.\n *\n * @param {RegExp} regex\n * @returns {(code: Code) => boolean}\n */\nfunction regexCheck(regex) {\n  return check\n\n  /**\n   * Check whether a code matches the bound regex.\n   *\n   * @param {Code} code\n   *   Character code.\n   * @returns {boolean}\n   *   Whether the character code matches the bound regex.\n   */\n  function check(code) {\n    return code !== null && regex.test(String.fromCharCode(code))\n  }\n}\n","// This module is generated by `script/`.\n//\n// CommonMark handles attention (emphasis, strong) markers based on what comes\n// before or after them.\n// One such difference is if those characters are Unicode punctuation.\n// This script is generated from the Unicode data.\n\n/**\n * Regular expression that matches a unicode punctuation character.\n */\nexport const unicodePunctuationRegex =\n  /[!-\\/:-@\\[-`\\{-~\\xA1\\xA7\\xAB\\xB6\\xB7\\xBB\\xBF\\u037E\\u0387\\u055A-\\u055F\\u0589\\u058A\\u05BE\\u05C0\\u05C3\\u05C6\\u05F3\\u05F4\\u0609\\u060A\\u060C\\u060D\\u061B\\u061D-\\u061F\\u066A-\\u066D\\u06D4\\u0700-\\u070D\\u07F7-\\u07F9\\u0830-\\u083E\\u085E\\u0964\\u0965\\u0970\\u09FD\\u0A76\\u0AF0\\u0C77\\u0C84\\u0DF4\\u0E4F\\u0E5A\\u0E5B\\u0F04-\\u0F12\\u0F14\\u0F3A-\\u0F3D\\u0F85\\u0FD0-\\u0FD4\\u0FD9\\u0FDA\\u104A-\\u104F\\u10FB\\u1360-\\u1368\\u1400\\u166E\\u169B\\u169C\\u16EB-\\u16ED\\u1735\\u1736\\u17D4-\\u17D6\\u17D8-\\u17DA\\u1800-\\u180A\\u1944\\u1945\\u1A1E\\u1A1F\\u1AA0-\\u1AA6\\u1AA8-\\u1AAD\\u1B5A-\\u1B60\\u1B7D\\u1B7E\\u1BFC-\\u1BFF\\u1C3B-\\u1C3F\\u1C7E\\u1C7F\\u1CC0-\\u1CC7\\u1CD3\\u2010-\\u2027\\u2030-\\u2043\\u2045-\\u2051\\u2053-\\u205E\\u207D\\u207E\\u208D\\u208E\\u2308-\\u230B\\u2329\\u232A\\u2768-\\u2775\\u27C5\\u27C6\\u27E6-\\u27EF\\u2983-\\u2998\\u29D8-\\u29DB\\u29FC\\u29FD\\u2CF9-\\u2CFC\\u2CFE\\u2CFF\\u2D70\\u2E00-\\u2E2E\\u2E30-\\u2E4F\\u2E52-\\u2E5D\\u3001-\\u3003\\u3008-\\u3011\\u3014-\\u301F\\u3030\\u303D\\u30A0\\u30FB\\uA4FE\\uA4FF\\uA60D-\\uA60F\\uA673\\uA67E\\uA6F2-\\uA6F7\\uA874-\\uA877\\uA8CE\\uA8CF\\uA8F8-\\uA8FA\\uA8FC\\uA92E\\uA92F\\uA95F\\uA9C1-\\uA9CD\\uA9DE\\uA9DF\\uAA5C-\\uAA5F\\uAADE\\uAADF\\uAAF0\\uAAF1\\uABEB\\uFD3E\\uFD3F\\uFE10-\\uFE19\\uFE30-\\uFE52\\uFE54-\\uFE61\\uFE63\\uFE68\\uFE6A\\uFE6B\\uFF01-\\uFF03\\uFF05-\\uFF0A\\uFF0C-\\uFF0F\\uFF1A\\uFF1B\\uFF1F\\uFF20\\uFF3B-\\uFF3D\\uFF3F\\uFF5B\\uFF5D\\uFF5F-\\uFF65]/\n","/**\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Exiter} Exiter\n * @typedef {import('micromark-util-types').Extension} Extension\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {blankLine} from 'micromark-core-commonmark'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEndingOrSpace} from 'micromark-util-character'\nimport {normalizeIdentifier} from 'micromark-util-normalize-identifier'\nconst indent = {\n  tokenize: tokenizeIndent,\n  partial: true\n}\n\n// To do: micromark should support a `_hiddenGfmFootnoteSupport`, which only\n// affects label start (image).\n// That will let us drop `tokenizePotentialGfmFootnote*`.\n// It currently has a `_hiddenFootnoteSupport`, which affects that and more.\n// That can be removed when `micromark-extension-footnote` is archived.\n\n/**\n * Create an extension for `micromark` to enable GFM footnote syntax.\n *\n * @returns {Extension}\n *   Extension for `micromark` that can be passed in `extensions` to\n *   enable GFM footnote syntax.\n */\nexport function gfmFootnote() {\n  /** @type {Extension} */\n  return {\n    document: {\n      [91]: {\n        tokenize: tokenizeDefinitionStart,\n        continuation: {\n          tokenize: tokenizeDefinitionContinuation\n        },\n        exit: gfmFootnoteDefinitionEnd\n      }\n    },\n    text: {\n      [91]: {\n        tokenize: tokenizeGfmFootnoteCall\n      },\n      [93]: {\n        add: 'after',\n        tokenize: tokenizePotentialGfmFootnoteCall,\n        resolveTo: resolveToPotentialGfmFootnoteCall\n      }\n    }\n  }\n}\n\n// To do: remove after micromark update.\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizePotentialGfmFootnoteCall(effects, ok, nok) {\n  const self = this\n  let index = self.events.length\n  /** @type {Array<string>} */\n  // @ts-expect-error It’s fine!\n  const defined = self.parser.gfmFootnotes || (self.parser.gfmFootnotes = [])\n  /** @type {Token} */\n  let labelStart\n\n  // Find an opening.\n  while (index--) {\n    const token = self.events[index][1]\n    if (token.type === 'labelImage') {\n      labelStart = token\n      break\n    }\n\n    // Exit if we’ve walked far enough.\n    if (\n      token.type === 'gfmFootnoteCall' ||\n      token.type === 'labelLink' ||\n      token.type === 'label' ||\n      token.type === 'image' ||\n      token.type === 'link'\n    ) {\n      break\n    }\n  }\n  return start\n\n  /**\n   * @type {State}\n   */\n  function start(code) {\n    if (!labelStart || !labelStart._balanced) {\n      return nok(code)\n    }\n    const id = normalizeIdentifier(\n      self.sliceSerialize({\n        start: labelStart.end,\n        end: self.now()\n      })\n    )\n    if (id.codePointAt(0) !== 94 || !defined.includes(id.slice(1))) {\n      return nok(code)\n    }\n    effects.enter('gfmFootnoteCallLabelMarker')\n    effects.consume(code)\n    effects.exit('gfmFootnoteCallLabelMarker')\n    return ok(code)\n  }\n}\n\n// To do: remove after micromark update.\n/** @type {Resolver} */\nfunction resolveToPotentialGfmFootnoteCall(events, context) {\n  let index = events.length\n  /** @type {Token | undefined} */\n  let labelStart\n\n  // Find an opening.\n  while (index--) {\n    if (\n      events[index][1].type === 'labelImage' &&\n      events[index][0] === 'enter'\n    ) {\n      labelStart = events[index][1]\n      break\n    }\n  }\n  // Change the `labelImageMarker` to a `data`.\n  events[index + 1][1].type = 'data'\n  events[index + 3][1].type = 'gfmFootnoteCallLabelMarker'\n\n  // The whole (without `!`):\n  /** @type {Token} */\n  const call = {\n    type: 'gfmFootnoteCall',\n    start: Object.assign({}, events[index + 3][1].start),\n    end: Object.assign({}, events[events.length - 1][1].end)\n  }\n  // The `^` marker\n  /** @type {Token} */\n  const marker = {\n    type: 'gfmFootnoteCallMarker',\n    start: Object.assign({}, events[index + 3][1].end),\n    end: Object.assign({}, events[index + 3][1].end)\n  }\n  // Increment the end 1 character.\n  marker.end.column++\n  marker.end.offset++\n  marker.end._bufferIndex++\n  /** @type {Token} */\n  const string = {\n    type: 'gfmFootnoteCallString',\n    start: Object.assign({}, marker.end),\n    end: Object.assign({}, events[events.length - 1][1].start)\n  }\n  /** @type {Token} */\n  const chunk = {\n    type: 'chunkString',\n    contentType: 'string',\n    start: Object.assign({}, string.start),\n    end: Object.assign({}, string.end)\n  }\n\n  /** @type {Array<Event>} */\n  const replacement = [\n    // Take the `labelImageMarker` (now `data`, the `!`)\n    events[index + 1],\n    events[index + 2],\n    ['enter', call, context],\n    // The `[`\n    events[index + 3],\n    events[index + 4],\n    // The `^`.\n    ['enter', marker, context],\n    ['exit', marker, context],\n    // Everything in between.\n    ['enter', string, context],\n    ['enter', chunk, context],\n    ['exit', chunk, context],\n    ['exit', string, context],\n    // The ending (`]`, properly parsed and labelled).\n    events[events.length - 2],\n    events[events.length - 1],\n    ['exit', call, context]\n  ]\n  events.splice(index, events.length - index + 1, ...replacement)\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeGfmFootnoteCall(effects, ok, nok) {\n  const self = this\n  /** @type {Array<string>} */\n  // @ts-expect-error It’s fine!\n  const defined = self.parser.gfmFootnotes || (self.parser.gfmFootnotes = [])\n  let size = 0\n  /** @type {boolean} */\n  let data\n\n  // Note: the implementation of `markdown-rs` is different, because it houses\n  // core *and* extensions in one project.\n  // Therefore, it can include footnote logic inside `label-end`.\n  // We can’t do that, but luckily, we can parse footnotes in a simpler way than\n  // needed for labels.\n  return start\n\n  /**\n   * Start of footnote label.\n   *\n   * ```markdown\n   * > | a [^b] c\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('gfmFootnoteCall')\n    effects.enter('gfmFootnoteCallLabelMarker')\n    effects.consume(code)\n    effects.exit('gfmFootnoteCallLabelMarker')\n    return callStart\n  }\n\n  /**\n   * After `[`, at `^`.\n   *\n   * ```markdown\n   * > | a [^b] c\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function callStart(code) {\n    if (code !== 94) return nok(code)\n    effects.enter('gfmFootnoteCallMarker')\n    effects.consume(code)\n    effects.exit('gfmFootnoteCallMarker')\n    effects.enter('gfmFootnoteCallString')\n    effects.enter('chunkString').contentType = 'string'\n    return callData\n  }\n\n  /**\n   * In label.\n   *\n   * ```markdown\n   * > | a [^b] c\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function callData(code) {\n    if (\n      // Too long.\n      size > 999 ||\n      // Closing brace with nothing.\n      (code === 93 && !data) ||\n      // Space or tab is not supported by GFM for some reason.\n      // `\\n` and `[` not being supported makes sense.\n      code === null ||\n      code === 91 ||\n      markdownLineEndingOrSpace(code)\n    ) {\n      return nok(code)\n    }\n    if (code === 93) {\n      effects.exit('chunkString')\n      const token = effects.exit('gfmFootnoteCallString')\n      if (!defined.includes(normalizeIdentifier(self.sliceSerialize(token)))) {\n        return nok(code)\n      }\n      effects.enter('gfmFootnoteCallLabelMarker')\n      effects.consume(code)\n      effects.exit('gfmFootnoteCallLabelMarker')\n      effects.exit('gfmFootnoteCall')\n      return ok\n    }\n    if (!markdownLineEndingOrSpace(code)) {\n      data = true\n    }\n    size++\n    effects.consume(code)\n    return code === 92 ? callEscape : callData\n  }\n\n  /**\n   * On character after escape.\n   *\n   * ```markdown\n   * > | a [^b\\c] d\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function callEscape(code) {\n    if (code === 91 || code === 92 || code === 93) {\n      effects.consume(code)\n      size++\n      return callData\n    }\n    return callData(code)\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeDefinitionStart(effects, ok, nok) {\n  const self = this\n  /** @type {Array<string>} */\n  // @ts-expect-error It’s fine!\n  const defined = self.parser.gfmFootnotes || (self.parser.gfmFootnotes = [])\n  /** @type {string} */\n  let identifier\n  let size = 0\n  /** @type {boolean | undefined} */\n  let data\n  return start\n\n  /**\n   * Start of GFM footnote definition.\n   *\n   * ```markdown\n   * > | [^a]: b\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('gfmFootnoteDefinition')._container = true\n    effects.enter('gfmFootnoteDefinitionLabel')\n    effects.enter('gfmFootnoteDefinitionLabelMarker')\n    effects.consume(code)\n    effects.exit('gfmFootnoteDefinitionLabelMarker')\n    return labelAtMarker\n  }\n\n  /**\n   * In label, at caret.\n   *\n   * ```markdown\n   * > | [^a]: b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelAtMarker(code) {\n    if (code === 94) {\n      effects.enter('gfmFootnoteDefinitionMarker')\n      effects.consume(code)\n      effects.exit('gfmFootnoteDefinitionMarker')\n      effects.enter('gfmFootnoteDefinitionLabelString')\n      effects.enter('chunkString').contentType = 'string'\n      return labelInside\n    }\n    return nok(code)\n  }\n\n  /**\n   * In label.\n   *\n   * > 👉 **Note**: `cmark-gfm` prevents whitespace from occurring in footnote\n   * > definition labels.\n   *\n   * ```markdown\n   * > | [^a]: b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelInside(code) {\n    if (\n      // Too long.\n      size > 999 ||\n      // Closing brace with nothing.\n      (code === 93 && !data) ||\n      // Space or tab is not supported by GFM for some reason.\n      // `\\n` and `[` not being supported makes sense.\n      code === null ||\n      code === 91 ||\n      markdownLineEndingOrSpace(code)\n    ) {\n      return nok(code)\n    }\n    if (code === 93) {\n      effects.exit('chunkString')\n      const token = effects.exit('gfmFootnoteDefinitionLabelString')\n      identifier = normalizeIdentifier(self.sliceSerialize(token))\n      effects.enter('gfmFootnoteDefinitionLabelMarker')\n      effects.consume(code)\n      effects.exit('gfmFootnoteDefinitionLabelMarker')\n      effects.exit('gfmFootnoteDefinitionLabel')\n      return labelAfter\n    }\n    if (!markdownLineEndingOrSpace(code)) {\n      data = true\n    }\n    size++\n    effects.consume(code)\n    return code === 92 ? labelEscape : labelInside\n  }\n\n  /**\n   * After `\\`, at a special character.\n   *\n   * > 👉 **Note**: `cmark-gfm` currently does not support escaped brackets:\n   * > <https://github.com/github/cmark-gfm/issues/240>\n   *\n   * ```markdown\n   * > | [^a\\*b]: c\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelEscape(code) {\n    if (code === 91 || code === 92 || code === 93) {\n      effects.consume(code)\n      size++\n      return labelInside\n    }\n    return labelInside(code)\n  }\n\n  /**\n   * After definition label.\n   *\n   * ```markdown\n   * > | [^a]: b\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelAfter(code) {\n    if (code === 58) {\n      effects.enter('definitionMarker')\n      effects.consume(code)\n      effects.exit('definitionMarker')\n      if (!defined.includes(identifier)) {\n        defined.push(identifier)\n      }\n\n      // Any whitespace after the marker is eaten, forming indented code\n      // is not possible.\n      // No space is also fine, just like a block quote marker.\n      return factorySpace(\n        effects,\n        whitespaceAfter,\n        'gfmFootnoteDefinitionWhitespace'\n      )\n    }\n    return nok(code)\n  }\n\n  /**\n   * After definition prefix.\n   *\n   * ```markdown\n   * > | [^a]: b\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function whitespaceAfter(code) {\n    // `markdown-rs` has a wrapping token for the prefix that is closed here.\n    return ok(code)\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeDefinitionContinuation(effects, ok, nok) {\n  /// Start of footnote definition continuation.\n  ///\n  /// ```markdown\n  ///   | [^a]: b\n  /// > |     c\n  ///     ^\n  /// ```\n  //\n  // Either a blank line, which is okay, or an indented thing.\n  return effects.check(blankLine, ok, effects.attempt(indent, ok, nok))\n}\n\n/** @type {Exiter} */\nfunction gfmFootnoteDefinitionEnd(effects) {\n  effects.exit('gfmFootnoteDefinition')\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeIndent(effects, ok, nok) {\n  const self = this\n  return factorySpace(\n    effects,\n    afterPrefix,\n    'gfmFootnoteDefinitionIndent',\n    4 + 1\n  )\n\n  /**\n   * @type {State}\n   */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1]\n    return tail &&\n      tail[1].type === 'gfmFootnoteDefinitionIndent' &&\n      tail[2].sliceSerialize(tail[1], true).length === 4\n      ? ok(code)\n      : nok(code)\n  }\n}\n"],"names":["gfmStrikethrough","options","single","singleTilde","tokenizer","tokenize","effects","ok","nok","previous","this","events","size","code","length","type","enter","more","before","classifyCharacter","consume","token","exit","after","_open","Boolean","_close","resolveAll","context","index","open","end","offset","start","strikethrough","Object","assign","text","nextEvents","insideSpan","parser","constructs","null","splice","slice","attentionMarkers","asciiAlpha","regexCheck","asciiAlphanumeric","markdownLineEndingOrSpace","unicodePunctuation","unicodeWhitespace","regex","test","String","fromCharCode","wwwPrefix","wwwPrefixInside","wwwPrefixAfter","partial","domain","underscoreInLastSegment","underscoreInLastLastSegment","seen","domainInside","check","trail","domainAfter","domainAtPunctuation","undefined","path","sizeOpen","sizeClose","pathInside","pathAtPunctuation","trailCharRefStart","trailBracketAfter","trailCharRefInside","emailDomainDotTrail","wwwAutolink","self","previousWww","call","previousUnbalanced","attempt","wwwAfter","protocolAutolink","buffer","previousProtocol","fromCodePoint","protocolPrefixInside","protocol","toLowerCase","protocolSlashesInside","afterProtocol","asciiControl","protocolAfter","emailAutolink","dot","data","gfmAtext","previousEmail","atext","emailDomain","emailDomainAfter","emailDomainDot","gfmAutolinkLiteral","result","_balanced","_gfmAutolinkLiteralWalkedInto","indent","factorySpace","tail","sliceSerialize","gfmFootnote","document","tokenizeDefinitionStart","continuation","tokenizeDefinitionContinuation","gfmFootnoteDefinitionEnd","tokenizeGfmFootnoteCall","add","tokenizePotentialGfmFootnoteCall","resolveTo","resolveToPotentialGfmFootnoteCall","defined","gfmFootnotes","labelStart","id","normalizeIdentifier","now","codePointAt","includes","marker","column","_bufferIndex","string","chunk","contentType","replacement","callStart","callData","callEscape","identifier","_container","labelAtMarker","labelInside","labelAfter","labelEscape","push","whitespaceAfter","blankLine"],"sourceRoot":""}