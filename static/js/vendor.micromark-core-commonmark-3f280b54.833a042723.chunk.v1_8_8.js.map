{"version":3,"file":"static/js/vendor.micromark-core-commonmark-3f280b54.833a042723.chunk.v1_8_8.js","mappings":"kKAWA,MAAMA,EAAsB,CAC1BC,SAwbF,SAAqCC,EAASC,EAAIC,GAChD,MAAMC,EAAOC,KACb,OAOA,SAAeC,GACb,GAAa,OAATA,EACF,OAAOH,EAAIG,GAKb,OAHAL,EAAQM,MAAM,cACdN,EAAQO,QAAQF,GAChBL,EAAQQ,KAAK,cACNC,CACT,EAOA,SAASA,EAAUJ,GACjB,OAAOF,EAAKO,OAAOC,KAAKR,EAAKS,MAAMC,MAAQX,EAAIG,GAAQJ,EAAGI,EAC5D,CACF,EAldES,SAAS,GAIEC,EAAa,CACxBC,KAAM,aACNjB,SAQF,SAA4BC,EAASC,EAAIC,GACvC,MAAMC,EAAOC,KAEPa,EAAa,CACjBlB,SA+SF,SAA4BC,EAASC,EAAIC,GACvC,IAAIgB,EAAO,EACX,OAAOC,EAOP,SAASA,EAAYd,GAInB,OAHAL,EAAQM,MAAM,cACdN,EAAQO,QAAQF,GAChBL,EAAQQ,KAAK,cACNY,CACT,CAcA,SAASA,EAAMf,GAKb,OADAL,EAAQM,MAAM,oBACPe,EAAAA,EAAAA,IAAchB,IACjBiB,EAAAA,EAAAA,GACEtB,EACAuB,EACA,aACApB,EAAKO,OAAOc,WAAWC,QAAQC,KAAKC,SAAS,qBACzCC,EACA,EANNN,CAOEjB,GACFkB,EAAoBlB,EAC1B,CAcA,SAASkB,EAAoBlB,GAC3B,OAAIA,IAASwB,GACX7B,EAAQM,MAAM,2BACPwB,EAAczB,IAEhBH,EAAIG,EACb,CAcA,SAASyB,EAAczB,GACrB,OAAIA,IAASwB,GACXX,IACAlB,EAAQO,QAAQF,GACTyB,GAELZ,GAAQa,GACV/B,EAAQQ,KAAK,4BACNa,EAAAA,EAAAA,IAAchB,IACjBiB,EAAAA,EAAAA,GAAatB,EAASgC,EAAoB,aAA1CV,CAAwDjB,GACxD2B,EAAmB3B,IAElBH,EAAIG,EACb,CAcA,SAAS2B,EAAmB3B,GAC1B,OAAa,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,IACtCL,EAAQQ,KAAK,mBACNP,EAAGI,IAELH,EAAIG,EACb,CACF,EA7ZES,SAAS,GAEX,IAGIe,EAHAK,EAAgB,EAChBH,EAAW,EAGf,OAcA,SAAe1B,GAEb,OAeF,SAA4BA,GAC1B,MAAM8B,EAAOhC,EAAKiC,OAAOjC,EAAKiC,OAAOC,OAAS,GAS9C,OARAH,EACEC,GAAyB,eAAjBA,EAAK,GAAGG,KACZH,EAAK,GAAGI,eAAeJ,EAAK,IAAI,GAAME,OACtC,EACNR,EAASxB,EACTL,EAAQM,MAAM,cACdN,EAAQM,MAAM,mBACdN,EAAQM,MAAM,2BACPkC,EAAanC,EACtB,CA1BSoC,CAAmBpC,EAC5B,EAuCA,SAASmC,EAAanC,GACpB,OAAIA,IAASwB,GACXE,IACA/B,EAAQO,QAAQF,GACTmC,GAELT,EAAW,EACN7B,EAAIG,IAEbL,EAAQQ,KAAK,4BACNa,EAAAA,EAAAA,IAAchB,IACjBiB,EAAAA,EAAAA,GAAatB,EAAS0C,EAAY,aAAlCpB,CAAgDjB,GAChDqC,EAAWrC,GACjB,CAcA,SAASqC,EAAWrC,GAClB,OAAa,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,IACtCL,EAAQQ,KAAK,mBACNL,EAAKwC,UACR1C,EAAGI,GACHL,EAAQ4C,MAAM9C,EAAqB+C,EAAgBC,EAAnD9C,CAA0DK,KAEhEL,EAAQM,MAAM,uBACdN,EAAQM,MAAM,cAAe,CAC3ByC,YAAa,WAERC,EAAK3C,GACd,CAcA,SAAS2C,EAAK3C,GACZ,OAAa,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,IACtCL,EAAQQ,KAAK,eACbR,EAAQQ,KAAK,uBACNkC,EAAWrC,KAEhBgB,EAAAA,EAAAA,IAAchB,IAChBL,EAAQQ,KAAK,eACbR,EAAQQ,KAAK,wBACNc,EAAAA,EAAAA,GAAatB,EAASiD,EAAY,aAAlC3B,CAAgDjB,IAE5C,KAATA,GAAeA,IAASwB,EACnB3B,EAAIG,IAEbL,EAAQO,QAAQF,GACT2C,EACT,CAcA,SAASC,EAAW5C,GAClB,OAAa,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,GAC/BqC,EAAWrC,IAEpBL,EAAQM,MAAM,uBACdN,EAAQM,MAAM,cAAe,CAC3ByC,YAAa,WAERG,EAAK7C,GACd,CAcA,SAAS6C,EAAK7C,GACZ,OAAa,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,IACtCL,EAAQQ,KAAK,eACbR,EAAQQ,KAAK,uBACNkC,EAAWrC,IAEP,KAATA,GAAeA,IAASwB,EACnB3B,EAAIG,IAEbL,EAAQO,QAAQF,GACT6C,EACT,CAeA,SAASL,EAAexC,GACtB,OAAOL,EAAQmD,QAAQlC,EAAY6B,EAAOM,EAAnCpD,CAAkDK,EAC3D,CAcA,SAAS+C,EAAc/C,GAIrB,OAHAL,EAAQM,MAAM,cACdN,EAAQO,QAAQF,GAChBL,EAAQQ,KAAK,cACN6C,CACT,CAcA,SAASA,EAAahD,GACpB,OAAO6B,EAAgB,IAAKb,EAAAA,EAAAA,IAAchB,IACtCiB,EAAAA,EAAAA,GACEtB,EACAsD,EACA,aACApB,EAAgB,EAJlBZ,CAKEjB,GACFiD,EAAmBjD,EACzB,CAcA,SAASiD,EAAmBjD,GAC1B,OAAa,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,GAC/BL,EAAQ4C,MAAM9C,EAAqB+C,EAAgBC,EAAnD9C,CAA0DK,IAEnEL,EAAQM,MAAM,iBACPiD,EAAalD,GACtB,CAcA,SAASkD,EAAalD,GACpB,OAAa,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,IACtCL,EAAQQ,KAAK,iBACN8C,EAAmBjD,KAE5BL,EAAQO,QAAQF,GACTkD,EACT,CAcA,SAAST,EAAMzC,GAEb,OADAL,EAAQQ,KAAK,cACNP,EAAGI,EACZ,CAsHF,EA1aEmD,UAAU,E,kDCXL,MAAMC,EAAkB,CAC7BzC,KAAM,kBACNjB,SAOF,SAAiCC,EAASC,EAAIC,GAC5C,OAaA,SAAeG,GAGb,OAFAL,EAAQM,MAAM,mBACdN,EAAQO,QAAQF,GACTyC,CACT,EAaA,SAASA,EAAMzC,GACb,OAAI4B,EAAAA,EAAAA,IAAmB5B,IACrBL,EAAQQ,KAAK,mBACNP,EAAGI,IAELH,EAAIG,EACb,CACF,E,kDC5CO,MAAMqD,EAAW,CACtB1C,KAAM,WACNjB,SA8EF,SAA0BC,EAASC,EAAIC,GAErC,IAEIgB,EAEAyC,EAJA5B,EAAW,EAKf,OAcA,SAAe1B,GAGb,OAFAL,EAAQM,MAAM,YACdN,EAAQM,MAAM,oBACPkC,EAAanC,EACtB,EAYA,SAASmC,EAAanC,GACpB,OAAa,KAATA,GACFL,EAAQO,QAAQF,GAChB0B,IACOS,IAETxC,EAAQQ,KAAK,oBACNoD,EAAQvD,GACjB,CAYA,SAASuD,EAAQvD,GAEf,OAAa,OAATA,EACKH,EAAIG,GAMA,KAATA,GACFL,EAAQM,MAAM,SACdN,EAAQO,QAAQF,GAChBL,EAAQQ,KAAK,SACNoD,GAII,KAATvD,GACFsD,EAAQ3D,EAAQM,MAAM,oBACtBY,EAAO,EACAY,EAAczB,KAEnB4B,EAAAA,EAAAA,IAAmB5B,IACrBL,EAAQM,MAAM,cACdN,EAAQO,QAAQF,GAChBL,EAAQQ,KAAK,cACNoD,IAIT5D,EAAQM,MAAM,gBACPuD,EAAKxD,GACd,CAYA,SAASwD,EAAKxD,GACZ,OACW,OAATA,GACS,KAATA,GACS,KAATA,IACA4B,EAAAA,EAAAA,IAAmB5B,IAEnBL,EAAQQ,KAAK,gBACNoD,EAAQvD,KAEjBL,EAAQO,QAAQF,GACTwD,EACT,CAYA,SAAS/B,EAAczB,GAErB,OAAa,KAATA,GACFL,EAAQO,QAAQF,GAChBa,IACOY,GAILZ,IAASa,GACX/B,EAAQQ,KAAK,oBACbR,EAAQQ,KAAK,YACNP,EAAGI,KAIZsD,EAAMrB,KAAO,eACNuB,EAAKxD,GACd,CACF,EA7NEyD,QAMF,SAAyB1B,GACvB,IAGI2B,EAEAzD,EALA0D,EAAgB5B,EAAOC,OAAS,EAChC4B,EAAiB,EAOrB,KACsC,eAAnC7B,EAAO6B,GAAgB,GAAG3B,MACU,UAAnCF,EAAO6B,GAAgB,GAAG3B,MACO,eAAlCF,EAAO4B,GAAe,GAAG1B,MACU,UAAlCF,EAAO4B,GAAe,GAAG1B,MAK3B,IAHAyB,EAAQE,IAGCF,EAAQC,GACf,GAA8B,iBAA1B5B,EAAO2B,GAAO,GAAGzB,KAAyB,CAE5CF,EAAO6B,GAAgB,GAAG3B,KAAO,kBACjCF,EAAO4B,GAAe,GAAG1B,KAAO,kBAChC2B,GAAkB,EAClBD,GAAiB,EACjB,KACF,CAKJD,EAAQE,EAAiB,EACzBD,IACA,OAASD,GAASC,QACFpC,IAAVtB,EACEyD,IAAUC,GAA2C,eAA1B5B,EAAO2B,GAAO,GAAGzB,OAC9ChC,EAAQyD,GAGVA,IAAUC,GACgB,eAA1B5B,EAAO2B,GAAO,GAAGzB,OAEjBF,EAAO9B,GAAO,GAAGgC,KAAO,eACpByB,IAAUzD,EAAQ,IACpB8B,EAAO9B,GAAO,GAAG4D,IAAM9B,EAAO2B,EAAQ,GAAG,GAAGG,IAC5C9B,EAAO+B,OAAO7D,EAAQ,EAAGyD,EAAQzD,EAAQ,GACzC0D,GAAiBD,EAAQzD,EAAQ,EACjCyD,EAAQzD,EAAQ,GAElBA,OAAQsB,GAGZ,OAAOQ,CACT,EA1DEgC,SAgEF,SAAkB/D,GAEhB,OACW,KAATA,GACgD,oBAAhDD,KAAKgC,OAAOhC,KAAKgC,OAAOC,OAAS,GAAG,GAAGC,IAE3C,E,oHCnEO,MAAM+B,EAAa,CACxBrD,KAAM,aACNjB,SAaF,SAA4BC,EAASC,EAAIC,GACvC,MAAMC,EAAOC,KAEb,IAAIkE,EACJ,OAYA,SAAejE,GAKb,OADAL,EAAQM,MAAM,cAchB,SAAgBD,GAGd,OAAOkE,EAAAA,EAAaC,KAClBrE,EACAH,EACAyE,EAEAvE,EACA,kBACA,wBACA,wBARKqE,CASLlE,EACJ,CA1BSqE,CAAOrE,EAChB,EAqCA,SAASoE,EAAWpE,GAIlB,OAHAiE,GAAaK,EAAAA,EAAAA,GACXxE,EAAKoC,eAAepC,EAAKiC,OAAOjC,EAAKiC,OAAOC,OAAS,GAAG,IAAIuC,MAAM,GAAI,IAE3D,KAATvE,GACFL,EAAQM,MAAM,oBACdN,EAAQO,QAAQF,GAChBL,EAAQQ,KAAK,oBACNqE,GAEF3E,EAAIG,EACb,CAYA,SAASwE,EAAYxE,GAEnB,OAAOyE,EAAAA,EAAAA,IAA0BzE,IAC7B0E,EAAAA,EAAAA,GAAkB/E,EAASgF,EAA3BD,CAA8C1E,GAC9C2E,EAAkB3E,EACxB,CAYA,SAAS2E,EAAkB3E,GACzB,OAAO4E,EAAAA,EAAAA,GACLjF,EACAkF,EAEAhF,EACA,wBACA,+BACA,qCACA,2BACA,8BATK+E,CAUL5E,EACJ,CAYA,SAAS6E,EAAiB7E,GACxB,OAAOL,EAAQmD,QAAQgC,EAAarC,EAAOA,EAApC9C,CAA2CK,EACpD,CAcA,SAASyC,EAAMzC,GACb,OAAOgB,EAAAA,EAAAA,IAAchB,IACjBiB,EAAAA,EAAAA,GAAatB,EAASoF,EAAiB,aAAvC9D,CAAqDjB,GACrD+E,EAAgB/E,EACtB,CAcA,SAAS+E,EAAgB/E,GACvB,OAAa,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,IACtCL,EAAQQ,KAAK,cAKbL,EAAKO,OAAO2E,QAAQC,KAAKhB,GAKlBrE,EAAGI,IAELH,EAAIG,EACb,CACF,GAtLM8E,EAAc,CAClBpF,SA2LF,SAA6BC,EAASC,EAAIC,GACxC,OAcA,SAAqBG,GACnB,OAAOyE,EAAAA,EAAAA,IAA0BzE,IAC7B0E,EAAAA,EAAAA,GAAkB/E,EAASuF,EAA3BR,CAAyC1E,GACzCH,EAAIG,EACV,EAaA,SAASkF,EAAalF,GACpB,OAAOmF,EAAAA,EAAAA,GACLxF,EACAyF,EACAvF,EACA,kBACA,wBACA,wBANKsF,CAOLnF,EACJ,CAYA,SAASoF,EAAWpF,GAClB,OAAOgB,EAAAA,EAAAA,IAAchB,IACjBiB,EAAAA,EAAAA,GAAatB,EAAS0F,EAA8B,aAApDpE,CAAkEjB,GAClEqF,EAA6BrF,EACnC,CAYA,SAASqF,EAA6BrF,GACpC,OAAgB,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,GAAQJ,EAAGI,GAAQH,EAAIG,EACpE,CACF,EAlQES,SAAS,E,uECVJ,MAAM6E,EAAa,CACxB3E,KAAM,aACNjB,SA2DF,SAA4BC,EAASC,EAAIC,GACvC,IAAIgB,EAAO,EACX,OAYA,SAAeb,GAGb,OADAL,EAAQM,MAAM,cAchB,SAAgBD,GAEd,OADAL,EAAQM,MAAM,sBACPkC,EAAanC,EACtB,CAhBSqE,CAAOrE,EAChB,EA2BA,SAASmC,EAAanC,GACpB,OAAa,KAATA,GAAea,IAAS,GAC1BlB,EAAQO,QAAQF,GACTmC,GAII,OAATnC,IAAiByE,EAAAA,EAAAA,IAA0BzE,IAC7CL,EAAQQ,KAAK,sBACNoF,EAAQvF,IAEVH,EAAIG,EACb,CAYA,SAASuF,EAAQvF,GACf,OAAa,KAATA,GACFL,EAAQM,MAAM,sBACPuF,EAAgBxF,IAEZ,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,IACtCL,EAAQQ,KAAK,cAINP,EAAGI,KAERgB,EAAAA,EAAAA,IAAchB,IACTiB,EAAAA,EAAAA,GAAatB,EAAS4F,EAAS,aAA/BtE,CAA6CjB,IAKtDL,EAAQM,MAAM,kBACPuD,EAAKxD,GACd,CAcA,SAASwF,EAAgBxF,GACvB,OAAa,KAATA,GACFL,EAAQO,QAAQF,GACTwF,IAET7F,EAAQQ,KAAK,sBACNoF,EAAQvF,GACjB,CAYA,SAASwD,EAAKxD,GACZ,OAAa,OAATA,GAA0B,KAATA,IAAeyE,EAAAA,EAAAA,IAA0BzE,IAC5DL,EAAQQ,KAAK,kBACNoF,EAAQvF,KAEjBL,EAAQO,QAAQF,GACTwD,EACT,CACF,EA5LEC,QAIF,SAA2B1B,EAAQ0D,GACjC,IAGIC,EAEAC,EALAC,EAAa7D,EAAOC,OAAS,EAC7BgB,EAAe,EAOkB,eAAjCjB,EAAOiB,GAAc,GAAGf,OAC1Be,GAAgB,GAKhB4C,EAAa,EAAI5C,GACc,eAA/BjB,EAAO6D,GAAY,GAAG3D,OAEtB2D,GAAc,GAGiB,uBAA/B7D,EAAO6D,GAAY,GAAG3D,OACrBe,IAAiB4C,EAAa,GAC5BA,EAAa,EAAI5C,GACmB,eAAnCjB,EAAO6D,EAAa,GAAG,GAAG3D,QAE9B2D,GAAc5C,EAAe,IAAM4C,EAAa,EAAI,GAElDA,EAAa5C,IACf0C,EAAU,CACRzD,KAAM,iBACNlB,MAAOgB,EAAOiB,GAAc,GAAGjC,MAC/B8C,IAAK9B,EAAO6D,GAAY,GAAG/B,KAE7B8B,EAAO,CACL1D,KAAM,YACNlB,MAAOgB,EAAOiB,GAAc,GAAGjC,MAC/B8C,IAAK9B,EAAO6D,GAAY,GAAG/B,IAC3BnB,YAAa,SAEfoB,EAAAA,EAAAA,GAAO/B,EAAQiB,EAAc4C,EAAa5C,EAAe,EAAG,CAC1D,CAAC,QAAS0C,EAASD,GACnB,CAAC,QAASE,EAAMF,GAChB,CAAC,OAAQE,EAAMF,GACf,CAAC,OAAQC,EAASD,MAGtB,OAAO1D,CACT,E,wECxDO,MAAM2D,EAAU,CACrBhG,SAyBF,SAAyBC,EAASC,GAEhC,IAAImE,EACJ,OAYA,SAAoB/D,GAKlB,OAJAL,EAAQM,MAAM,WACd8D,EAAWpE,EAAQM,MAAM,eAAgB,CACvCyC,YAAa,YAERmD,EAAY7F,EACrB,EAYA,SAAS6F,EAAY7F,GACnB,OAAa,OAATA,EACK4F,EAAW5F,IAKhB4B,EAAAA,EAAAA,IAAmB5B,GACdL,EAAQ4C,MACbuD,EACAC,EACAH,EAHKjG,CAILK,IAIJL,EAAQO,QAAQF,GACT6F,EACT,CAOA,SAASD,EAAW5F,GAGlB,OAFAL,EAAQQ,KAAK,gBACbR,EAAQQ,KAAK,WACNP,EAAGI,EACZ,CAOA,SAAS+F,EAAgB/F,GAQvB,OAPAL,EAAQO,QAAQF,GAChBL,EAAQQ,KAAK,gBACb4D,EAASiC,KAAOrG,EAAQM,MAAM,eAAgB,CAC5CyC,YAAa,UACbqB,aAEFA,EAAWA,EAASiC,KACbH,CACT,CACF,EAvGEpC,QAeF,SAAwB1B,GAEtB,OADAkE,EAAAA,EAAAA,GAAYlE,GACLA,CACT,GAdM+D,EAAwB,CAC5BpG,SAwGF,SAA8BC,EAASC,EAAIC,GACzC,MAAMC,EAAOC,KACb,OAOA,SAAwBC,GAKtB,OAJAL,EAAQQ,KAAK,gBACbR,EAAQM,MAAM,cACdN,EAAQO,QAAQF,GAChBL,EAAQQ,KAAK,eACNc,EAAAA,EAAAA,GAAatB,EAASuG,EAAU,aACzC,EAOA,SAASA,EAASlG,GAChB,GAAa,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,GACtC,OAAOH,EAAIG,GAKb,MAAM8B,EAAOhC,EAAKiC,OAAOjC,EAAKiC,OAAOC,OAAS,GAC9C,OACGlC,EAAKO,OAAOc,WAAWC,QAAQC,KAAKC,SAAS,iBAC9CQ,GACiB,eAAjBA,EAAK,GAAGG,MACRH,EAAK,GAAGI,eAAeJ,EAAK,IAAI,GAAME,QAAU,EAEzCpC,EAAGI,GAELL,EAAQ2C,UAAUxC,EAAKO,OAAOc,WAAWgF,KAAMtG,EAAKD,EAApDD,CAAwDK,EACjE,CACF,EA/IES,SAAS,E,6DCdJ,MAAM2F,EAAe,CAC1BzF,KAAM,eACNjB,SAaF,SAA8BC,EAASC,EAAIC,GACzC,MAAMC,EAAOC,KACb,OAgBA,SAAeC,GAMb,OAHAL,EAAQM,MAAM,iBAGPgB,EAAAA,EAAAA,GAAatB,EAAS0G,EAAa,aAAc,EAAjDpF,CAAwDjB,EACjE,EAYA,SAASqG,EAAYrG,GACnB,MAAM8B,EAAOhC,EAAKiC,OAAOjC,EAAKiC,OAAOC,OAAS,GAC9C,OAAOF,GACY,eAAjBA,EAAK,GAAGG,MACRH,EAAK,GAAGI,eAAeJ,EAAK,IAAI,GAAME,QAAU,EAC9CuD,EAAQvF,GACRH,EAAIG,EACV,CAYA,SAASuF,EAAQvF,GACf,OAAa,OAATA,EACKyC,EAAMzC,IAEX4B,EAAAA,EAAAA,IAAmB5B,GACdL,EAAQmD,QAAQwD,EAAcf,EAAS9C,EAAvC9C,CAA8CK,IAEvDL,EAAQM,MAAM,iBACPsG,EAAOvG,GAChB,CAYA,SAASuG,EAAOvG,GACd,OAAa,OAATA,IAAiB4B,EAAAA,EAAAA,IAAmB5B,IACtCL,EAAQQ,KAAK,iBACNoF,EAAQvF,KAEjBL,EAAQO,QAAQF,GACTuG,EACT,CAGA,SAAS9D,EAAMzC,GAKb,OAJAL,EAAQQ,KAAK,gBAINP,EAAGI,EACZ,CACF,GAvGMsG,EAAe,CACnB5G,SA4GF,SAA8BC,EAASC,EAAIC,GACzC,MAAMC,EAAOC,KACb,OAAOuG,EAaP,SAASA,EAAatG,GAGpB,OAAIF,EAAKO,OAAOC,KAAKR,EAAKS,MAAMC,MACvBX,EAAIG,IAET4B,EAAAA,EAAAA,IAAmB5B,IACrBL,EAAQM,MAAM,cACdN,EAAQO,QAAQF,GAChBL,EAAQQ,KAAK,cACNmG,IASFrF,EAAAA,EAAAA,GAAatB,EAAS0G,EAAa,aAAc,EAAjDpF,CAAwDjB,EACjE,CAYA,SAASqG,EAAYrG,GACnB,MAAM8B,EAAOhC,EAAKiC,OAAOjC,EAAKiC,OAAOC,OAAS,GAC9C,OAAOF,GACY,eAAjBA,EAAK,GAAGG,MACRH,EAAK,GAAGI,eAAeJ,EAAK,IAAI,GAAME,QAAU,EAC9CpC,EAAGI,IACH4B,EAAAA,EAAAA,IAAmB5B,GACnBsG,EAAatG,GACbH,EAAIG,EACV,CACF,EApKES,SAAS,E","sources":["../node_modules/micromark-core-commonmark/lib/code-fenced.js","../node_modules/micromark-core-commonmark/lib/hard-break-escape.js","../node_modules/micromark-core-commonmark/lib/code-text.js","../node_modules/micromark-core-commonmark/lib/definition.js","../node_modules/micromark-core-commonmark/lib/heading-atx.js","../node_modules/micromark-core-commonmark/lib/content.js","../node_modules/micromark-core-commonmark/lib/code-indented.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding, markdownSpace} from 'micromark-util-character'\n/** @type {Construct} */\nconst nonLazyContinuation = {\n  tokenize: tokenizeNonLazyContinuation,\n  partial: true\n}\n\n/** @type {Construct} */\nexport const codeFenced = {\n  name: 'codeFenced',\n  tokenize: tokenizeCodeFenced,\n  concrete: true\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCodeFenced(effects, ok, nok) {\n  const self = this\n  /** @type {Construct} */\n  const closeStart = {\n    tokenize: tokenizeCloseStart,\n    partial: true\n  }\n  let initialPrefix = 0\n  let sizeOpen = 0\n  /** @type {NonNullable<Code>} */\n  let marker\n  return start\n\n  /**\n   * Start of code.\n   *\n   * ```markdown\n   * > | ~~~js\n   *     ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: parse whitespace like `markdown-rs`.\n    return beforeSequenceOpen(code)\n  }\n\n  /**\n   * In opening fence, after prefix, at sequence.\n   *\n   * ```markdown\n   * > | ~~~js\n   *     ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeSequenceOpen(code) {\n    const tail = self.events[self.events.length - 1]\n    initialPrefix =\n      tail && tail[1].type === 'linePrefix'\n        ? tail[2].sliceSerialize(tail[1], true).length\n        : 0\n    marker = code\n    effects.enter('codeFenced')\n    effects.enter('codeFencedFence')\n    effects.enter('codeFencedFenceSequence')\n    return sequenceOpen(code)\n  }\n\n  /**\n   * In opening fence sequence.\n   *\n   * ```markdown\n   * > | ~~~js\n   *      ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === marker) {\n      sizeOpen++\n      effects.consume(code)\n      return sequenceOpen\n    }\n    if (sizeOpen < 3) {\n      return nok(code)\n    }\n    effects.exit('codeFencedFenceSequence')\n    return markdownSpace(code)\n      ? factorySpace(effects, infoBefore, 'whitespace')(code)\n      : infoBefore(code)\n  }\n\n  /**\n   * In opening fence, after the sequence (and optional whitespace), before info.\n   *\n   * ```markdown\n   * > | ~~~js\n   *        ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function infoBefore(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFencedFence')\n      return self.interrupt\n        ? ok(code)\n        : effects.check(nonLazyContinuation, atNonLazyBreak, after)(code)\n    }\n    effects.enter('codeFencedFenceInfo')\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return info(code)\n  }\n\n  /**\n   * In info.\n   *\n   * ```markdown\n   * > | ~~~js\n   *        ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function info(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString')\n      effects.exit('codeFencedFenceInfo')\n      return infoBefore(code)\n    }\n    if (markdownSpace(code)) {\n      effects.exit('chunkString')\n      effects.exit('codeFencedFenceInfo')\n      return factorySpace(effects, metaBefore, 'whitespace')(code)\n    }\n    if (code === 96 && code === marker) {\n      return nok(code)\n    }\n    effects.consume(code)\n    return info\n  }\n\n  /**\n   * In opening fence, after info and whitespace, before meta.\n   *\n   * ```markdown\n   * > | ~~~js eval\n   *           ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function metaBefore(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return infoBefore(code)\n    }\n    effects.enter('codeFencedFenceMeta')\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return meta(code)\n  }\n\n  /**\n   * In meta.\n   *\n   * ```markdown\n   * > | ~~~js eval\n   *           ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function meta(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString')\n      effects.exit('codeFencedFenceMeta')\n      return infoBefore(code)\n    }\n    if (code === 96 && code === marker) {\n      return nok(code)\n    }\n    effects.consume(code)\n    return meta\n  }\n\n  /**\n   * At eol/eof in code, before a non-lazy closing fence or content.\n   *\n   * ```markdown\n   * > | ~~~js\n   *          ^\n   * > | alert(1)\n   *             ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function atNonLazyBreak(code) {\n    return effects.attempt(closeStart, after, contentBefore)(code)\n  }\n\n  /**\n   * Before code content, not a closing fence, at eol.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *             ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentBefore(code) {\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return contentStart\n  }\n\n  /**\n   * Before code content, not a closing fence.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentStart(code) {\n    return initialPrefix > 0 && markdownSpace(code)\n      ? factorySpace(\n          effects,\n          beforeContentChunk,\n          'linePrefix',\n          initialPrefix + 1\n        )(code)\n      : beforeContentChunk(code)\n  }\n\n  /**\n   * Before code content, after optional prefix.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeContentChunk(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return effects.check(nonLazyContinuation, atNonLazyBreak, after)(code)\n    }\n    effects.enter('codeFlowValue')\n    return contentChunk(code)\n  }\n\n  /**\n   * In code content.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^^^^^^^^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentChunk(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFlowValue')\n      return beforeContentChunk(code)\n    }\n    effects.consume(code)\n    return contentChunk\n  }\n\n  /**\n   * After code.\n   *\n   * ```markdown\n   *   | ~~~js\n   *   | alert(1)\n   * > | ~~~\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    effects.exit('codeFenced')\n    return ok(code)\n  }\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Tokenizer}\n   */\n  function tokenizeCloseStart(effects, ok, nok) {\n    let size = 0\n    return startBefore\n\n    /**\n     *\n     *\n     * @type {State}\n     */\n    function startBefore(code) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return start\n    }\n\n    /**\n     * Before closing fence, at optional whitespace.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function start(code) {\n      // Always populated by defaults.\n\n      // To do: `enter` here or in next state?\n      effects.enter('codeFencedFence')\n      return markdownSpace(code)\n        ? factorySpace(\n            effects,\n            beforeSequenceClose,\n            'linePrefix',\n            self.parser.constructs.disable.null.includes('codeIndented')\n              ? undefined\n              : 4\n          )(code)\n        : beforeSequenceClose(code)\n    }\n\n    /**\n     * In closing fence, after optional whitespace, at sequence.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function beforeSequenceClose(code) {\n      if (code === marker) {\n        effects.enter('codeFencedFenceSequence')\n        return sequenceClose(code)\n      }\n      return nok(code)\n    }\n\n    /**\n     * In closing fence sequence.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function sequenceClose(code) {\n      if (code === marker) {\n        size++\n        effects.consume(code)\n        return sequenceClose\n      }\n      if (size >= sizeOpen) {\n        effects.exit('codeFencedFenceSequence')\n        return markdownSpace(code)\n          ? factorySpace(effects, sequenceCloseAfter, 'whitespace')(code)\n          : sequenceCloseAfter(code)\n      }\n      return nok(code)\n    }\n\n    /**\n     * After closing fence sequence, after optional whitespace.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *        ^\n     * ```\n     *\n     * @type {State}\n     */\n    function sequenceCloseAfter(code) {\n      if (code === null || markdownLineEnding(code)) {\n        effects.exit('codeFencedFence')\n        return ok(code)\n      }\n      return nok(code)\n    }\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeNonLazyContinuation(effects, ok, nok) {\n  const self = this\n  return start\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (code === null) {\n      return nok(code)\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return lineStart\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function lineStart(code) {\n    return self.parser.lazy[self.now().line] ? nok(code) : ok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {Construct} */\nexport const hardBreakEscape = {\n  name: 'hardBreakEscape',\n  tokenize: tokenizeHardBreakEscape\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeHardBreakEscape(effects, ok, nok) {\n  return start\n\n  /**\n   * Start of a hard break (escape).\n   *\n   * ```markdown\n   * > | a\\\n   *      ^\n   *   | b\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('hardBreakEscape')\n    effects.consume(code)\n    return after\n  }\n\n  /**\n   * After `\\`, at eol.\n   *\n   * ```markdown\n   * > | a\\\n   *       ^\n   *   | b\n   * ```\n   *\n   *  @type {State}\n   */\n  function after(code) {\n    if (markdownLineEnding(code)) {\n      effects.exit('hardBreakEscape')\n      return ok(code)\n    }\n    return nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Previous} Previous\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {Construct} */\nexport const codeText = {\n  name: 'codeText',\n  tokenize: tokenizeCodeText,\n  resolve: resolveCodeText,\n  previous\n}\n\n// To do: next major: don’t resolve, like `markdown-rs`.\n/** @type {Resolver} */\nfunction resolveCodeText(events) {\n  let tailExitIndex = events.length - 4\n  let headEnterIndex = 3\n  /** @type {number} */\n  let index\n  /** @type {number | undefined} */\n  let enter\n\n  // If we start and end with an EOL or a space.\n  if (\n    (events[headEnterIndex][1].type === 'lineEnding' ||\n      events[headEnterIndex][1].type === 'space') &&\n    (events[tailExitIndex][1].type === 'lineEnding' ||\n      events[tailExitIndex][1].type === 'space')\n  ) {\n    index = headEnterIndex\n\n    // And we have data.\n    while (++index < tailExitIndex) {\n      if (events[index][1].type === 'codeTextData') {\n        // Then we have padding.\n        events[headEnterIndex][1].type = 'codeTextPadding'\n        events[tailExitIndex][1].type = 'codeTextPadding'\n        headEnterIndex += 2\n        tailExitIndex -= 2\n        break\n      }\n    }\n  }\n\n  // Merge adjacent spaces and data.\n  index = headEnterIndex - 1\n  tailExitIndex++\n  while (++index <= tailExitIndex) {\n    if (enter === undefined) {\n      if (index !== tailExitIndex && events[index][1].type !== 'lineEnding') {\n        enter = index\n      }\n    } else if (\n      index === tailExitIndex ||\n      events[index][1].type === 'lineEnding'\n    ) {\n      events[enter][1].type = 'codeTextData'\n      if (index !== enter + 2) {\n        events[enter][1].end = events[index - 1][1].end\n        events.splice(enter + 2, index - enter - 2)\n        tailExitIndex -= index - enter - 2\n        index = enter + 2\n      }\n      enter = undefined\n    }\n  }\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Previous}\n */\nfunction previous(code) {\n  // If there is a previous code, there will always be a tail.\n  return (\n    code !== 96 ||\n    this.events[this.events.length - 1][1].type === 'characterEscape'\n  )\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCodeText(effects, ok, nok) {\n  const self = this\n  let sizeOpen = 0\n  /** @type {number} */\n  let size\n  /** @type {Token} */\n  let token\n  return start\n\n  /**\n   * Start of code (text).\n   *\n   * ```markdown\n   * > | `a`\n   *     ^\n   * > | \\`a`\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('codeText')\n    effects.enter('codeTextSequence')\n    return sequenceOpen(code)\n  }\n\n  /**\n   * In opening sequence.\n   *\n   * ```markdown\n   * > | `a`\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === 96) {\n      effects.consume(code)\n      sizeOpen++\n      return sequenceOpen\n    }\n    effects.exit('codeTextSequence')\n    return between(code)\n  }\n\n  /**\n   * Between something and something else.\n   *\n   * ```markdown\n   * > | `a`\n   *      ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function between(code) {\n    // EOF.\n    if (code === null) {\n      return nok(code)\n    }\n\n    // To do: next major: don’t do spaces in resolve, but when compiling,\n    // like `markdown-rs`.\n    // Tabs don’t work, and virtual spaces don’t make sense.\n    if (code === 32) {\n      effects.enter('space')\n      effects.consume(code)\n      effects.exit('space')\n      return between\n    }\n\n    // Closing fence? Could also be data.\n    if (code === 96) {\n      token = effects.enter('codeTextSequence')\n      size = 0\n      return sequenceClose(code)\n    }\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return between\n    }\n\n    // Data.\n    effects.enter('codeTextData')\n    return data(code)\n  }\n\n  /**\n   * In data.\n   *\n   * ```markdown\n   * > | `a`\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function data(code) {\n    if (\n      code === null ||\n      code === 32 ||\n      code === 96 ||\n      markdownLineEnding(code)\n    ) {\n      effects.exit('codeTextData')\n      return between(code)\n    }\n    effects.consume(code)\n    return data\n  }\n\n  /**\n   * In closing sequence.\n   *\n   * ```markdown\n   * > | `a`\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceClose(code) {\n    // More.\n    if (code === 96) {\n      effects.consume(code)\n      size++\n      return sequenceClose\n    }\n\n    // Done!\n    if (size === sizeOpen) {\n      effects.exit('codeTextSequence')\n      effects.exit('codeText')\n      return ok(code)\n    }\n\n    // More or less accents: mark as data.\n    token.type = 'codeTextData'\n    return data(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factoryDestination} from 'micromark-factory-destination'\nimport {factoryLabel} from 'micromark-factory-label'\nimport {factorySpace} from 'micromark-factory-space'\nimport {factoryTitle} from 'micromark-factory-title'\nimport {factoryWhitespace} from 'micromark-factory-whitespace'\nimport {\n  markdownLineEnding,\n  markdownLineEndingOrSpace,\n  markdownSpace\n} from 'micromark-util-character'\nimport {normalizeIdentifier} from 'micromark-util-normalize-identifier'\n/** @type {Construct} */\nexport const definition = {\n  name: 'definition',\n  tokenize: tokenizeDefinition\n}\n\n/** @type {Construct} */\nconst titleBefore = {\n  tokenize: tokenizeTitleBefore,\n  partial: true\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeDefinition(effects, ok, nok) {\n  const self = this\n  /** @type {string} */\n  let identifier\n  return start\n\n  /**\n   * At start of a definition.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // Do not interrupt paragraphs (but do follow definitions).\n    // To do: do `interrupt` the way `markdown-rs` does.\n    // To do: parse whitespace the way `markdown-rs` does.\n    effects.enter('definition')\n    return before(code)\n  }\n\n  /**\n   * After optional whitespace, at `[`.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    // To do: parse whitespace the way `markdown-rs` does.\n\n    return factoryLabel.call(\n      self,\n      effects,\n      labelAfter,\n      // Note: we don’t need to reset the way `markdown-rs` does.\n      nok,\n      'definitionLabel',\n      'definitionLabelMarker',\n      'definitionLabelString'\n    )(code)\n  }\n\n  /**\n   * After label.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelAfter(code) {\n    identifier = normalizeIdentifier(\n      self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1)\n    )\n    if (code === 58) {\n      effects.enter('definitionMarker')\n      effects.consume(code)\n      effects.exit('definitionMarker')\n      return markerAfter\n    }\n    return nok(code)\n  }\n\n  /**\n   * After marker.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function markerAfter(code) {\n    // Note: whitespace is optional.\n    return markdownLineEndingOrSpace(code)\n      ? factoryWhitespace(effects, destinationBefore)(code)\n      : destinationBefore(code)\n  }\n\n  /**\n   * Before destination.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function destinationBefore(code) {\n    return factoryDestination(\n      effects,\n      destinationAfter,\n      // Note: we don’t need to reset the way `markdown-rs` does.\n      nok,\n      'definitionDestination',\n      'definitionDestinationLiteral',\n      'definitionDestinationLiteralMarker',\n      'definitionDestinationRaw',\n      'definitionDestinationString'\n    )(code)\n  }\n\n  /**\n   * After destination.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function destinationAfter(code) {\n    return effects.attempt(titleBefore, after, after)(code)\n  }\n\n  /**\n   * After definition.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    return markdownSpace(code)\n      ? factorySpace(effects, afterWhitespace, 'whitespace')(code)\n      : afterWhitespace(code)\n  }\n\n  /**\n   * After definition, after optional whitespace.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterWhitespace(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('definition')\n\n      // Note: we don’t care about uniqueness.\n      // It’s likely that that doesn’t happen very frequently.\n      // It is more likely that it wastes precious time.\n      self.parser.defined.push(identifier)\n\n      // To do: `markdown-rs` interrupt.\n      // // You’d be interrupting.\n      // tokenizer.interrupt = true\n      return ok(code)\n    }\n    return nok(code)\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeTitleBefore(effects, ok, nok) {\n  return titleBefore\n\n  /**\n   * After destination, at whitespace.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleBefore(code) {\n    return markdownLineEndingOrSpace(code)\n      ? factoryWhitespace(effects, beforeMarker)(code)\n      : nok(code)\n  }\n\n  /**\n   * At title.\n   *\n   * ```markdown\n   *   | [a]: b\n   * > | \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeMarker(code) {\n    return factoryTitle(\n      effects,\n      titleAfter,\n      nok,\n      'definitionTitle',\n      'definitionTitleMarker',\n      'definitionTitleString'\n    )(code)\n  }\n\n  /**\n   * After title.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleAfter(code) {\n    return markdownSpace(code)\n      ? factorySpace(effects, titleAfterOptionalWhitespace, 'whitespace')(code)\n      : titleAfterOptionalWhitespace(code)\n  }\n\n  /**\n   * After title, after optional whitespace.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleAfterOptionalWhitespace(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {\n  markdownLineEnding,\n  markdownLineEndingOrSpace,\n  markdownSpace\n} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\n/** @type {Construct} */\nexport const headingAtx = {\n  name: 'headingAtx',\n  tokenize: tokenizeHeadingAtx,\n  resolve: resolveHeadingAtx\n}\n\n/** @type {Resolver} */\nfunction resolveHeadingAtx(events, context) {\n  let contentEnd = events.length - 2\n  let contentStart = 3\n  /** @type {Token} */\n  let content\n  /** @type {Token} */\n  let text\n\n  // Prefix whitespace, part of the opening.\n  if (events[contentStart][1].type === 'whitespace') {\n    contentStart += 2\n  }\n\n  // Suffix whitespace, part of the closing.\n  if (\n    contentEnd - 2 > contentStart &&\n    events[contentEnd][1].type === 'whitespace'\n  ) {\n    contentEnd -= 2\n  }\n  if (\n    events[contentEnd][1].type === 'atxHeadingSequence' &&\n    (contentStart === contentEnd - 1 ||\n      (contentEnd - 4 > contentStart &&\n        events[contentEnd - 2][1].type === 'whitespace'))\n  ) {\n    contentEnd -= contentStart + 1 === contentEnd ? 2 : 4\n  }\n  if (contentEnd > contentStart) {\n    content = {\n      type: 'atxHeadingText',\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end\n    }\n    text = {\n      type: 'chunkText',\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end,\n      contentType: 'text'\n    }\n    splice(events, contentStart, contentEnd - contentStart + 1, [\n      ['enter', content, context],\n      ['enter', text, context],\n      ['exit', text, context],\n      ['exit', content, context]\n    ])\n  }\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeHeadingAtx(effects, ok, nok) {\n  let size = 0\n  return start\n\n  /**\n   * Start of a heading (atx).\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: parse indent like `markdown-rs`.\n    effects.enter('atxHeading')\n    return before(code)\n  }\n\n  /**\n   * After optional whitespace, at `#`.\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    effects.enter('atxHeadingSequence')\n    return sequenceOpen(code)\n  }\n\n  /**\n   * In opening sequence.\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === 35 && size++ < 6) {\n      effects.consume(code)\n      return sequenceOpen\n    }\n\n    // Always at least one `#`.\n    if (code === null || markdownLineEndingOrSpace(code)) {\n      effects.exit('atxHeadingSequence')\n      return atBreak(code)\n    }\n    return nok(code)\n  }\n\n  /**\n   * After something, before something else.\n   *\n   * ```markdown\n   * > | ## aa\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (code === 35) {\n      effects.enter('atxHeadingSequence')\n      return sequenceFurther(code)\n    }\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('atxHeading')\n      // To do: interrupt like `markdown-rs`.\n      // // Feel free to interrupt.\n      // tokenizer.interrupt = false\n      return ok(code)\n    }\n    if (markdownSpace(code)) {\n      return factorySpace(effects, atBreak, 'whitespace')(code)\n    }\n\n    // To do: generate `data` tokens, add the `text` token later.\n    // Needs edit map, see: `markdown.rs`.\n    effects.enter('atxHeadingText')\n    return data(code)\n  }\n\n  /**\n   * In further sequence (after whitespace).\n   *\n   * Could be normal “visible” hashes in the heading or a final sequence.\n   *\n   * ```markdown\n   * > | ## aa ##\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceFurther(code) {\n    if (code === 35) {\n      effects.consume(code)\n      return sequenceFurther\n    }\n    effects.exit('atxHeadingSequence')\n    return atBreak(code)\n  }\n\n  /**\n   * In text.\n   *\n   * ```markdown\n   * > | ## aa\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function data(code) {\n    if (code === null || code === 35 || markdownLineEndingOrSpace(code)) {\n      effects.exit('atxHeadingText')\n      return atBreak(code)\n    }\n    effects.consume(code)\n    return data\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {subtokenize} from 'micromark-util-subtokenize'\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n}\n\n/** @type {Construct} */\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n}\n\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token | undefined} */\n  let previous\n  return chunkStart\n\n  /**\n   * Before a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkStart(code) {\n    effects.enter('content')\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    })\n    return chunkInside(code)\n  }\n\n  /**\n   * In a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkInside(code) {\n    if (code === null) {\n      return contentEnd(code)\n    }\n\n    // To do: in `markdown-rs`, each line is parsed on its own, and everything\n    // is stitched together resolving.\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    }\n\n    // Data.\n    effects.consume(code)\n    return chunkInside\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentEnd(code) {\n    effects.exit('chunkContent')\n    effects.exit('content')\n    return ok(code)\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentContinue(code) {\n    effects.consume(code)\n    effects.exit('chunkContent')\n    previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous\n    })\n    previous = previous.next\n    return chunkInside\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this\n  return startLookahead\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function startLookahead(code) {\n    effects.exit('chunkContent')\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, prefixed, 'linePrefix')\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    // Always populated by defaults.\n\n    const tail = self.events[self.events.length - 1]\n    if (\n      !self.parser.constructs.disable.null.includes('codeIndented') &&\n      tail &&\n      tail[1].type === 'linePrefix' &&\n      tail[2].sliceSerialize(tail[1], true).length >= 4\n    ) {\n      return ok(code)\n    }\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding, markdownSpace} from 'micromark-util-character'\n/** @type {Construct} */\nexport const codeIndented = {\n  name: 'codeIndented',\n  tokenize: tokenizeCodeIndented\n}\n\n/** @type {Construct} */\nconst furtherStart = {\n  tokenize: tokenizeFurtherStart,\n  partial: true\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCodeIndented(effects, ok, nok) {\n  const self = this\n  return start\n\n  /**\n   * Start of code (indented).\n   *\n   * > **Parsing note**: it is not needed to check if this first line is a\n   * > filled line (that it has a non-whitespace character), because blank lines\n   * > are parsed already, so we never run into that.\n   *\n   * ```markdown\n   * > |     aaa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: manually check if interrupting like `markdown-rs`.\n\n    effects.enter('codeIndented')\n    // To do: use an improved `space_or_tab` function like `markdown-rs`,\n    // so that we can drop the next state.\n    return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)(code)\n  }\n\n  /**\n   * At start, after 1 or 4 spaces.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1]\n    return tail &&\n      tail[1].type === 'linePrefix' &&\n      tail[2].sliceSerialize(tail[1], true).length >= 4\n      ? atBreak(code)\n      : nok(code)\n  }\n\n  /**\n   * At a break.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^  ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (code === null) {\n      return after(code)\n    }\n    if (markdownLineEnding(code)) {\n      return effects.attempt(furtherStart, atBreak, after)(code)\n    }\n    effects.enter('codeFlowValue')\n    return inside(code)\n  }\n\n  /**\n   * In code content.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFlowValue')\n      return atBreak(code)\n    }\n    effects.consume(code)\n    return inside\n  }\n\n  /** @type {State} */\n  function after(code) {\n    effects.exit('codeIndented')\n    // To do: allow interrupting like `markdown-rs`.\n    // Feel free to interrupt.\n    // tokenizer.interrupt = false\n    return ok(code)\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeFurtherStart(effects, ok, nok) {\n  const self = this\n  return furtherStart\n\n  /**\n   * At eol, trying to parse another indent.\n   *\n   * ```markdown\n   * > |     aaa\n   *            ^\n   *   |     bbb\n   * ```\n   *\n   * @type {State}\n   */\n  function furtherStart(code) {\n    // To do: improve `lazy` / `pierce` handling.\n    // If this is a lazy line, it can’t be code.\n    if (self.parser.lazy[self.now().line]) {\n      return nok(code)\n    }\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return furtherStart\n    }\n\n    // To do: the code here in `micromark-js` is a bit different from\n    // `markdown-rs` because there it can attempt spaces.\n    // We can’t yet.\n    //\n    // To do: use an improved `space_or_tab` function like `markdown-rs`,\n    // so that we can drop the next state.\n    return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)(code)\n  }\n\n  /**\n   * At start, after 1 or 4 spaces.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1]\n    return tail &&\n      tail[1].type === 'linePrefix' &&\n      tail[2].sliceSerialize(tail[1], true).length >= 4\n      ? ok(code)\n      : markdownLineEnding(code)\n      ? furtherStart(code)\n      : nok(code)\n  }\n}\n"],"names":["nonLazyContinuation","tokenize","effects","ok","nok","self","this","code","enter","consume","exit","lineStart","parser","lazy","now","line","partial","codeFenced","name","closeStart","size","startBefore","start","markdownSpace","factorySpace","beforeSequenceClose","constructs","disable","null","includes","undefined","marker","sequenceClose","sizeOpen","sequenceCloseAfter","markdownLineEnding","initialPrefix","tail","events","length","type","sliceSerialize","sequenceOpen","beforeSequenceOpen","infoBefore","interrupt","check","atNonLazyBreak","after","contentType","info","metaBefore","meta","attempt","contentBefore","contentStart","beforeContentChunk","contentChunk","concrete","hardBreakEscape","codeText","token","between","data","resolve","index","tailExitIndex","headEnterIndex","end","splice","previous","definition","identifier","factoryLabel","call","labelAfter","before","normalizeIdentifier","slice","markerAfter","markdownLineEndingOrSpace","factoryWhitespace","destinationBefore","factoryDestination","destinationAfter","titleBefore","afterWhitespace","defined","push","beforeMarker","factoryTitle","titleAfter","titleAfterOptionalWhitespace","headingAtx","atBreak","sequenceFurther","context","content","text","contentEnd","chunkInside","continuationConstruct","contentContinue","next","subtokenize","prefixed","flow","codeIndented","afterPrefix","furtherStart","inside"],"sourceRoot":""}