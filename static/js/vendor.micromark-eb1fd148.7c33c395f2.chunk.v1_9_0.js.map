{"version":3,"file":"static/js/vendor.micromark-eb1fd148.7c33c395f2.chunk.v1_9_0.js","mappings":"yLAWO,MAAMA,EAAU,CACrBC,SAOF,SAA2BC,GACzB,MAAMC,EAAeD,EAAQE,QAC3BC,KAAKC,OAAOC,WAAWC,gBASzB,SAAoCC,GAClC,GAAa,OAATA,EAEF,YADAP,EAAQQ,QAAQD,GAMlB,OAHAP,EAAQS,MAAM,cACdT,EAAQQ,QAAQD,GAChBP,EAAQU,KAAK,eACNC,EAAAA,EAAAA,GAAaX,EAASC,EAAc,aAC7C,IAGA,SAA0BM,GAExB,OADAP,EAAQS,MAAM,aACPG,EAAUL,EACnB,IAnBA,IAAIM,EACJ,OAAOZ,EAqBP,SAASW,EAAUL,GACjB,MAAMO,EAAQd,EAAQS,MAAM,YAAa,CACvCM,YAAa,OACbF,aAMF,OAJIA,IACFA,EAASG,KAAOF,GAElBD,EAAWC,EACJG,EAAKV,EACd,CAGA,SAASU,EAAKV,GACZ,OAAa,OAATA,GACFP,EAAQU,KAAK,aACbV,EAAQU,KAAK,kBACbV,EAAQQ,QAAQD,KAGdW,EAAAA,EAAAA,IAAmBX,IACrBP,EAAQQ,QAAQD,GAChBP,EAAQU,KAAK,aACNE,IAITZ,EAAQQ,QAAQD,GACTU,EACT,CACF,E,uEC1DO,MAAME,EAAW,CACtBpB,SAYF,SAA4BC,GAC1B,MAAMoB,EAAOjB,KAEPkB,EAAQ,GACd,IAEIC,EAEAC,EAEAC,EANAC,EAAY,EAOhB,OAAOC,EAGP,SAASA,EAAMnB,GAWb,GAAIkB,EAAYJ,EAAMM,OAAQ,CAC5B,MAAMC,EAAOP,EAAMI,GAEnB,OADAL,EAAKS,eAAiBD,EAAK,GACpB5B,EAAQE,QACb0B,EAAK,GAAGE,aACRC,EACAC,EAHKhC,CAILO,EACJ,CAGA,OAAOyB,EAAmBzB,EAC5B,CAGA,SAASwB,EAAiBxB,GAMxB,GALAkB,IAKIL,EAAKS,eAAeI,WAAY,CAClCb,EAAKS,eAAeI,gBAAaC,EAC7BZ,GACFa,IAKF,MAAMC,EAAmBhB,EAAKiB,OAAOV,OACrC,IAEIW,EAFAC,EAAkBH,EAKtB,KAAOG,KACL,GACsC,SAApCnB,EAAKiB,OAAOE,GAAiB,IACY,cAAzCnB,EAAKiB,OAAOE,GAAiB,GAAGC,KAChC,CACAF,EAAQlB,EAAKiB,OAAOE,GAAiB,GAAGE,IACxC,KACF,CAEFC,EAAejB,GAGf,IAAIkB,EAAQP,EACZ,KAAOO,EAAQvB,EAAKiB,OAAOV,QACzBP,EAAKiB,OAAOM,GAAO,GAAGF,IAAMG,OAAOC,OAAO,CAAC,EAAGP,GAC9CK,IAaF,OATAG,EAAAA,EAAAA,GACE1B,EAAKiB,OACLE,EAAkB,EAClB,EACAnB,EAAKiB,OAAOU,MAAMX,IAIpBhB,EAAKiB,OAAOV,OAASgB,EACdX,EAAmBzB,EAC5B,CACA,OAAOmB,EAAMnB,EACf,CAGA,SAASyB,EAAmBzB,GAM1B,GAAIkB,IAAcJ,EAAMM,OAAQ,CAI9B,IAAKL,EACH,OAAO0B,EAAkBzC,GAM3B,GAAIe,EAAU2B,kBAAoB3B,EAAU2B,iBAAiBC,SAC3D,OAAOC,EAAU5C,GAQnBa,EAAKgC,UAAYC,QACf/B,EAAU2B,mBAAqB3B,EAAUgC,8BAE7C,CAIA,OADAlC,EAAKS,eAAiB,CAAC,EAChB7B,EAAQuD,MACbC,EACAC,EACAC,EAHK1D,CAILO,EACJ,CAGA,SAASkD,EAAqBlD,GAG5B,OAFIe,GAAWa,IACfO,EAAejB,GACRuB,EAAkBzC,EAC3B,CAGA,SAASmD,EAAsBnD,GAG7B,OAFAa,EAAKhB,OAAOuD,KAAKvC,EAAKwC,MAAMC,MAAQpC,IAAcJ,EAAMM,OACxDH,EAAkBJ,EAAKwC,MAAME,OACtBX,EAAU5C,EACnB,CAGA,SAASyC,EAAkBzC,GAGzB,OADAa,EAAKS,eAAiB,CAAC,EAChB7B,EAAQE,QACbsD,EACAO,EACAZ,EAHKnD,CAILO,EACJ,CAGA,SAASwD,EAAkBxD,GAIzB,OAHAkB,IACAJ,EAAM2C,KAAK,CAAC5C,EAAK6B,iBAAkB7B,EAAKS,iBAEjCmB,EAAkBzC,EAC3B,CAGA,SAAS4C,EAAU5C,GACjB,OAAa,OAATA,GACEe,GAAWa,IACfO,EAAe,QACf1C,EAAQQ,QAAQD,KAGlBe,EAAYA,GAAaF,EAAKhB,OAAO6D,KAAK7C,EAAKwC,OAC/C5D,EAAQS,MAAM,YAAa,CACzBM,YAAa,OACbF,SAAUU,EACV2C,WAAY5C,IAEP6C,EAAa5D,GACtB,CAGA,SAAS4D,EAAa5D,GACpB,OAAa,OAATA,GACF6D,EAAapE,EAAQU,KAAK,cAAc,GACxCgC,EAAe,QACf1C,EAAQQ,QAAQD,KAGdW,EAAAA,EAAAA,IAAmBX,IACrBP,EAAQQ,QAAQD,GAChB6D,EAAapE,EAAQU,KAAK,cAE1Be,EAAY,EACZL,EAAKgC,eAAYlB,EACVR,IAET1B,EAAQQ,QAAQD,GACT4D,EACT,CAOA,SAASC,EAAatD,EAAOuD,GAC3B,MAAMC,EAASlD,EAAKmD,YAAYzD,GAyChC,GAxCIuD,GAAKC,EAAON,KAAK,MACrBlD,EAAMD,SAAWU,EACbA,IAAYA,EAAWP,KAAOF,GAClCS,EAAaT,EACbQ,EAAUkD,WAAW1D,EAAMY,OAC3BJ,EAAUmD,MAAMH,GAmCZlD,EAAKhB,OAAOuD,KAAK7C,EAAMY,MAAMmC,MAAO,CACtC,IAAIlB,EAAQrB,EAAUe,OAAOV,OAC7B,KAAOgB,KACL,GAEErB,EAAUe,OAAOM,GAAO,GAAGjB,MAAMoC,OAAStC,KAExCF,EAAUe,OAAOM,GAAO,GAAGF,KAE3BnB,EAAUe,OAAOM,GAAO,GAAGF,IAAIqB,OAAStC,GAI1C,OAMJ,MAAMY,EAAmBhB,EAAKiB,OAAOV,OACrC,IAEI+C,EAEApC,EAJAC,EAAkBH,EAOtB,KAAOG,KACL,GACsC,SAApCnB,EAAKiB,OAAOE,GAAiB,IACY,cAAzCnB,EAAKiB,OAAOE,GAAiB,GAAGC,KAChC,CACA,GAAIkC,EAAM,CACRpC,EAAQlB,EAAKiB,OAAOE,GAAiB,GAAGE,IACxC,KACF,CACAiC,GAAO,CACT,CAMF,IAJAhC,EAAejB,GAGfkB,EAAQP,EACDO,EAAQvB,EAAKiB,OAAOV,QACzBP,EAAKiB,OAAOM,GAAO,GAAGF,IAAMG,OAAOC,OAAO,CAAC,EAAGP,GAC9CK,KAIFG,EAAAA,EAAAA,GACE1B,EAAKiB,OACLE,EAAkB,EAClB,EACAnB,EAAKiB,OAAOU,MAAMX,IAIpBhB,EAAKiB,OAAOV,OAASgB,CACvB,CACF,CAMA,SAASD,EAAeiC,GACtB,IAAIhC,EAAQtB,EAAMM,OAGlB,KAAOgB,KAAUgC,GAAM,CACrB,MAAMC,EAAQvD,EAAMsB,GACpBvB,EAAKS,eAAiB+C,EAAM,GAC5BA,EAAM,GAAGlE,KAAKmE,KAAKzD,EAAMpB,EAC3B,CACAqB,EAAMM,OAASgD,CACjB,CACA,SAASxC,IACPb,EAAUmD,MAAM,CAAC,OACjBlD,OAAaW,EACbZ,OAAYY,EACZd,EAAKS,eAAeI,gBAAaC,CACnC,CACF,GArVMsB,EAAqB,CACzBzD,SA0VF,SAA2BC,EAAS8E,EAAIC,GAGtC,OAAOpE,EAAAA,EAAAA,GACLX,EACAA,EAAQE,QAAQC,KAAKC,OAAOC,WAAWc,SAAU2D,EAAIC,GACrD,aACA5E,KAAKC,OAAOC,WAAW2E,QAAQC,KAAKC,SAAS,qBAAkBhD,EAAY,EAE/E,E,yZChWO,MAAMf,EAAW,CACtB,GAAMgE,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMC,EAAAA,GAIK9E,EAAiB,CAC5B,GAAM+E,EAAAA,GAIKC,EAAc,CACzB,EAAE,GAAIC,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,GAAMA,EAAAA,GAIKtB,EAAO,CAClB,GAAMuB,EAAAA,EACN,GAAMC,EAAAA,EACN,GAAM,CAACC,EAAAA,EAAiBD,EAAAA,GACxB,GAAME,EAAAA,EACN,GAAMD,EAAAA,EACN,GAAMD,EAAAA,EACN,GAAMG,EAAAA,EACN,IAAOA,EAAAA,GAIIC,EAAS,CACpB,GAAMC,EAAAA,EACN,GAAMC,EAAAA,GAIKC,EAAO,CAClB,EAAE,GAAIC,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,GAAMC,EAAAA,EACN,GAAMJ,EAAAA,EACN,GAAMK,EAAAA,EACN,GAAM,CAACC,EAAAA,EAAUC,EAAAA,GACjB,GAAMC,EAAAA,EACN,GAAM,CAACC,EAAAA,EAAiBR,EAAAA,GACxB,GAAMS,EAAAA,EACN,GAAML,EAAAA,EACN,GAAMM,EAAAA,GAIKC,EAAa,CACxBzB,KAAM,CAACkB,EAAAA,EAAWQ,EAAAA,KAIPC,EAAmB,CAC9B3B,KAAM,CAAC,GAAI,KAIAD,EAAU,CACrBC,KAAM,G,uECzDD,SAAS4B,EAAgBzG,EAAQ0G,EAAYC,GAElD,IAAIzE,EAAQM,OAAOC,OACjBkE,EACInE,OAAOC,OAAO,CAAC,EAAGkE,GAClB,CACElD,KAAM,EACNmD,OAAQ,EACRlD,OAAQ,GAEd,CACEmD,OAAQ,EACRC,cAAe,IAInB,MAAMC,EAAc,CAAC,EAEfC,EAAuB,GAE7B,IAAIC,EAAS,GAEThG,EAAQ,GAERiG,GAAW,EAOf,MAAMtH,EAAU,CACdQ,QAkJF,SAAiBD,IACXW,EAAAA,EAAAA,IAAmBX,IACrB+B,EAAMuB,OACNvB,EAAM0E,OAAS,EACf1E,EAAMwB,SAAoB,IAAVvD,EAAc,EAAI,EAClCgH,MACmB,IAAVhH,IACT+B,EAAM0E,SACN1E,EAAMwB,UAIJxB,EAAM4E,aAAe,EACvB5E,EAAM2E,UAEN3E,EAAM4E,eAKF5E,EAAM4E,eAAiBG,EAAO/E,EAAM2E,QAAQtF,SAC9CW,EAAM4E,cAAgB,EACtB5E,EAAM2E,WAKVO,EAAQ3G,SAAWN,EAGnB+G,GAAW,CACb,EAhLE7G,MAmLF,SAAe+B,EAAMiF,GAGnB,MAAM3G,EAAQ2G,GAAU,CAAC,EAKzB,OAJA3G,EAAM0B,KAAOA,EACb1B,EAAMY,MAAQkC,IACd4D,EAAQnF,OAAO2B,KAAK,CAAC,QAASlD,EAAO0G,IACrCnG,EAAM2C,KAAKlD,GACJA,CACT,EA3LEJ,KA8LF,SAAc8B,GACZ,MAAM1B,EAAQO,EAAMqG,MAGpB,OAFA5G,EAAM2B,IAAMmB,IACZ4D,EAAQnF,OAAO2B,KAAK,CAAC,OAAQlD,EAAO0G,IAC7B1G,CACT,EAlMEZ,QAASyH,GAyMX,SAA+BC,EAAWC,GACxCC,EAAUF,EAAWC,EAAKd,KAC5B,IA1MExD,MAAOoE,EAAiBI,GACxB3E,UAAWuE,EAAiBI,EAAmB,CAC7C3E,WAAW,KASToE,EAAU,CACd3G,SAAU,KACVN,KAAM,KACNsB,eAAgB,CAAC,EACjBQ,OAAQ,GACRjC,SACAmE,cACAyD,eA6CF,SAAwBlH,EAAOmH,GAC7B,OAsYJ,SAAyBZ,EAAQY,GAC/B,IAAItF,GAAS,EAEb,MAAMuF,EAAS,GAEf,IAAIC,EACJ,OAASxF,EAAQ0E,EAAO1F,QAAQ,CAC9B,MAAMyG,EAAQf,EAAO1E,GAErB,IAAI0F,EACJ,GAAqB,iBAAVD,EACTC,EAAQD,OAER,OAAQA,GACN,KAAM,EACJC,EAAQ,KACR,MAEF,KAAM,EACJA,EAAQ,KACR,MAEF,KAAM,EACJA,EAAQ,OACR,MAEF,KAAM,EACJA,EAAQJ,EAAa,IAAM,KAC3B,MAEF,KAAM,EACJ,IAAKA,GAAcE,EAAO,SAC1BE,EAAQ,IACR,MAEF,QAEEA,EAAQC,OAAOC,aAAaH,GAGlCD,GAAmB,IAAXC,EACRF,EAAOlE,KAAKqE,EACd,CACA,OAAOH,EAAOM,KAAK,GACrB,CAlbWC,CAAgBlE,EAAYzD,GAAQmH,EAC7C,EA9CErE,MACAY,WAkEF,SAAoB6D,GAClBlB,EAAYkB,EAAMxE,MAAQwE,EAAMrB,OAChCO,GACF,EApEE9C,MAsBF,SAAe1B,GAKb,GAJAsE,GAASrD,EAAAA,EAAAA,GAAKqD,EAAQtE,GACtB2F,IAGkC,OAA9BrB,EAAOA,EAAO1F,OAAS,GACzB,MAAO,GAMT,OAJAmG,EAAUhB,EAAY,GAGtBU,EAAQnF,QAASsG,EAAAA,EAAAA,GAAWvB,EAAsBI,EAAQnF,OAAQmF,GAC3DA,EAAQnF,MACjB,GA3BA,IAOIuG,EAPAC,EAAQ/B,EAAW/G,SAAS8E,KAAK2C,EAASxH,GAW9C,OAHI8G,EAAW6B,YACbvB,EAAqBpD,KAAK8C,GAErBU,EA4BP,SAASjD,EAAYzD,GACnB,OA8VJ,SAAqBuG,EAAQvG,GAC3B,MAAMgI,EAAahI,EAAMY,MAAMuF,OACzB8B,EAAmBjI,EAAMY,MAAMwF,aAC/B8B,EAAWlI,EAAM2B,IAAIwE,OACrBgC,EAAiBnI,EAAM2B,IAAIyE,aAEjC,IAAIgC,EACJ,GAAIJ,IAAeE,EAEjBE,EAAO,CAAC7B,EAAOyB,GAAY/F,MAAMgG,EAAkBE,QAC9C,CAEL,GADAC,EAAO7B,EAAOtE,MAAM+F,EAAYE,GAC5BD,GAAoB,EAAG,CACzB,MAAMI,EAAOD,EAAK,GACE,iBAATC,EACTD,EAAK,GAAKC,EAAKpG,MAAMgG,GAErBG,EAAKE,OAET,CACIH,EAAiB,GAEnBC,EAAKlF,KAAKqD,EAAO2B,GAAUjG,MAAM,EAAGkG,GAExC,CACA,OAAOC,CACT,CAxXWG,CAAYhC,EAAQvG,EAC7B,CAGA,SAAS8C,IAEP,MAAM,KAACC,EAAI,OAAEmD,EAAM,OAAElD,EAAM,OAAEmD,EAAM,aAAEC,GAAgB5E,EACrD,MAAO,CACLuB,OACAmD,SACAlD,SACAmD,SACAC,eAEJ,CAsBA,SAASwB,IAEP,IAAIY,EACJ,KAAOhH,EAAM2E,OAASI,EAAO1F,QAAQ,CACnC,MAAMyG,EAAQf,EAAO/E,EAAM2E,QAG3B,GAAqB,iBAAVmB,EAKT,IAJAkB,EAAahH,EAAM2E,OACf3E,EAAM4E,aAAe,IACvB5E,EAAM4E,aAAe,GAGrB5E,EAAM2E,SAAWqC,GACjBhH,EAAM4E,aAAekB,EAAMzG,QAE3B4H,EAAGnB,EAAMoB,WAAWlH,EAAM4E,oBAG5BqC,EAAGnB,EAEP,CACF,CAQA,SAASmB,EAAGhJ,GACV+G,OAAWpF,EACX0G,EAAerI,EACfsI,EAAQA,EAAMtI,EAChB,CAsEA,SAASwH,EAAkB0B,EAAG5B,GAC5BA,EAAK6B,SACP,CAQA,SAAS/B,EAAiBgC,EAAUlC,GAClC,OAWA,SAAcpH,EAAYuJ,EAAaC,GAErC,IAAIC,EAEAC,EAEA9G,EAEA4E,EACJ,OAAOmC,MAAMC,QAAQ5J,GACjB6J,EAAuB7J,GACvB,aAAcA,EAEd6J,EAAuB,CAAC7J,IAS5B,SAA+B8J,GAC7B,OAAOzI,EAGP,SAASA,EAAMnB,GACb,MAAM6J,EAAe,OAAT7J,GAAiB4J,EAAI5J,GAC3B8J,EAAe,OAAT9J,GAAiB4J,EAAIlF,KAOjC,OAAOiF,EANM,IAGPF,MAAMC,QAAQG,GAAOA,EAAMA,EAAM,CAACA,GAAO,MACzCJ,MAAMC,QAAQI,GAAOA,EAAMA,EAAM,CAACA,GAAO,IAExCH,CAA6B3J,EACtC,CACF,CAvBI+J,CAAsBjK,GA+B1B,SAAS6J,EAAuB/E,GAG9B,OAFA2E,EAAmB3E,EACnB4E,EAAiB,EACG,IAAhB5E,EAAKxD,OACAkI,EAEFU,EAAgBpF,EAAK4E,GAC9B,CAQA,SAASQ,EAAgB3C,GACvB,OAGA,SAAerH,GAKbsH,EAwER,WACE,MAAM2C,EAAa5G,IACb6G,EAAgBjD,EAAQ3G,SACxB6J,EAAwBlD,EAAQvE,iBAChC0H,EAAmBnD,EAAQnF,OAAOV,OAClCiJ,EAAaZ,MAAMjD,KAAK1F,GAC9B,MAAO,CACLqI,UACA3C,KAAM4D,GAQR,SAASjB,IACPpH,EAAQkI,EACRhD,EAAQ3G,SAAW4J,EACnBjD,EAAQvE,iBAAmByH,EAC3BlD,EAAQnF,OAAOV,OAASgJ,EACxBtJ,EAAQuJ,EACRrD,GACF,CACF,CAhGesD,GACP5H,EAAmB2E,EACdA,EAAUkD,UACbtD,EAAQvE,iBAAmB2E,GAK7B,GACEA,EAAUmD,MACVvD,EAAQpH,OAAOC,WAAW2E,QAAQC,KAAKC,SAAS0C,EAAUmD,MAE1D,OAAOhG,EAAIxE,GAEb,OAAOqH,EAAU7H,SAAS8E,KAIxB4C,EAAS7E,OAAOC,OAAOD,OAAOoI,OAAOxD,GAAUC,GAAUD,EACzDxH,EACA8E,EACAC,EAPK6C,CAQLrH,EACJ,CACF,CAGA,SAASuE,EAAGvE,GAGV,OAFA+G,GAAW,EACXqC,EAAS1G,EAAkB4E,GACpB+B,CACT,CAGA,SAAS7E,EAAIxE,GAGX,OAFA+G,GAAW,EACXO,EAAK6B,YACCK,EAAiBD,EAAiBnI,OAC/B4I,EAAgBT,EAAiBC,IAEnCF,CACT,CACF,CACF,CAOA,SAAS/B,EAAUF,EAAWb,GACxBa,EAAUe,aAAevB,EAAqBlC,SAAS0C,IACzDR,EAAqBpD,KAAK4D,GAExBA,EAAUqD,UACZnI,EAAAA,EAAAA,GACE0E,EAAQnF,OACR0E,EACAS,EAAQnF,OAAOV,OAASoF,EACxBa,EAAUqD,QAAQzD,EAAQnF,OAAOU,MAAMgE,GAAOS,IAG9CI,EAAUsD,YACZ1D,EAAQnF,OAASuF,EAAUsD,UAAU1D,EAAQnF,OAAQmF,GAEzD,CAuCA,SAASD,IACHjF,EAAMuB,QAAQsD,GAAe7E,EAAM0E,OAAS,IAC9C1E,EAAM0E,OAASG,EAAY7E,EAAMuB,MACjCvB,EAAMwB,QAAUqD,EAAY7E,EAAMuB,MAAQ,EAE9C,CACF,C","sources":["../node_modules/micromark/lib/initialize/content.js","../node_modules/micromark/lib/initialize/document.js","../node_modules/micromark/lib/constructs.js","../node_modules/micromark/lib/create-tokenizer.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  /** @type {Token} */\n  let previous\n  return contentStart\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, contentStart, 'linePrefix')\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter('paragraph')\n    return lineStart(code)\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter('chunkText', {\n      contentType: 'text',\n      previous\n    })\n    if (previous) {\n      previous.next = token\n    }\n    previous = token\n    return data(code)\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit('chunkText')\n      effects.exit('paragraph')\n      effects.consume(code)\n      return\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit('chunkText')\n      return lineStart\n    }\n\n    // Data.\n    effects.consume(code)\n    return data\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n}\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeDocument(effects) {\n  const self = this\n  /** @type {Array<StackItem>} */\n  const stack = []\n  let continued = 0\n  /** @type {TokenizeContext | undefined} */\n  let childFlow\n  /** @type {Token | undefined} */\n  let childToken\n  /** @type {number} */\n  let lineStartOffset\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued]\n      self.containerState = item[1]\n      return effects.attempt(\n        item[0].continuation,\n        documentContinue,\n        checkNewContainers\n      )(code)\n    }\n\n    // Done.\n    return checkNewContainers(code)\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined\n      if (childFlow) {\n        closeFlow()\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          point = self.events[indexBeforeFlow][1].end\n          break\n        }\n      }\n      exitContainers(continued)\n\n      // Fix positions.\n      let index = indexBeforeExits\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n      return checkNewContainers(code)\n    }\n    return start(code)\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code)\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code)\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(\n        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack\n      )\n    }\n\n    // Check if there is a new container.\n    self.containerState = {}\n    return effects.check(\n      containerConstruct,\n      thereIsANewContainer,\n      thereIsNoNewContainer\n    )(code)\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow()\n    exitContainers(continued)\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length\n    lineStartOffset = self.now().offset\n    return flowStart(code)\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++\n    stack.push([self.currentConstruct, self.containerState])\n    // Try another.\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow()\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n    return flowContinue(code)\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit('chunkFlow'), true)\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      writeToChild(effects.exit('chunkFlow'))\n      // Get ready for the next line.\n      continued = 0\n      self.interrupt = undefined\n      return start\n    }\n    effects.consume(code)\n    return flowContinue\n  }\n\n  /**\n   * @param {Token} token\n   * @param {boolean | undefined} [eof]\n   * @returns {void}\n   */\n  function writeToChild(token, eof) {\n    const stream = self.sliceStream(token)\n    if (eof) stream.push(null)\n    token.previous = childToken\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.defineSkip(token.start)\n    childFlow.write(stream)\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length\n      while (index--) {\n        if (\n          // The token starts before the line ending…\n          childFlow.events[index][1].start.offset < lineStartOffset &&\n          // …and either is not ended yet…\n          (!childFlow.events[index][1].end ||\n            // …or ends after it.\n            childFlow.events[index][1].end.offset > lineStartOffset)\n        ) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {boolean | undefined} */\n      let seen\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end\n            break\n          }\n          seen = true\n        }\n      }\n      exitContainers(continued)\n\n      // Fix positions.\n      index = indexBeforeExits\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n    }\n  }\n\n  /**\n   * @param {number} size\n   * @returns {void}\n   */\n  function exitContainers(size) {\n    let index = stack.length\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index]\n      self.containerState = entry[1]\n      entry[0].exit.call(self, effects)\n    }\n    stack.length = size\n  }\n  function closeFlow() {\n    childFlow.write([null])\n    childToken = undefined\n    childFlow = undefined\n    self.containerState._closeFlow = undefined\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4\n  )\n}\n","/**\n * @typedef {import('micromark-util-types').Extension} Extension\n */\n\nimport {\n  attention,\n  autolink,\n  blockQuote,\n  characterEscape,\n  characterReference,\n  codeFenced,\n  codeIndented,\n  codeText,\n  definition,\n  hardBreakEscape,\n  headingAtx,\n  htmlFlow,\n  htmlText,\n  labelEnd,\n  labelStartImage,\n  labelStartLink,\n  lineEnding,\n  list,\n  setextUnderline,\n  thematicBreak\n} from 'micromark-core-commonmark'\nimport {resolver as resolveText} from './initialize/text.js'\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n}\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n}\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n}\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n}\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n}\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n}\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n}\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n}\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n}\n","/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenType} TokenType\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * @callback Restore\n * @returns {void}\n *\n * @typedef Info\n * @property {Restore} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {void}\n */\n\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {push, splice} from 'micromark-util-chunked'\nimport {resolveAll} from 'micromark-util-resolve-all'\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(\n    from\n      ? Object.assign({}, from)\n      : {\n          line: 1,\n          column: 1,\n          offset: 0\n        },\n    {\n      _index: 0,\n      _bufferIndex: -1\n    }\n  )\n  /** @type {Record<string, number>} */\n  const columnStart = {}\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = []\n  /** @type {Array<Chunk>} */\n  let chunks = []\n  /** @type {Array<Token>} */\n  let stack = []\n  /** @type {boolean | undefined} */\n  let consumed = true\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  }\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    previous: null,\n    code: null,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  }\n\n  /**\n   * The state function.\n   *\n   * @type {State | void}\n   */\n  let state = initialize.tokenize.call(context, effects)\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n  return context\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice)\n    main()\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n    addResult(initialize, 0)\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n    return context.events\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs)\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {line, column, offset, _index, _bufferIndex} = point\n    return {\n      line,\n      column,\n      offset,\n      _index,\n      _bufferIndex\n    }\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {void}\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index]\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {void}\n   */\n  function go(code) {\n    consumed = undefined\n    expectedCode = code\n    state = state(code)\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++\n\n      // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code\n\n    // Mark as consumed.\n    consumed = true\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {}\n    token.type = type\n    token.start = now()\n    context.events.push(['enter', token, context])\n    stack.push(token)\n    return token\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop()\n    token.end = now()\n    context.events.push(['exit', token, context])\n    return token\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore()\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   */\n  function constructFactory(onreturn, fields) {\n    return hook\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | Construct | ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State | undefined} [bogusState]\n     * @returns {State}\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Array<Construct>} */\n      let listOfConstructs\n      /** @type {number} */\n      let constructIndex\n      /** @type {Construct} */\n      let currentConstruct\n      /** @type {Info} */\n      let info\n      return Array.isArray(constructs) /* c8 ignore next 1 */\n        ? handleListOfConstructs(constructs)\n        : 'tokenize' in constructs\n        ? // @ts-expect-error Looks like a construct.\n          handleListOfConstructs([constructs])\n        : handleMapOfConstructs(constructs)\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n      function handleMapOfConstructs(map) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          const def = code !== null && map[code]\n          const all = code !== null && map.null\n          const list = [\n            // To do: add more extension tests.\n            /* c8 ignore next 2 */\n            ...(Array.isArray(def) ? def : def ? [def] : []),\n            ...(Array.isArray(all) ? all : all ? [all] : [])\n          ]\n          return handleListOfConstructs(list)(code)\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Array<Construct>} list\n       * @returns {State}\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n        if (list.length === 0) {\n          return bogusState\n        }\n        return handleConstruct(list[constructIndex])\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n      function handleConstruct(construct) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          // Always populated by defaults.\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.includes(construct.name)\n          ) {\n            return nok(code)\n          }\n          return construct.tokenize.call(\n            // If we do have fields, create an object w/ `context` as its\n            // prototype.\n            // This allows a “live binding”, which is needed for `interrupt`.\n            fields ? Object.assign(Object.create(context), fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true\n        info.restore()\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n        return bogusState\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {void}\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct)\n    }\n    if (construct.resolve) {\n      splice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n  function store() {\n    const startPoint = now()\n    const startPrevious = context.previous\n    const startCurrentConstruct = context.currentConstruct\n    const startEventsIndex = context.events.length\n    const startStack = Array.from(stack)\n    return {\n      restore,\n      from: startEventsIndex\n    }\n\n    /**\n     * Restore state.\n     *\n     * @returns {void}\n     */\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {void}\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Array<Chunk>} chunks\n * @param {Pick<Token, 'end' | 'start'>} token\n * @returns {Array<Chunk>}\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index\n  const startBufferIndex = token.start._bufferIndex\n  const endIndex = token.end._index\n  const endBufferIndex = token.end._bufferIndex\n  /** @type {Array<Chunk>} */\n  let view\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n    if (startBufferIndex > -1) {\n      const head = view[0]\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex)\n      } else {\n        view.shift()\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n  return view\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Array<Chunk>} chunks\n * @param {boolean | undefined} [expandTabs=false]\n * @returns {string}\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1\n  /** @type {Array<string>} */\n  const result = []\n  /** @type {boolean | undefined} */\n  let atTab\n  while (++index < chunks.length) {\n    const chunk = chunks[index]\n    /** @type {string} */\n    let value\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else\n      switch (chunk) {\n        case -5: {\n          value = '\\r'\n          break\n        }\n        case -4: {\n          value = '\\n'\n          break\n        }\n        case -3: {\n          value = '\\r' + '\\n'\n          break\n        }\n        case -2: {\n          value = expandTabs ? ' ' : '\\t'\n          break\n        }\n        case -1: {\n          if (!expandTabs && atTab) continue\n          value = ' '\n          break\n        }\n        default: {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk)\n        }\n      }\n    atTab = chunk === -2\n    result.push(value)\n  }\n  return result.join('')\n}\n"],"names":["content","tokenize","effects","contentStart","attempt","this","parser","constructs","contentInitial","code","consume","enter","exit","factorySpace","lineStart","previous","token","contentType","next","data","markdownLineEnding","document","self","stack","childFlow","childToken","lineStartOffset","continued","start","length","item","containerState","continuation","documentContinue","checkNewContainers","_closeFlow","undefined","closeFlow","indexBeforeExits","events","point","indexBeforeFlow","type","end","exitContainers","index","Object","assign","splice","slice","documentContinued","currentConstruct","concrete","flowStart","interrupt","Boolean","_gfmTableDynamicInterruptHack","check","containerConstruct","thereIsANewContainer","thereIsNoNewContainer","lazy","now","line","offset","containerContinue","push","flow","_tokenizer","flowContinue","writeToChild","eof","stream","sliceStream","defineSkip","write","seen","size","entry","call","ok","nok","disable","null","includes","list","blockQuote","definition","flowInitial","codeIndented","headingAtx","thematicBreak","setextUnderline","htmlFlow","codeFenced","string","characterReference","characterEscape","text","lineEnding","labelStartImage","attention","autolink","htmlText","labelStartLink","hardBreakEscape","labelEnd","codeText","insideSpan","resolveText","attentionMarkers","createTokenizer","initialize","from","column","_index","_bufferIndex","columnStart","resolveAllConstructs","chunks","consumed","accountForPotentialSkip","context","fields","pop","constructFactory","construct","info","addResult","onsuccessfulcheck","sliceSerialize","expandTabs","result","atTab","chunk","value","String","fromCharCode","join","serializeChunks","main","resolveAll","expectedCode","state","startIndex","startBufferIndex","endIndex","endBufferIndex","view","head","shift","sliceChunks","chunkIndex","go","charCodeAt","_","restore","onreturn","returnState","bogusState","listOfConstructs","constructIndex","Array","isArray","handleListOfConstructs","map","def","all","handleMapOfConstructs","handleConstruct","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","store","partial","name","create","resolve","resolveTo"],"sourceRoot":""}