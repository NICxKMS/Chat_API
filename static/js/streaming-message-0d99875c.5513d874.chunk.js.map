{"version":3,"file":"static/js/streaming-message-0d99875c.5513d874.chunk.js","mappings":"4KAkDA,MAAMA,EAAkB,MAClBC,EAAoB,UAEpBC,GAAKC,EAAAA,EAAAA,GAAe,MACpBC,GAAOD,EAAAA,EAAAA,IAyjBb,SAAgBE,GACd,MAAwB,OAAjBA,EAAKC,SAAqC,OAAjBD,EAAKC,OACvC,IA1jBMC,GAAIJ,EAAAA,EAAAA,GAAe,KACnBK,GAAML,EAAAA,EAAAA,GAAe,MAIrBM,GAAcN,EAAAA,EAAAA,GAAe,CAEjC,WACA,OACA,UACA,WACA,WACA,KACA,SACA,QACA,WACA,QA+hBF,SAAgBE,GACd,OAAOK,SAASL,EAAKM,YAAc,CAAC,GAAGC,OACzC,EAcA,SAAsBP,GACpB,MAAwB,WAAjBA,EAAKC,WAA0BD,EAAKM,YAAc,CAAC,GAAGE,IAC/D,IAziBMC,GAAiBX,EAAAA,EAAAA,GAAe,CACpC,UACA,UACA,QACA,aACA,OACA,UACA,SACA,KACA,SACA,MACA,KACA,KACA,MACA,SACA,aACA,SACA,QACA,KACA,KACA,KACA,KACA,KACA,KACA,SACA,SACA,KACA,OACA,SACA,KACA,UACA,OACA,OACA,MACA,KACA,IACA,YACA,MACA,UACA,KACA,QAoCK,SAASY,EAAOC,EAAMC,GAC3B,MAAMC,EAAWD,GAAW,CAAC,EACvBE,EAAW,aAAcH,EAAOA,EAAKG,SAAW,GAChDC,EAAQN,EAAeE,GACvBK,EAAaC,EAAgBN,EAAM,CACvCK,WAAYH,EAASG,YAAc,SACnCE,aAAa,EACbC,YAAY,IAIRC,EAAU,GAUE,SAAdT,EAAKU,MAAiC,YAAdV,EAAKU,MAC/BD,EAAQE,QACHC,EAAYZ,EAAM,CACnBK,aACAE,aAAa,EACbC,YAAY,KAgBlB,IAAIK,GAAS,EAGb,OAASA,EAAQV,EAASW,QAMxBL,EAAQE,QACHI,EACDZ,EAASU,GAETb,EACA,CACEK,aACAE,YAAaM,OAAQG,EAAYZ,EACjCI,WACEK,EAAQV,EAASW,OAAS,EAAI5B,EAAGiB,EAASU,EAAQ,IAAMT,KAclE,MAAMa,EAAS,GAEf,IAAIC,EAIJ,IAFAL,GAAS,IAEAA,EAAQJ,EAAQK,QAAQ,CAC/B,MAAMK,EAAQV,EAAQI,GAED,iBAAVM,OACKH,IAAVE,GAAuBC,EAAQD,IAAOA,EAAQC,GACzCA,SACKH,IAAVE,GAAuBA,GAAS,GAClCD,EAAON,KAAK,KAAKS,OAAOF,IAAU,KAGpCA,GAAS,EACTD,EAAON,KAAKQ,GAEhB,CAGA,OAAOF,EAAOI,KAAK,GACrB,CAUA,SAASN,EAAuB1B,EAAMiC,EAAQC,GAC5C,MAAkB,YAAdlC,EAAKqB,KAuBX,SAAwBrB,EAAMiC,EAAQC,GAEpC,MAAMlB,EAAaC,EAAgBjB,EAAMkC,GACnCpB,EAAWd,EAAKc,UAAY,GAClC,IAWIqB,EAEAC,EAbAZ,GAAS,EAETa,EAAQ,GAIZ,GAAIjC,EAAYJ,GACd,OAAOqC,EAuBLxC,EAAGG,IAaLG,EAAIH,KAEJsC,EAAAA,EAAAA,GAAUL,EAAQjC,EAAMG,GAdxBiC,EAAS,KAqBFlC,EAAEF,IACTmC,EAAS,EACTC,EAAS,GAMF3B,EAAeT,KACtBmC,EAAS,EACTC,EAAS,GAMX,OAASZ,EAAQV,EAASW,QACxBY,EAAQA,EAAME,OACZb,EAAuBZ,EAASU,GAAQxB,EAAM,CAC5CgB,aACAE,YAAaM,OAAQG,EAAYQ,EACjChB,WACEK,EAAQV,EAASW,OAAS,EAAI5B,EAAGiB,EAASU,EAAQ,IAAMY,KAY9DrC,EAAKC,KAELsC,EAAAA,EAAAA,GAAUL,EAAQjC,EAAMD,IAExBsC,EAAMf,KAAK,MAITa,GAAQE,EAAMG,QAAQL,GACtBC,GAAQC,EAAMf,KAAKc,GAEvB,OAAOC,CACT,CA5HWI,CAAezC,EAAMiC,EAAQC,GAGpB,SAAdlC,EAAKqB,KACoB,WAApBa,EAAKlB,WACRO,EAAYvB,EAAMkC,GA8O1B,SAAwBlC,GACtB,MAAO,CAAC0C,OAAO1C,EAAK8B,OACtB,CA/OQa,CAAe3C,GAGd,EACT,CA4IA,SAASuB,EAAYvB,EAAMkC,GACzB,MAAMJ,EAAQY,OAAO1C,EAAK8B,OAEpBc,EAAQ,GAERhB,EAAS,GACf,IAAIiB,EAAQ,EAEZ,KAAOA,GAASf,EAAML,QAAQ,CAC5B9B,EAAgBmD,UAAYD,EAE5B,MAAME,EAAQpD,EAAgBqD,KAAKlB,GAC7BmB,EAAMF,GAAS,UAAWA,EAAQA,EAAMvB,MAAQM,EAAML,OAE5DmB,EAAMtB,KAGJ4B,EAIEpB,EACGqB,MAAMN,EAAOI,GACbG,QAAQ,kDAAmD,IACpD,IAAVP,GAAcX,EAAKhB,YACnB+B,IAAQnB,EAAML,QAASS,EAAKf,aAIhC0B,EAAQI,EAAM,CAChB,CAOA,IAEIjB,EAFAR,GAAS,EAIb,OAASA,EAAQoB,EAAMnB,QAKkC,OAArDmB,EAAMpB,GAAO6B,WAAWT,EAAMpB,GAAOC,OAAS,IAC7CD,EAAQoB,EAAMnB,OAAS,GACa,OAAnCmB,EAAMpB,EAAQ,GAAG6B,WAAW,IAE9BzB,EAAON,KAAKsB,EAAMpB,IAClBQ,OAAOL,GAmBAiB,EAAMpB,IACO,iBAATQ,GAAmBJ,EAAON,KAAKU,GAC1CJ,EAAON,KAAKsB,EAAMpB,IAClBQ,EAAO,GACY,IAAVR,GAAeA,IAAUoB,EAAMnB,OAAS,GAIjDG,EAAON,KAAK,GAIhB,OAAOM,CACT,CA+BA,SAASsB,EAA6BpB,EAAOZ,EAAaC,GAExD,MAAMS,EAAS,GACf,IAEIqB,EAFAJ,EAAQ,EAIZ,KAAOA,EAAQf,EAAML,QAAQ,CAC3B7B,EAAkBkD,UAAYD,EAC9B,MAAME,EAAQnD,EAAkBoD,KAAKlB,GACrCmB,EAAMF,EAAQA,EAAMvB,MAAQM,EAAML,OAI7BoB,GAAUI,IAAOF,GAAU7B,GAC9BU,EAAON,KAAK,IAGVuB,IAAUI,GACZrB,EAAON,KAAKQ,EAAMqB,MAAMN,EAAOI,IAGjCJ,EAAQE,EAAQE,EAAMF,EAAM,GAAGtB,OAASwB,CAC1C,CASA,OAJIJ,IAAUI,GAAQ9B,GACpBS,EAAON,KAAK,IAGPM,EAAOI,KAAK,IACrB,CAcA,SAASf,EAAgBjB,EAAMkC,GAC7B,GAAkB,YAAdlC,EAAKqB,KAAoB,CAC3B,MAAMf,EAAaN,EAAKM,YAAc,CAAC,EACvC,OAAQN,EAAKC,SACX,IAAK,UACL,IAAK,YACL,IAAK,MACH,MAAO,MAGT,IAAK,OACH,MAAO,SAGT,IAAK,MACH,OAAOK,EAAWgD,KAAO,WAAa,MAGxC,IAAK,KACL,IAAK,KACH,OAAOhD,EAAWiD,OAAS,SAAWrB,EAAKlB,WAG7C,IAAK,WACH,MAAO,WAKb,CAEA,OAAOkB,EAAKlB,UACd,C,yICtjBA,MAAMwC,EACJ,+FAIIC,EAAgB,IAAIC,IAAI,CAC5B,oBACA,oBACA,oBACA,oBACA,aAIIC,EAAe,CAACC,wBAAwB,EAAMC,kBAAkB,GAa/D,SAASC,EAAInD,EAAMC,GACxB,MAAMmD,EA4iBR,SAAsB/D,GACpB,MAAMgE,EAAqB,SAAdhE,EAAKqB,KAAkBrB,EAAKc,SAAS,GAAKd,EACvD,OAAOK,QACL2D,IACiB,YAAdA,EAAK3C,MACW,YAAd2C,EAAK3C,MAAqD,SAA/B2C,EAAK/D,QAAQgE,eAEjD,CAnjBmBC,CAAavD,GAExBwD,GAAMC,EAAAA,EAAAA,GAAO,OAAQ,CACzBC,SAAU,CAACC,OAAMC,UAASC,OAAMC,UAASC,UAASZ,IAAKa,GACvDC,YAIIC,EAAQ,CACZC,OAAQf,EACJ,IAAIgB,EAAAA,GAAOpB,GACXoB,EAAAA,GAAOC,uBAAkBrD,EAAWgC,GACxCsB,MAAAA,CAAOjF,GACLmE,EAAInE,EAAM6E,EACZ,EACAK,UAAU,EACVtE,QAASA,GAAW,CAAC,GAGvBuD,EAAIxD,EAAMkE,GACVM,EAAeN,GAAOO,EAAAA,EAAAA,OAEtB,MAAMC,EAAKtB,EAAWc,EAAMC,OAAOf,SAAWc,EAAMC,OAAOQ,cACrD1D,GAAS2D,EAAAA,EAAAA,GAAWF,EAAI,CAE5BG,KAAMX,EAAMjE,QAAQ4E,OAiBtB,OAdIX,EAAMK,WACRO,EAAAA,EAAAA,IAAM7D,EAAQ,WAAW,SAAU5B,EAAMwB,EAAOS,GAC9C,MAAMyD,EAAwD1F,EAC9D,GAAI0F,EAAO5D,MAAM4D,QAAUzD,QAAoBN,IAAVH,EAAqB,CAKxD,OAHiBS,EAAOnB,SAEfU,GAASkE,EAAO5D,MAAM4D,OACxBlE,CACT,CACF,IAKgB,SAAhBI,EAAOP,MACoB,IAA3BO,EAAOd,SAASW,QAChBG,EAAOd,SAAS,GAAGO,OAASV,EAAKU,KAE1BO,EAAOd,SAAS,GAGlBc,CACT,CAYA,SAAS+D,EAAIC,EAAOf,GAClB,IAAIrD,GAAS,EAGb,GAAIoE,EACF,OAASpE,EAAQoE,EAAMnE,QACrBoD,EAAMI,OAAOW,EAAMpE,GAGzB,CAYA,SAAS8C,EAAKtE,EAAM6E,GAClBc,EAAI3F,EAAKc,SAAU+D,EACrB,CAYA,SAASN,EAAQvE,EAAM6E,IA0UvB,SAAkB7E,EAAM6E,GACtB,MAAM5E,EAAUD,EAAKC,QAAQgE,cAG7B,GAAIY,EAAMC,OAAOe,UAAUhB,QAAUiB,EAAAA,GAAcC,UAAW,OAE9DZ,EAAeN,GAAOO,EAAAA,EAAAA,IAAWpF,IAEjC,MAAMgG,EAAUnB,EAAMC,OAAOmB,aAAaD,QAC1C,IAAIE,EAAK,iBAAkBF,EAAUA,EAAQG,aAAeC,EAAAA,EAAcC,KAEtEH,IAAOE,EAAAA,EAAcC,MAAoB,QAAZpG,IAC/BiG,EAAKE,EAAAA,EAAcE,KAGrB,MAAM1E,GAAS2E,EAAAA,EAAAA,GAEb,IAAIvG,EAAMc,SAAU,IACpB,CAAC0F,MAAON,IAAOE,EAAAA,EAAcE,IAAM,MAAQ,SAIvCG,EAAM,CACVpF,KAAMqF,EAAAA,GAAAA,EAAgBC,UACtB1G,UACA2G,MAAOP,EAAAA,GAAAA,SAAcpG,GAErB4G,aAAa,EACbC,gBAAgB,EAGhBC,MAAO,UAAWnF,EAASA,EAAOmF,MAAQ,GAC1CC,SAAUC,EAAqBjH,IASjC6E,EAAMC,OAAOoC,aAAeT,EAE5B5B,EAAMC,OAAOqC,cAActC,EAAMC,OAAOoC,cAMxCrC,EAAMC,OAAOe,UAAUuB,iBAAmBnH,CAG5C,CA7XEoH,CAASrH,EAAM6E,GAEfc,EAAI3F,EAAKc,SAAU+D,GAuYrB,SAAgB7E,EAAM6E,GACpB,MAAM5E,EAAUD,EAAKC,QAAQgE,cAE7B,IACGY,EAAMC,OAAOe,UAAUyB,eACxBC,EAAAA,EAAiBC,SAASvH,GAE1B,OAIF,GAAI4E,EAAMC,OAAOe,UAAUhB,QAAUiB,EAAAA,GAAcC,UAAW,OAE9DZ,EAAeN,GAAO4C,EAAAA,EAAAA,GAASzH,IAG/B,MAAMyG,EAAM,CACVpF,KAAMqF,EAAAA,GAAAA,EAAgBgB,QACtBzH,UACA2G,MAAOP,EAAAA,GAAAA,SAAcpG,GACrB4G,aAAa,EACbC,gBAAgB,EAChBC,MAAO,GACPC,SAAUC,EAAqBjH,IASjC6E,EAAMC,OAAOoC,aAAeT,EAE5B5B,EAAMC,OAAOqC,cAActC,EAAMC,OAAOoC,cAStCjH,IAAY4E,EAAMC,OAAOe,UAAUuB,kBAElCvC,EAAMC,OAAOe,UAAUhB,QAAUiB,EAAAA,GAAc6B,QAE9C9C,EAAMC,OAAOe,UAAUhB,QAAUiB,EAAAA,GAAc8B,SAE/C/C,EAAMC,OAAOe,UAAUhB,QAAUiB,EAAAA,GAAc+B,cAGjDhD,EAAMC,OAAOe,UAAUhB,MAAQiB,EAAAA,GAAcgC,KAEjD,CA3bEC,CAAO/H,EAAM6E,EACf,CAYA,SAASL,EAAKxE,EAAM6E,GAMdA,EAAMC,OAAOe,UAAUhB,MAAQ,IACjCA,EAAMC,OAAOe,UAAUhB,MAAQ,GAIjC,MAAMmD,EAAQ,CACZ3G,KAAMqF,EAAAA,GAAAA,EAAgBuB,UACtBC,MAAOlI,EAAK8B,MACZkF,SAAUC,EAAqBjH,IAGjCmF,EAAeN,GAAOO,EAAAA,EAAAA,IAAWpF,IAEjC6E,EAAMC,OAAOoC,aAAec,EAE5BnD,EAAMC,OAAOqC,cAActC,EAAMC,OAAOoC,aAC1C,CAYA,SAASxC,EAAQ1E,EAAM6E,GAErB,MAAMmD,EAAQ,CACZ3G,KAAMqF,EAAAA,GAAAA,EAAgByB,QACtBC,KAAM,OACNC,aAAa,EACbC,SAAU,GACVC,SAAU,GACVvB,SAAUC,EAAqBjH,IAGjCmF,EAAeN,GAAOO,EAAAA,EAAAA,IAAWpF,IAEjC6E,EAAMC,OAAOoC,aAAec,EAE5BnD,EAAMC,OAAOqC,cAActC,EAAMC,OAAOoC,aAC1C,CAYA,SAASxB,EAAO1F,EAAM6E,GAEpBA,EAAMK,UAAW,EAGjB,MAAMsD,EAyaR,SAA8BxI,GAC5B,MAAO,aAAcA,GACjByI,EAAAA,EAAAA,IAAgB,IAAIzI,EAAMc,SAAU,MACpC2H,EAAAA,EAAAA,IAAgBzI,EACtB,CA7agB0I,CAAqB1I,GAInC,GAAI,aAAcA,GAAQ,aAAcwI,EAAO,CAE7C,MAAMG,EACJ7E,EAAI,CAACzC,KAAM,OAAQP,SAAUd,EAAKc,UAAW+D,EAAMjE,SAErD4H,EAAM1H,SAAW6H,EAAS7H,QAC5B,CAKA2D,EAAQ,CAACpD,KAAM,UAAWS,MAAO,CAAC4D,OAAQ8C,IAAS3D,EACrD,CAYA,SAASJ,EAAQzE,EAAM6E,GAGrB,MAAM+D,EAAO5I,EAAK8B,MAGZkG,EAAQ,CACZ3G,KAAMqF,EAAAA,GAAAA,EAAgBmC,QACtBD,OACA5B,SAAUC,EAAqBjH,IAEjCmF,EAAeN,GAAOO,EAAAA,EAAAA,IAAWpF,IAEjC6E,EAAMC,OAAOoC,aAAec,EAE5BnD,EAAMC,OAAOqC,cAActC,EAAMC,OAAOoC,aAC1C,CAYA,SAASvC,EAAU3E,EAAM6E,GA4CvB,GAzCAA,EAAMC,OAAOe,UAAUiD,aAAazC,KAAO,GAC3CxB,EAAMC,OAAOe,UAAUiD,aAAaC,KAAO,EAG3ClE,EAAMC,OAAOe,UAAUiD,aAAaE,YAAc,EAGlDnE,EAAMC,OAAOe,UAAUiD,aAAaG,SAAW,GAG/CpE,EAAMC,OAAOe,UAAUiD,aAAaI,iBAAkB,EACtDrE,EAAMC,OAAOe,UAAUiD,aAAaK,kBAAmB,EACvDtE,EAAMC,OAAOe,UAAUiD,aAAaM,eAAgB,EAGpDvE,EAAMC,OAAOe,UAAUiD,aAAaO,OAAQ,EAG5CC,EAASzE,GAAOO,EAAAA,EAAAA,IAAWpF,IAE3B6E,EAAMC,OAAOe,UAAU0D,MACrB1E,EAAMjE,QAAQ4I,UACVxJ,EAAK8B,MAAMsB,QAAQI,EAAwB,YAC3CxD,EAAK8B,OACT,GAGF+C,EAAMC,OAAOe,UAAU4D,kBAeY,KAAjC5E,EAAMC,OAAOe,UAAUhB,OAEU,KAAjCA,EAAMC,OAAOe,UAAUhB,MACvB,CACAA,EAAMC,OAAOe,UAAUiD,aAAaK,kBAAmB,EAGvD,MAAMO,EAAK7E,EAAMC,OAAOe,UAAU8D,WAElC9E,EAAMC,OAAOe,UAAU+D,WAAWF,EACpC,CACF,CAYA,SAAS9E,EAAQiF,EAAOhF,GACtB,MAAM7E,EAA6B6J,EAEnC,IACEhF,EAAMjE,QAAQkJ,cACdjF,EAAMjE,QAAQkJ,YAAYtC,SAASxH,EAAKqB,MAGnC,CACL,IAAI0I,EAAQ,GAOZ,MALItG,EAAcuG,IAAIhK,EAAKqB,QACzB0I,EACE,0cAGE,IAAIE,MAAM,mBAAqBjK,EAAKqB,KAAO,SAAW0I,EAC9D,CAVErE,EAAO1F,EAAM6E,EAWjB,CAYA,SAASM,EAAeN,EAAOqF,GAC7BZ,EAASzE,EAAOqF,GAKhB,MAAMlC,EAAQnD,EAAMC,OAAOe,UAAUsE,sBAEjCnC,GAASA,EAAMhB,WACjBgB,EAAMhB,SAASoD,QAAUvF,EAAMC,OAAOe,UAAUiD,aAAauB,KAC7DrC,EAAMhB,SAASsD,OAASzF,EAAMC,OAAOe,UAAUiD,aAAayB,IAAM,EAClEvC,EAAMhB,SAASwD,UAAY3F,EAAMC,OAAOe,UAAUiD,aAAa2B,OAAS,EAExE5F,EAAMC,OAAOoC,aAAec,EAE5BnD,EAAMC,OAAOqC,cAActC,EAAMC,OAAOoC,eAW1CrC,EAAMC,OAAOe,UAAU6E,QAAS,EAEhC7F,EAAMC,OAAOe,UAAU8E,QAAS,EAIhC9F,EAAMC,OAAOe,UAAU+E,QAAS,EAEhC/F,EAAMC,OAAOe,UAAUgF,YAAc/E,EAAAA,GAAcgC,KAEnDjD,EAAMC,OAAOe,UAAUiF,aAAe,EAEtCjG,EAAMC,OAAOe,UAAUkF,uBAAyB,EAEhDlG,EAAMC,OAAOe,UAAUmF,gBAAkB,KAEzCnG,EAAMC,OAAOe,UAAUsE,sBAAwB,KAE/CtF,EAAMC,OAAOe,UAAUqB,aAAe,KAEtCrC,EAAMC,OAAOe,UAAUoF,YAAc,CAAC7C,KAAM,GAAItG,MAAO,GACzD,CAYA,SAASwH,EAASzE,EAAOqF,GACvB,GAAIA,QAA0BvI,IAAjBuI,EAAMO,OAAsB,CAEvC,MAAMzD,EAAW,CACfkE,UAAWhB,EAAMG,KACjBc,SAAUjB,EAAMkB,OAChBC,YAAanB,EAAMO,OACnBL,SAAU,EACVE,QAAS,EACTE,WAAY,GAKd3F,EAAMC,OAAOe,UAAUiD,aAAawC,aAA+B,EAAfpB,EAAMkB,OAC1DvG,EAAMC,OAAOe,UAAUiD,aAAayC,kBAAoBrB,EAAMO,OAC9D5F,EAAMC,OAAOe,UAAUiD,aAAauB,KAAOH,EAAMG,KAEjDxF,EAAMC,OAAOe,UAAUmF,gBAAkBhE,CAC3C,CACF,CA6JA,SAASC,EAAqBjH,GAC5B,MAAM6C,GAAQuC,EAAAA,EAAAA,IAAWpF,IAAS,CAChCqK,UAAM1I,EACNyJ,YAAQzJ,EACR8I,YAAQ9I,GAEJsB,GAAMwE,EAAAA,EAAAA,GAASzH,IAAS,CAC5BqK,UAAM1I,EACNyJ,YAAQzJ,EACR8I,YAAQ9I,GAeV,MAXiB,CACfuJ,UAAWrI,EAAMwH,KACjBc,SAAUtI,EAAMuI,OAChBC,YAAaxI,EAAM4H,OACnBL,QAASnH,EAAIoH,KACbC,OAAQrH,EAAImI,OACZZ,UAAWvH,EAAIwH,OAMnB,C","sources":["../node_modules/hast-util-to-text/lib/index.js","../node_modules/hast-util-raw/lib/index.js"],"sourcesContent":["/**\n * @typedef {import('hast').Comment} Comment\n * @typedef {import('hast').Element} Element\n * @typedef {import('hast').Nodes} Nodes\n * @typedef {import('hast').Parents} Parents\n * @typedef {import('hast').Text} Text\n * @typedef {import('hast-util-is-element').TestFunction} TestFunction\n */\n\n/**\n * @typedef {'normal' | 'nowrap' | 'pre' | 'pre-wrap'} Whitespace\n *   Valid and useful whitespace values (from CSS).\n *\n * @typedef {0 | 1 | 2} BreakNumber\n *   Specific break:\n *\n *   *   `0` â€” space\n *   *   `1` â€” line ending\n *   *   `2` â€” blank line\n *\n * @typedef {'\\n'} BreakForce\n *   Forced break.\n *\n * @typedef {boolean} BreakValue\n *   Whether there was a break.\n *\n * @typedef {BreakNumber | BreakValue | undefined} BreakBefore\n *   Any value for a break before.\n *\n * @typedef {BreakForce | BreakNumber | BreakValue | undefined} BreakAfter\n *   Any value for a break after.\n *\n * @typedef CollectionInfo\n *   Info on current collection.\n * @property {BreakAfter} breakAfter\n *   Whether there was a break after.\n * @property {BreakBefore} breakBefore\n *   Whether there was a break before.\n * @property {Whitespace} whitespace\n *   Current whitespace setting.\n *\n * @typedef Options\n *   Configuration.\n * @property {Whitespace | null | undefined} [whitespace='normal']\n *   Initial CSS whitespace setting to use (default: `'normal'`).\n */\n\nimport {findAfter} from 'unist-util-find-after'\nimport {convertElement} from 'hast-util-is-element'\n\nconst searchLineFeeds = /\\n/g\nconst searchTabOrSpaces = /[\\t ]+/g\n\nconst br = convertElement('br')\nconst cell = convertElement(isCell)\nconst p = convertElement('p')\nconst row = convertElement('tr')\n\n// Note that we donâ€™t need to include void elements here as they donâ€™t have text.\n// See: <https://github.com/wooorm/html-void-elements>\nconst notRendered = convertElement([\n  // List from: <https://html.spec.whatwg.org/multipage/rendering.html#hidden-elements>\n  'datalist',\n  'head',\n  'noembed',\n  'noframes',\n  'noscript', // Act as if we support scripting.\n  'rp',\n  'script',\n  'style',\n  'template',\n  'title',\n  // Hidden attribute.\n  hidden,\n  // From: <https://html.spec.whatwg.org/multipage/rendering.html#flow-content-3>\n  closedDialog\n])\n\n// See: <https://html.spec.whatwg.org/multipage/rendering.html#the-css-user-agent-style-sheet-and-presentational-hints>\nconst blockOrCaption = convertElement([\n  'address', // Flow content\n  'article', // Sections and headings\n  'aside', // Sections and headings\n  'blockquote', // Flow content\n  'body', // Page\n  'caption', // `table-caption`\n  'center', // Flow content (legacy)\n  'dd', // Lists\n  'dialog', // Flow content\n  'dir', // Lists (legacy)\n  'dl', // Lists\n  'dt', // Lists\n  'div', // Flow content\n  'figure', // Flow content\n  'figcaption', // Flow content\n  'footer', // Flow content\n  'form,', // Flow content\n  'h1', // Sections and headings\n  'h2', // Sections and headings\n  'h3', // Sections and headings\n  'h4', // Sections and headings\n  'h5', // Sections and headings\n  'h6', // Sections and headings\n  'header', // Flow content\n  'hgroup', // Sections and headings\n  'hr', // Flow content\n  'html', // Page\n  'legend', // Flow content\n  'li', // Lists (as `display: list-item`)\n  'listing', // Flow content (legacy)\n  'main', // Flow content\n  'menu', // Lists\n  'nav', // Sections and headings\n  'ol', // Lists\n  'p', // Flow content\n  'plaintext', // Flow content (legacy)\n  'pre', // Flow content\n  'section', // Sections and headings\n  'ul', // Lists\n  'xmp' // Flow content (legacy)\n])\n\n/**\n * Get the plain-text value of a node.\n *\n * ###### Algorithm\n *\n * *   if `tree` is a comment, returns its `value`\n * *   if `tree` is a text, applies normal whitespace collapsing to its\n *     `value`, as defined by the CSS Text spec\n * *   if `tree` is a root or element, applies an algorithm similar to the\n *     `innerText` getter as defined by HTML\n *\n * ###### Notes\n *\n * > ðŸ‘‰ **Note**: the algorithm acts as if `tree` is being rendered, and as if\n * > weâ€™re a CSS-supporting user agent, with scripting enabled.\n *\n * *   if `tree` is an element that is not displayed (such as a `head`), weâ€™ll\n *     still use the `innerText` algorithm instead of switching to `textContent`\n * *   if descendants of `tree` are elements that are not displayed, they are\n *     ignored\n * *   CSS is not considered, except for the default user agent style sheet\n * *   a line feed is collapsed instead of ignored in cases where Fullwidth, Wide,\n *     or Halfwidth East Asian Width characters are used, the same goes for a case\n *     with Chinese, Japanese, or Yi writing systems\n * *   replaced elements (such as `audio`) are treated like non-replaced elements\n *\n * @param {Nodes} tree\n *   Tree to turn into text.\n * @param {Readonly<Options> | null | undefined} [options]\n *   Configuration (optional).\n * @returns {string}\n *   Serialized `tree`.\n */\nexport function toText(tree, options) {\n  const options_ = options || {}\n  const children = 'children' in tree ? tree.children : []\n  const block = blockOrCaption(tree)\n  const whitespace = inferWhitespace(tree, {\n    whitespace: options_.whitespace || 'normal',\n    breakBefore: false,\n    breakAfter: false\n  })\n\n  /** @type {Array<BreakNumber | string>} */\n  const results = []\n\n  // Treat `text` and `comment` as having normal white-space.\n  // This deviates from the spec as in the DOM the nodeâ€™s `.data` has to be\n  // returned.\n  // If you want that behavior use `hast-util-to-string`.\n  // All other nodes are later handled as if they are `element`s (so the\n  // algorithm also works on a `root`).\n  // Nodes without children are treated as a void element, so `doctype` is thus\n  // ignored.\n  if (tree.type === 'text' || tree.type === 'comment') {\n    results.push(\n      ...collectText(tree, {\n        whitespace,\n        breakBefore: true,\n        breakAfter: true\n      })\n    )\n  }\n\n  // 1.  If this element is not being rendered, or if the user agent is a\n  //     non-CSS user agent, then return the same value as the textContent IDL\n  //     attribute on this element.\n  //\n  //     Note: weâ€™re not supporting stylesheets so weâ€™re acting as if the node\n  //     is rendered.\n  //\n  //     If you want that behavior use `hast-util-to-string`.\n  //     Important: weâ€™ll have to account for this later though.\n\n  // 2.  Let results be a new empty list.\n  let index = -1\n\n  // 3.  For each child node node of this element:\n  while (++index < children.length) {\n    // 3.1. Let current be the list resulting in running the inner text\n    //      collection steps with node.\n    //      Each item in results will either be a JavaScript string or a\n    //      positive integer (a required line break count).\n    // 3.2. For each item item in current, append item to results.\n    results.push(\n      ...renderedTextCollection(\n        children[index],\n        // @ts-expect-error: `tree` is a parent if weâ€™re here.\n        tree,\n        {\n          whitespace,\n          breakBefore: index ? undefined : block,\n          breakAfter:\n            index < children.length - 1 ? br(children[index + 1]) : block\n        }\n      )\n    )\n  }\n\n  // 4.  Remove any items from results that are the empty string.\n  // 5.  Remove any runs of consecutive required line break count items at the\n  //     start or end of results.\n  // 6.  Replace each remaining run of consecutive required line break count\n  //     items with a string consisting of as many U+000A LINE FEED (LF)\n  //     characters as the maximum of the values in the required line break\n  //     count items.\n  /** @type {Array<string>} */\n  const result = []\n  /** @type {number | undefined} */\n  let count\n\n  index = -1\n\n  while (++index < results.length) {\n    const value = results[index]\n\n    if (typeof value === 'number') {\n      if (count !== undefined && value > count) count = value\n    } else if (value) {\n      if (count !== undefined && count > -1) {\n        result.push('\\n'.repeat(count) || ' ')\n      }\n\n      count = -1\n      result.push(value)\n    }\n  }\n\n  // 7.  Return the concatenation of the string items in results.\n  return result.join('')\n}\n\n/**\n * <https://html.spec.whatwg.org/multipage/dom.html#rendered-text-collection-steps>\n *\n * @param {Nodes} node\n * @param {Parents} parent\n * @param {CollectionInfo} info\n * @returns {Array<BreakNumber | string>}\n */\nfunction renderedTextCollection(node, parent, info) {\n  if (node.type === 'element') {\n    return collectElement(node, parent, info)\n  }\n\n  if (node.type === 'text') {\n    return info.whitespace === 'normal'\n      ? collectText(node, info)\n      : collectPreText(node)\n  }\n\n  return []\n}\n\n/**\n * Collect an element.\n *\n * @param {Element} node\n *   Element node.\n * @param {Parents} parent\n * @param {CollectionInfo} info\n *   Info on current collection.\n * @returns {Array<BreakNumber | string>}\n */\nfunction collectElement(node, parent, info) {\n  // First we infer the `white-space` property.\n  const whitespace = inferWhitespace(node, info)\n  const children = node.children || []\n  let index = -1\n  /** @type {Array<BreakNumber | string>} */\n  let items = []\n\n  // Weâ€™re ignoring point 3, and exiting without any content here, because we\n  // deviated from the spec in `toText` at step 3.\n  if (notRendered(node)) {\n    return items\n  }\n\n  /** @type {BreakNumber | undefined} */\n  let prefix\n  /** @type {BreakForce | BreakNumber | undefined} */\n  let suffix\n  // Note: we first detect if there is going to be a break before or after the\n  // contents, as that changes the white-space handling.\n\n  // 2.  If nodeâ€™s computed value of `visibility` is not `visible`, then return\n  //     items.\n  //\n  //     Note: Ignored, as everything is visible by default user agent styles.\n\n  // 3.  If node is not being rendered, then return items. [...]\n  //\n  //     Note: We already did this above.\n\n  // See `collectText` for step 4.\n\n  // 5.  If node is a `<br>` element, then append a string containing a single\n  //     U+000A LINE FEED (LF) character to items.\n  if (br(node)) {\n    suffix = '\\n'\n  }\n\n  // 7.  If nodeâ€™s computed value of `display` is `table-row`, and nodeâ€™s CSS\n  //     box is not the last `table-row` box of the nearest ancestor `table`\n  //     box, then append a string containing a single U+000A LINE FEED (LF)\n  //     character to items.\n  //\n  //     See: <https://html.spec.whatwg.org/multipage/rendering.html#tables-2>\n  //     Note: needs further investigation as this does not account for implicit\n  //     rows.\n  else if (\n    row(node) &&\n    // @ts-expect-error: something up with types of parents.\n    findAfter(parent, node, row)\n  ) {\n    suffix = '\\n'\n  }\n\n  // 8.  If node is a `<p>` element, then append 2 (a required line break count)\n  //     at the beginning and end of items.\n  else if (p(node)) {\n    prefix = 2\n    suffix = 2\n  }\n\n  // 9.  If nodeâ€™s used value of `display` is block-level or `table-caption`,\n  //     then append 1 (a required line break count) at the beginning and end of\n  //     items.\n  else if (blockOrCaption(node)) {\n    prefix = 1\n    suffix = 1\n  }\n\n  // 1.  Let items be the result of running the inner text collection steps with\n  //     each child node of node in tree order, and then concatenating the\n  //     results to a single list.\n  while (++index < children.length) {\n    items = items.concat(\n      renderedTextCollection(children[index], node, {\n        whitespace,\n        breakBefore: index ? undefined : prefix,\n        breakAfter:\n          index < children.length - 1 ? br(children[index + 1]) : suffix\n      })\n    )\n  }\n\n  // 6.  If nodeâ€™s computed value of `display` is `table-cell`, and nodeâ€™s CSS\n  //     box is not the last `table-cell` box of its enclosing `table-row` box,\n  //     then append a string containing a single U+0009 CHARACTER TABULATION\n  //     (tab) character to items.\n  //\n  //     See: <https://html.spec.whatwg.org/multipage/rendering.html#tables-2>\n  if (\n    cell(node) &&\n    // @ts-expect-error: something up with types of parents.\n    findAfter(parent, node, cell)\n  ) {\n    items.push('\\t')\n  }\n\n  // Add the pre- and suffix.\n  if (prefix) items.unshift(prefix)\n  if (suffix) items.push(suffix)\n\n  return items\n}\n\n/**\n * 4.  If node is a Text node, then for each CSS text box produced by node,\n *     in content order, compute the text of the box after application of the\n *     CSS `white-space` processing rules and `text-transform` rules, set\n *     items to the list of the resulting strings, and return items.\n *     The CSS `white-space` processing rules are slightly modified:\n *     collapsible spaces at the end of lines are always collapsed, but they\n *     are only removed if the line is the last line of the block, or it ends\n *     with a br element.\n *     Soft hyphens should be preserved.\n *\n *     Note: See `collectText` and `collectPreText`.\n *     Note: we donâ€™t deal with `text-transform`, no element has that by\n *     default.\n *\n * See: <https://drafts.csswg.org/css-text/#white-space-phase-1>\n *\n * @param {Comment | Text} node\n *   Text node.\n * @param {CollectionInfo} info\n *   Info on current collection.\n * @returns {Array<BreakNumber | string>}\n *   Result.\n */\nfunction collectText(node, info) {\n  const value = String(node.value)\n  /** @type {Array<string>} */\n  const lines = []\n  /** @type {Array<BreakNumber | string>} */\n  const result = []\n  let start = 0\n\n  while (start <= value.length) {\n    searchLineFeeds.lastIndex = start\n\n    const match = searchLineFeeds.exec(value)\n    const end = match && 'index' in match ? match.index : value.length\n\n    lines.push(\n      // Any sequence of collapsible spaces and tabs immediately preceding or\n      // following a segment break is removed.\n      trimAndCollapseSpacesAndTabs(\n        // [â€¦] ignoring bidi formatting characters (characters with the\n        // Bidi_Control property [UAX9]: ALM, LTR, RTL, LRE-RLO, LRI-PDI) as if\n        // they were not there.\n        value\n          .slice(start, end)\n          .replace(/[\\u061C\\u200E\\u200F\\u202A-\\u202E\\u2066-\\u2069]/g, ''),\n        start === 0 ? info.breakBefore : true,\n        end === value.length ? info.breakAfter : true\n      )\n    )\n\n    start = end + 1\n  }\n\n  // Collapsible segment breaks are transformed for rendering according to the\n  // segment break transformation rules.\n  // So here we jump to 4.1.2 of [CSSTEXT]:\n  // Any collapsible segment break immediately following another collapsible\n  // segment break is removed\n  let index = -1\n  /** @type {BreakNumber | undefined} */\n  let join\n\n  while (++index < lines.length) {\n    // *   If the character immediately before or immediately after the segment\n    //     break is the zero-width space character (U+200B), then the break is\n    //     removed, leaving behind the zero-width space.\n    if (\n      lines[index].charCodeAt(lines[index].length - 1) === 0x20_0b /* ZWSP */ ||\n      (index < lines.length - 1 &&\n        lines[index + 1].charCodeAt(0) === 0x20_0b) /* ZWSP */\n    ) {\n      result.push(lines[index])\n      join = undefined\n    }\n\n    // *   Otherwise, if the East Asian Width property [UAX11] of both the\n    //     character before and after the segment break is Fullwidth, Wide, or\n    //     Halfwidth (not Ambiguous), and neither side is Hangul, then the\n    //     segment break is removed.\n    //\n    //     Note: ignored.\n    // *   Otherwise, if the writing system of the segment break is Chinese,\n    //     Japanese, or Yi, and the character before or after the segment break\n    //     is punctuation or a symbol (Unicode general category P* or S*) and\n    //     has an East Asian Width property of Ambiguous, and the character on\n    //     the other side of the segment break is Fullwidth, Wide, or Halfwidth,\n    //     and not Hangul, then the segment break is removed.\n    //\n    //     Note: ignored.\n\n    // *   Otherwise, the segment break is converted to a space (U+0020).\n    else if (lines[index]) {\n      if (typeof join === 'number') result.push(join)\n      result.push(lines[index])\n      join = 0\n    } else if (index === 0 || index === lines.length - 1) {\n      // If this line is empty, and itâ€™s the first or last, add a space.\n      // Note that this function is only called in normal whitespace, so we\n      // donâ€™t worry about `pre`.\n      result.push(0)\n    }\n  }\n\n  return result\n}\n\n/**\n * Collect a text node as â€œpreâ€ whitespace.\n *\n * @param {Text} node\n *   Text node.\n * @returns {Array<BreakNumber | string>}\n *   Result.\n */\nfunction collectPreText(node) {\n  return [String(node.value)]\n}\n\n/**\n * 3.  Every collapsible tab is converted to a collapsible space (U+0020).\n * 4.  Any collapsible space immediately following another collapsible\n *     spaceâ€”even one outside the boundary of the inline containing that\n *     space, provided both spaces are within the same inline formatting\n *     contextâ€”is collapsed to have zero advance width. (It is invisible,\n *     but retains its soft wrap opportunity, if any.)\n *\n * @param {string} value\n *   Value to collapse.\n * @param {BreakBefore} breakBefore\n *   Whether there was a break before.\n * @param {BreakAfter} breakAfter\n *   Whether there was a break after.\n * @returns {string}\n *   Result.\n */\nfunction trimAndCollapseSpacesAndTabs(value, breakBefore, breakAfter) {\n  /** @type {Array<string>} */\n  const result = []\n  let start = 0\n  /** @type {number | undefined} */\n  let end\n\n  while (start < value.length) {\n    searchTabOrSpaces.lastIndex = start\n    const match = searchTabOrSpaces.exec(value)\n    end = match ? match.index : value.length\n\n    // If weâ€™re not directly after a segment break, but there was white space,\n    // add an empty value that will be turned into a space.\n    if (!start && !end && match && !breakBefore) {\n      result.push('')\n    }\n\n    if (start !== end) {\n      result.push(value.slice(start, end))\n    }\n\n    start = match ? end + match[0].length : end\n  }\n\n  // If we reached the end, there was trailing white space, and thereâ€™s no\n  // segment break after this node, add an empty value that will be turned\n  // into a space.\n  if (start !== end && !breakAfter) {\n    result.push('')\n  }\n\n  return result.join(' ')\n}\n\n/**\n * Figure out the whitespace of a node.\n *\n * We donâ€™t support void elements here (so `nobr wbr` -> `normal` is ignored).\n *\n * @param {Nodes} node\n *   Node (typically `Element`).\n * @param {CollectionInfo} info\n *   Info on current collection.\n * @returns {Whitespace}\n *   Applied whitespace.\n */\nfunction inferWhitespace(node, info) {\n  if (node.type === 'element') {\n    const properties = node.properties || {}\n    switch (node.tagName) {\n      case 'listing':\n      case 'plaintext':\n      case 'xmp': {\n        return 'pre'\n      }\n\n      case 'nobr': {\n        return 'nowrap'\n      }\n\n      case 'pre': {\n        return properties.wrap ? 'pre-wrap' : 'pre'\n      }\n\n      case 'td':\n      case 'th': {\n        return properties.noWrap ? 'nowrap' : info.whitespace\n      }\n\n      case 'textarea': {\n        return 'pre-wrap'\n      }\n\n      default:\n    }\n  }\n\n  return info.whitespace\n}\n\n/**\n * @type {TestFunction}\n * @param {Element} node\n * @returns {node is {properties: {hidden: true}}}\n */\nfunction hidden(node) {\n  return Boolean((node.properties || {}).hidden)\n}\n\n/**\n * @type {TestFunction}\n * @param {Element} node\n * @returns {node is {tagName: 'td' | 'th'}}\n */\nfunction isCell(node) {\n  return node.tagName === 'td' || node.tagName === 'th'\n}\n\n/**\n * @type {TestFunction}\n */\nfunction closedDialog(node) {\n  return node.tagName === 'dialog' && !(node.properties || {}).open\n}\n","/**\n * @import {Options} from 'hast-util-raw'\n * @import {Comment, Doctype, Element, Nodes, RootContent, Root, Text} from 'hast'\n * @import {Raw} from 'mdast-util-to-hast'\n * @import {DefaultTreeAdapterMap, ParserOptions} from 'parse5'\n * @import {Point} from 'unist'\n */\n\n/**\n * @typedef State\n *   Info passed around about the current state.\n * @property {(node: Nodes) => undefined} handle\n *   Add a hast node to the parser.\n * @property {Options} options\n *   User configuration.\n * @property {Parser<DefaultTreeAdapterMap>} parser\n *   Current parser.\n * @property {boolean} stitches\n *   Whether there are stitches.\n */\n\n/**\n * @typedef Stitch\n *   Custom comment-like value we pass through parse5, which contains a\n *   replacement node that weâ€™ll swap back in afterwards.\n * @property {'comment'} type\n *   Node type.\n * @property {{stitch: Nodes}} value\n *   Replacement value.\n */\n\nimport structuredClone from '@ungap/structured-clone'\nimport {fromParse5} from 'hast-util-from-parse5'\nimport {toParse5} from 'hast-util-to-parse5'\nimport {htmlVoidElements} from 'html-void-elements'\nimport {Parser, Token, TokenizerMode, html} from 'parse5'\nimport {pointEnd, pointStart} from 'unist-util-position'\nimport {visit} from 'unist-util-visit'\nimport {webNamespaces} from 'web-namespaces'\nimport {zwitch} from 'zwitch'\n\nconst gfmTagfilterExpression =\n  /<(\\/?)(iframe|noembed|noframes|plaintext|script|style|textarea|title|xmp)(?=[\\t\\n\\f\\r />])/gi\n\n// Node types associated with MDX.\n// <https://github.com/mdx-js/mdx/blob/8a56312/packages/mdx/lib/node-types.js>\nconst knownMdxNames = new Set([\n  'mdxFlowExpression',\n  'mdxJsxFlowElement',\n  'mdxJsxTextElement',\n  'mdxTextExpression',\n  'mdxjsEsm'\n])\n\n/** @type {ParserOptions<DefaultTreeAdapterMap>} */\nconst parseOptions = {sourceCodeLocationInfo: true, scriptingEnabled: false}\n\n/**\n * Pass a hast tree through an HTML parser, which will fix nesting, and turn\n * raw nodes into actual nodes.\n *\n * @param {Nodes} tree\n *   Original hast tree to transform.\n * @param {Options | null | undefined} [options]\n *   Configuration (optional).\n * @returns {Nodes}\n *   Parsed again tree.\n */\nexport function raw(tree, options) {\n  const document = documentMode(tree)\n  /** @type {(node: Nodes, state: State) => undefined} */\n  const one = zwitch('type', {\n    handlers: {root, element, text, comment, doctype, raw: handleRaw},\n    unknown\n  })\n\n  /** @type {State} */\n  const state = {\n    parser: document\n      ? new Parser(parseOptions)\n      : Parser.getFragmentParser(undefined, parseOptions),\n    handle(node) {\n      one(node, state)\n    },\n    stitches: false,\n    options: options || {}\n  }\n\n  one(tree, state)\n  resetTokenizer(state, pointStart())\n\n  const p5 = document ? state.parser.document : state.parser.getFragment()\n  const result = fromParse5(p5, {\n    // To do: support `space`?\n    file: state.options.file\n  })\n\n  if (state.stitches) {\n    visit(result, 'comment', function (node, index, parent) {\n      const stitch = /** @type {Stitch} */ (/** @type {unknown} */ (node))\n      if (stitch.value.stitch && parent && index !== undefined) {\n        /** @type {Array<RootContent>} */\n        const siblings = parent.children\n        // @ts-expect-error: assume the stitch is allowed.\n        siblings[index] = stitch.value.stitch\n        return index\n      }\n    })\n  }\n\n  // Unpack if possible and when not given a `root`.\n  if (\n    result.type === 'root' &&\n    result.children.length === 1 &&\n    result.children[0].type === tree.type\n  ) {\n    return result.children[0]\n  }\n\n  return result\n}\n\n/**\n * Transform all nodes\n *\n * @param {Array<RootContent>} nodes\n *   hast content.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction all(nodes, state) {\n  let index = -1\n\n  /* istanbul ignore else - invalid nodes, see rehypejs/rehype-raw#7. */\n  if (nodes) {\n    while (++index < nodes.length) {\n      state.handle(nodes[index])\n    }\n  }\n}\n\n/**\n * Transform a root.\n *\n * @param {Root} node\n *   hast root node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction root(node, state) {\n  all(node.children, state)\n}\n\n/**\n * Transform an element.\n *\n * @param {Element} node\n *   hast element node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction element(node, state) {\n  startTag(node, state)\n\n  all(node.children, state)\n\n  endTag(node, state)\n}\n\n/**\n * Transform a text.\n *\n * @param {Text} node\n *   hast text node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction text(node, state) {\n  // Allow `DATA` through `PLAINTEXT`,\n  // but when hanging in a tag for example,\n  // switch back to `DATA`.\n  // Note: `State` is not exposed by `parse5`, so these numbers are fragile.\n  // See: <https://github.com/inikulin/parse5/blob/46cba43/packages/parse5/lib/tokenizer/index.ts#L58>\n  if (state.parser.tokenizer.state > 4) {\n    state.parser.tokenizer.state = 0\n  }\n\n  /** @type {Token.CharacterToken} */\n  const token = {\n    type: Token.TokenType.CHARACTER,\n    chars: node.value,\n    location: createParse5Location(node)\n  }\n\n  resetTokenizer(state, pointStart(node))\n  // @ts-expect-error: private.\n  state.parser.currentToken = token\n  // @ts-expect-error: private.\n  state.parser._processToken(state.parser.currentToken)\n}\n\n/**\n * Transform a doctype.\n *\n * @param {Doctype} node\n *   hast doctype node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction doctype(node, state) {\n  /** @type {Token.DoctypeToken} */\n  const token = {\n    type: Token.TokenType.DOCTYPE,\n    name: 'html',\n    forceQuirks: false,\n    publicId: '',\n    systemId: '',\n    location: createParse5Location(node)\n  }\n\n  resetTokenizer(state, pointStart(node))\n  // @ts-expect-error: private.\n  state.parser.currentToken = token\n  // @ts-expect-error: private.\n  state.parser._processToken(state.parser.currentToken)\n}\n\n/**\n * Transform a stitch.\n *\n * @param {Nodes} node\n *   unknown node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction stitch(node, state) {\n  // Mark that there are stitches, so we need to walk the tree and revert them.\n  state.stitches = true\n\n  /** @type {Nodes} */\n  const clone = cloneWithoutChildren(node)\n\n  // Recurse, because to somewhat handle `[<x>]</x>` (where `[]` denotes the\n  // passed through node).\n  if ('children' in node && 'children' in clone) {\n    // Root in root out.\n    const fakeRoot = /** @type {Root} */ (\n      raw({type: 'root', children: node.children}, state.options)\n    )\n    clone.children = fakeRoot.children\n  }\n\n  // Hack: `value` is supposed to be a string, but as none of the tools\n  // (`parse5` or `hast-util-from-parse5`) looks at it, we can pass nodes\n  // through.\n  comment({type: 'comment', value: {stitch: clone}}, state)\n}\n\n/**\n * Transform a comment (or stitch).\n *\n * @param {Comment | Stitch} node\n *   hast comment node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction comment(node, state) {\n  /** @type {string} */\n  // @ts-expect-error: we pass stitches through.\n  const data = node.value\n\n  /** @type {Token.CommentToken} */\n  const token = {\n    type: Token.TokenType.COMMENT,\n    data,\n    location: createParse5Location(node)\n  }\n  resetTokenizer(state, pointStart(node))\n  // @ts-expect-error: private.\n  state.parser.currentToken = token\n  // @ts-expect-error: private.\n  state.parser._processToken(state.parser.currentToken)\n}\n\n/**\n * Transform a raw node.\n *\n * @param {Raw} node\n *   hast raw node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction handleRaw(node, state) {\n  // Reset preprocessor:\n  // See: <https://github.com/inikulin/parse5/blob/6f7ca60/packages/parse5/lib/tokenizer/preprocessor.ts#L18-L31>.\n  state.parser.tokenizer.preprocessor.html = ''\n  state.parser.tokenizer.preprocessor.pos = -1\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.lastGapPos = -2\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.gapStack = []\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.skipNextNewLine = false\n  state.parser.tokenizer.preprocessor.lastChunkWritten = false\n  state.parser.tokenizer.preprocessor.endOfChunkHit = false\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.isEol = false\n\n  // Now pass `node.value`.\n  setPoint(state, pointStart(node))\n\n  state.parser.tokenizer.write(\n    state.options.tagfilter\n      ? node.value.replace(gfmTagfilterExpression, '&lt;$1$2')\n      : node.value,\n    false\n  )\n  // @ts-expect-error: private.\n  state.parser.tokenizer._runParsingLoop()\n\n  // Character references hang, so if we ended there, we need to flush\n  // those too.\n  // We reset the preprocessor as if the document ends here.\n  // Then one single call to the relevant state does the trick, parse5\n  // consumes the whole token.\n\n  // Note: `State` is not exposed by `parse5`, so these numbers are fragile.\n  // See: <https://github.com/inikulin/parse5/blob/46cba43/packages/parse5/lib/tokenizer/index.ts#L58>\n  // Note: a change to `parse5`, which breaks this, was merged but not released.\n  // Investigate when it is.\n  // To do: remove next major.\n  /* c8 ignore next 12 -- removed in <https://github.com/inikulin/parse5/pull/897> */\n  if (\n    state.parser.tokenizer.state === 72 /* NAMED_CHARACTER_REFERENCE */ ||\n    // @ts-expect-error: removed.\n    state.parser.tokenizer.state === 78 /* NUMERIC_CHARACTER_REFERENCE_END */\n  ) {\n    state.parser.tokenizer.preprocessor.lastChunkWritten = true\n    /** @type {number} */\n    // @ts-expect-error: private.\n    const cp = state.parser.tokenizer._consume()\n    // @ts-expect-error: private.\n    state.parser.tokenizer._callState(cp)\n  }\n}\n\n/**\n * Crash on an unknown node.\n *\n * @param {unknown} node_\n *   unknown node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Never.\n */\nfunction unknown(node_, state) {\n  const node = /** @type {Nodes} */ (node_)\n\n  if (\n    state.options.passThrough &&\n    state.options.passThrough.includes(node.type)\n  ) {\n    stitch(node, state)\n  } else {\n    let extra = ''\n\n    if (knownMdxNames.has(node.type)) {\n      extra =\n        \". It looks like you are using MDX nodes with `hast-util-raw` (or `rehype-raw`). If you use this because you are using remark or rehype plugins that inject `'html'` nodes, then please raise an issue with that plugin, as its a bad and slow idea. If you use this because you are using markdown syntax, then you have to configure this utility (or plugin) to pass through these nodes (see `passThrough` in docs), but you can also migrate to use the MDX syntax\"\n    }\n\n    throw new Error('Cannot compile `' + node.type + '` node' + extra)\n  }\n}\n\n/**\n * Reset the tokenizer of a parser.\n *\n * @param {State} state\n *   Info passed around about the current state.\n * @param {Point | undefined} point\n *   Point.\n * @returns {undefined}\n *   Nothing.\n */\nfunction resetTokenizer(state, point) {\n  setPoint(state, point)\n\n  // Process final characters if theyâ€™re still there after hibernating.\n  /** @type {Token.CharacterToken} */\n  // @ts-expect-error: private.\n  const token = state.parser.tokenizer.currentCharacterToken\n\n  if (token && token.location) {\n    token.location.endLine = state.parser.tokenizer.preprocessor.line\n    token.location.endCol = state.parser.tokenizer.preprocessor.col + 1\n    token.location.endOffset = state.parser.tokenizer.preprocessor.offset + 1\n    // @ts-expect-error: private.\n    state.parser.currentToken = token\n    // @ts-expect-error: private.\n    state.parser._processToken(state.parser.currentToken)\n  }\n\n  // Reset tokenizer:\n  // See: <https://github.com/inikulin/parse5/blob/6f7ca60/packages/parse5/lib/tokenizer/index.ts#L187-L223>.\n  // Especially putting it back in the `data` state is useful: some elements,\n  // like textareas and iframes, change the state.\n  // See GH-7.\n  // But also if broken HTML is in `raw`, and then a correct element is given.\n  // See GH-11.\n  // @ts-expect-error: private.\n  state.parser.tokenizer.paused = false\n  // @ts-expect-error: private.\n  state.parser.tokenizer.inLoop = false\n\n  // Note: donâ€™t reset `state`, `inForeignNode`, or `lastStartTagName`, we\n  // manually update those when needed.\n  state.parser.tokenizer.active = false\n  // @ts-expect-error: private.\n  state.parser.tokenizer.returnState = TokenizerMode.DATA\n  // @ts-expect-error: private.\n  state.parser.tokenizer.charRefCode = -1\n  // @ts-expect-error: private.\n  state.parser.tokenizer.consumedAfterSnapshot = -1\n  // @ts-expect-error: private.\n  state.parser.tokenizer.currentLocation = null\n  // @ts-expect-error: private.\n  state.parser.tokenizer.currentCharacterToken = null\n  // @ts-expect-error: private.\n  state.parser.tokenizer.currentToken = null\n  // @ts-expect-error: private.\n  state.parser.tokenizer.currentAttr = {name: '', value: ''}\n}\n\n/**\n * Set current location.\n *\n * @param {State} state\n *   Info passed around about the current state.\n * @param {Point | undefined} point\n *   Point.\n * @returns {undefined}\n *   Nothing.\n */\nfunction setPoint(state, point) {\n  if (point && point.offset !== undefined) {\n    /** @type {Token.Location} */\n    const location = {\n      startLine: point.line,\n      startCol: point.column,\n      startOffset: point.offset,\n      endLine: -1,\n      endCol: -1,\n      endOffset: -1\n    }\n\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.tokenizer.preprocessor.lineStartPos = -point.column + 1 // Looks weird, but ensures we get correct positional info.\n    state.parser.tokenizer.preprocessor.droppedBufferSize = point.offset\n    state.parser.tokenizer.preprocessor.line = point.line\n    // @ts-expect-error: private.\n    state.parser.tokenizer.currentLocation = location\n  }\n}\n\n/**\n * Emit a start tag.\n *\n * @param {Element} node\n *   Element.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction startTag(node, state) {\n  const tagName = node.tagName.toLowerCase()\n\n  // Ignore tags if weâ€™re in plain text.\n  if (state.parser.tokenizer.state === TokenizerMode.PLAINTEXT) return\n\n  resetTokenizer(state, pointStart(node))\n\n  const current = state.parser.openElements.current\n  let ns = 'namespaceURI' in current ? current.namespaceURI : webNamespaces.html\n\n  if (ns === webNamespaces.html && tagName === 'svg') {\n    ns = webNamespaces.svg\n  }\n\n  const result = toParse5(\n    // Shallow clone to not delve into `children`: we only need the attributes.\n    {...node, children: []},\n    {space: ns === webNamespaces.svg ? 'svg' : 'html'}\n  )\n\n  /** @type {Token.TagToken} */\n  const tag = {\n    type: Token.TokenType.START_TAG,\n    tagName,\n    tagID: html.getTagID(tagName),\n    // We always send start and end tags.\n    selfClosing: false,\n    ackSelfClosing: false,\n    // Always element.\n    /* c8 ignore next */\n    attrs: 'attrs' in result ? result.attrs : [],\n    location: createParse5Location(node)\n  }\n\n  // The HTML parsing algorithm works by doing half of the state management in\n  // the tokenizer and half in the parser.\n  // We canâ€™t use the tokenizer here, as we donâ€™t have strings.\n  // So we act *as if* the tokenizer emits tokens:\n\n  // @ts-expect-error: private.\n  state.parser.currentToken = tag\n  // @ts-expect-error: private.\n  state.parser._processToken(state.parser.currentToken)\n\n  // â€¦but then we still need a bunch of work that the tokenizer would normally\n  // do, such as:\n\n  // Set a tag name, similar to how the tokenizer would do it.\n  state.parser.tokenizer.lastStartTagName = tagName\n\n  // `inForeignNode` is correctly set by the parser.\n}\n\n/**\n * Emit an end tag.\n *\n * @param {Element} node\n *   Element.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction endTag(node, state) {\n  const tagName = node.tagName.toLowerCase()\n  // Do not emit closing tags for HTML void elements.\n  if (\n    !state.parser.tokenizer.inForeignNode &&\n    htmlVoidElements.includes(tagName)\n  ) {\n    return\n  }\n\n  // Ignore tags if weâ€™re in plain text.\n  if (state.parser.tokenizer.state === TokenizerMode.PLAINTEXT) return\n\n  resetTokenizer(state, pointEnd(node))\n\n  /** @type {Token.TagToken} */\n  const tag = {\n    type: Token.TokenType.END_TAG,\n    tagName,\n    tagID: html.getTagID(tagName),\n    selfClosing: false,\n    ackSelfClosing: false,\n    attrs: [],\n    location: createParse5Location(node)\n  }\n\n  // The HTML parsing algorithm works by doing half of the state management in\n  // the tokenizer and half in the parser.\n  // We canâ€™t use the tokenizer here, as we donâ€™t have strings.\n  // So we act *as if* the tokenizer emits tokens:\n\n  // @ts-expect-error: private.\n  state.parser.currentToken = tag\n  // @ts-expect-error: private.\n  state.parser._processToken(state.parser.currentToken)\n\n  // â€¦but then we still need a bunch of work that the tokenizer would normally\n  // do, such as:\n\n  // Switch back to the data state after alternative states that donâ€™t accept\n  // tags:\n  if (\n    // Current element is closed.\n    tagName === state.parser.tokenizer.lastStartTagName &&\n    // `<textarea>` and `<title>`\n    (state.parser.tokenizer.state === TokenizerMode.RCDATA ||\n      // `<iframe>`, `<noembed>`, `<noframes>`, `<style>`, `<xmp>`\n      state.parser.tokenizer.state === TokenizerMode.RAWTEXT ||\n      // `<script>`\n      state.parser.tokenizer.state === TokenizerMode.SCRIPT_DATA)\n    // Note: `<plaintext>` not needed, as itâ€™s the last element.\n  ) {\n    state.parser.tokenizer.state = TokenizerMode.DATA\n  }\n}\n\n/**\n * Check if `node` represents a whole document or a fragment.\n *\n * @param {Nodes} node\n *   hast node.\n * @returns {boolean}\n *   Whether this represents a whole document or a fragment.\n */\nfunction documentMode(node) {\n  const head = node.type === 'root' ? node.children[0] : node\n  return Boolean(\n    head &&\n      (head.type === 'doctype' ||\n        (head.type === 'element' && head.tagName.toLowerCase() === 'html'))\n  )\n}\n\n/**\n * Get a `parse5` location from a node.\n *\n * @param {Nodes | Stitch} node\n *   hast node.\n * @returns {Token.Location}\n *   `parse5` location.\n */\nfunction createParse5Location(node) {\n  const start = pointStart(node) || {\n    line: undefined,\n    column: undefined,\n    offset: undefined\n  }\n  const end = pointEnd(node) || {\n    line: undefined,\n    column: undefined,\n    offset: undefined\n  }\n\n  /** @type {Record<keyof Token.Location, number | undefined>} */\n  const location = {\n    startLine: start.line,\n    startCol: start.column,\n    startOffset: start.offset,\n    endLine: end.line,\n    endCol: end.column,\n    endOffset: end.offset\n  }\n\n  // @ts-expect-error: unist point values can be `undefined` in hast, which\n  // `parse5` types donâ€™t want.\n  return location\n}\n\n/**\n * @template {Nodes} NodeType\n *   Node type.\n * @param {NodeType} node\n *   Node to clone.\n * @returns {NodeType}\n *   Cloned node, without children.\n */\nfunction cloneWithoutChildren(node) {\n  return 'children' in node\n    ? structuredClone({...node, children: []})\n    : structuredClone(node)\n}\n"],"names":["searchLineFeeds","searchTabOrSpaces","br","convertElement","cell","node","tagName","p","row","notRendered","Boolean","properties","hidden","open","blockOrCaption","toText","tree","options","options_","children","block","whitespace","inferWhitespace","breakBefore","breakAfter","results","type","push","collectText","index","length","renderedTextCollection","undefined","result","count","value","repeat","join","parent","info","prefix","suffix","items","findAfter","concat","unshift","collectElement","String","collectPreText","lines","start","lastIndex","match","exec","end","trimAndCollapseSpacesAndTabs","slice","replace","charCodeAt","wrap","noWrap","gfmTagfilterExpression","knownMdxNames","Set","parseOptions","sourceCodeLocationInfo","scriptingEnabled","raw","document","head","toLowerCase","documentMode","one","zwitch","handlers","root","element","text","comment","doctype","handleRaw","unknown","state","parser","Parser","getFragmentParser","handle","stitches","resetTokenizer","pointStart","p5","getFragment","fromParse5","file","visit","stitch","all","nodes","tokenizer","TokenizerMode","PLAINTEXT","current","openElements","ns","namespaceURI","webNamespaces","html","svg","toParse5","space","tag","Token","START_TAG","tagID","selfClosing","ackSelfClosing","attrs","location","createParse5Location","currentToken","_processToken","lastStartTagName","startTag","inForeignNode","htmlVoidElements","includes","pointEnd","END_TAG","RCDATA","RAWTEXT","SCRIPT_DATA","DATA","endTag","token","CHARACTER","chars","DOCTYPE","name","forceQuirks","publicId","systemId","clone","structuredClone","cloneWithoutChildren","fakeRoot","data","COMMENT","preprocessor","pos","lastGapPos","gapStack","skipNextNewLine","lastChunkWritten","endOfChunkHit","isEol","setPoint","write","tagfilter","_runParsingLoop","cp","_consume","_callState","node_","passThrough","extra","has","Error","point","currentCharacterToken","endLine","line","endCol","col","endOffset","offset","paused","inLoop","active","returnState","charRefCode","consumedAfterSnapshot","currentLocation","currentAttr","startLine","startCol","column","startOffset","lineStartPos","droppedBufferSize"],"sourceRoot":""}