{"version":3,"file":"static/js/vendor.remark-parse-20e8959b.21279e69.chunk.js","mappings":"gKAUO,MAAMA,EAAY,CACvBC,SAQF,SAA2BC,EAASC,EAAIC,GACtC,OAgBA,SAAeC,GACb,OAAOC,EAAAA,EAAAA,IAAcD,IACjBE,EAAAA,EAAAA,GAAaL,EAASM,EAAO,aAA7BD,CAA2CF,GAC3CG,EAAMH,EACZ,EAgBA,SAASG,EAAMH,GACb,OAAgB,OAATA,IAAiBI,EAAAA,EAAAA,IAAmBJ,GAAQF,EAAGE,GAAQD,EAAIC,EACpE,CACF,EA/CEK,SAAS,E,6DCDJ,MAAMC,EAAa,CACxBC,KAAM,aACNX,SAWF,SAAiCC,EAASC,EAAIC,GAC5C,MAAMS,EAAOC,KACb,OAYA,SAAeT,GACb,GAAa,KAATA,EAAa,CACf,MAAMU,EAAQF,EAAKG,eAWnB,OAVKD,EAAME,OACTf,EAAQgB,MAAM,aAAc,CAC1BC,YAAY,IAEdJ,EAAME,MAAO,GAEff,EAAQgB,MAAM,oBACdhB,EAAQgB,MAAM,oBACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,oBACNb,CACT,CACA,OAAOJ,EAAIC,EACb,EAYA,SAASG,EAAMH,GACb,OAAIC,EAAAA,EAAAA,IAAcD,IAChBH,EAAQgB,MAAM,8BACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,8BACbnB,EAAQmB,KAAK,oBACNlB,IAETD,EAAQmB,KAAK,oBACNlB,EAAGE,GACZ,CACF,EA/DEiB,aAAc,CACZrB,SA4EJ,SAAwCC,EAASC,EAAIC,GACnD,MAAMS,EAAOC,KACb,OAeA,SAAmBT,GACjB,IAAIC,EAAAA,EAAAA,IAAcD,GAGhB,OAAOE,EAAAA,EAAAA,GACLL,EACAqB,EACA,aACAV,EAAKW,OAAOC,WAAWC,QAAQC,KAAKC,SAAS,qBACzCC,EACA,EANCtB,CAOLF,GAEJ,OAAOkB,EAAWlB,EACpB,EAeA,SAASkB,EAAWlB,GAClB,OAAOH,EAAQ4B,QAAQnB,EAAYR,EAAIC,EAAhCF,CAAqCG,EAC9C,CACF,GA3HEgB,KA8HF,SAAcnB,GACZA,EAAQmB,KAAK,aACf,E,kDCnIO,MAAMU,EAAW,CACtBnB,KAAM,WACNX,SAOF,SAA0BC,EAASC,EAAIC,GACrC,IAAI4B,EAAO,EACX,OAcA,SAAe3B,GAMb,OALAH,EAAQgB,MAAM,YACdhB,EAAQgB,MAAM,kBACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,kBACbnB,EAAQgB,MAAM,oBACPD,CACT,EAcA,SAASA,EAAKZ,GACZ,OAAI4B,EAAAA,EAAAA,IAAW5B,IACbH,EAAQkB,QAAQf,GACT6B,GAEFC,EAAW9B,EACpB,CAcA,SAAS6B,EAAmB7B,GAE1B,OAAa,KAATA,GAAwB,KAATA,GAAwB,KAATA,IAAe+B,EAAAA,EAAAA,IAAkB/B,IAEjE2B,EAAO,EACAK,EAAyBhC,IAE3B8B,EAAW9B,EACpB,CAcA,SAASgC,EAAyBhC,GAChC,OAAa,KAATA,GACFH,EAAQkB,QAAQf,GAChB2B,EAAO,EACAM,IAKG,KAATjC,GAAwB,KAATA,GAAwB,KAATA,IAAe+B,EAAAA,EAAAA,IAAkB/B,KAChE2B,IAAS,IAET9B,EAAQkB,QAAQf,GACTgC,IAETL,EAAO,EACAG,EAAW9B,GACpB,CAYA,SAASiC,EAAUjC,GACjB,OAAa,KAATA,GACFH,EAAQmB,KAAK,oBACbnB,EAAQgB,MAAM,kBACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,kBACbnB,EAAQmB,KAAK,YACNlB,GAII,OAATE,GAA0B,KAATA,GAAwB,KAATA,IAAekC,EAAAA,EAAAA,IAAalC,GACvDD,EAAIC,IAEbH,EAAQkB,QAAQf,GACTiC,EACT,CAYA,SAASH,EAAW9B,GAClB,OAAa,KAATA,GACFH,EAAQkB,QAAQf,GACTmC,IAELC,EAAAA,EAAAA,IAAWpC,IACbH,EAAQkB,QAAQf,GACT8B,GAEF/B,EAAIC,EACb,CAYA,SAASmC,EAAiBnC,GACxB,OAAO+B,EAAAA,EAAAA,IAAkB/B,GAAQqC,EAAWrC,GAAQD,EAAIC,EAC1D,CAYA,SAASqC,EAAWrC,GAClB,OAAa,KAATA,GACFH,EAAQkB,QAAQf,GAChB2B,EAAO,EACAQ,GAEI,KAATnC,GAEFH,EAAQmB,KAAK,oBAAoBsB,KAAO,gBACxCzC,EAAQgB,MAAM,kBACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,kBACbnB,EAAQmB,KAAK,YACNlB,GAEFyC,EAAWvC,EACpB,CAcA,SAASuC,EAAWvC,GAElB,IAAc,KAATA,IAAe+B,EAAAA,EAAAA,IAAkB/B,KAAU2B,IAAS,GAAI,CAC3D,MAAMa,EAAgB,KAATxC,EAAcuC,EAAaF,EAExC,OADAxC,EAAQkB,QAAQf,GACTwC,CACT,CACA,OAAOzC,EAAIC,EACb,CACF,E,6DC3NO,MAAMyC,EAAqB,CAChClC,KAAM,qBACNX,SAOF,SAAoCC,EAASC,EAAIC,GAC/C,MAAMS,EAAOC,KACb,IAEIiC,EAEAC,EAJAhB,EAAO,EAKX,OAgBA,SAAe3B,GAKb,OAJAH,EAAQgB,MAAM,sBACdhB,EAAQgB,MAAM,4BACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,4BACNJ,CACT,EAiBA,SAASA,EAAKZ,GACZ,OAAa,KAATA,GACFH,EAAQgB,MAAM,mCACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,mCACN4B,IAET/C,EAAQgB,MAAM,2BACd6B,EAAM,GACNC,EAAOZ,EAAAA,GACAc,EAAM7C,GACf,CAcA,SAAS4C,EAAQ5C,GACf,OAAa,KAATA,GAAwB,MAATA,GACjBH,EAAQgB,MAAM,uCACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,uCACbnB,EAAQgB,MAAM,2BACd6B,EAAM,EACNC,EAAOG,EAAAA,GACAD,IAEThD,EAAQgB,MAAM,2BACd6B,EAAM,EACNC,EAAOI,EAAAA,GACAF,EAAM7C,GACf,CAmBA,SAAS6C,EAAM7C,GACb,GAAa,KAATA,GAAe2B,EAAM,CACvB,MAAMqB,EAAQnD,EAAQmB,KAAK,2BAC3B,OACE2B,IAASZ,EAAAA,KACRkB,EAAAA,EAAAA,GAA8BzC,EAAK0C,eAAeF,KAOrDnD,EAAQgB,MAAM,4BACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,4BACbnB,EAAQmB,KAAK,sBACNlB,GATEC,EAAIC,EAUf,CACA,OAAI2C,EAAK3C,IAAS2B,IAASe,GACzB7C,EAAQkB,QAAQf,GACT6C,GAEF9C,EAAIC,EACb,CACF,E,uECxIO,MAAMmD,EAAY,CACvB5C,KAAM,YACNX,SA4KF,SAA2BC,EAASC,GAClC,MAAMsD,EAAmB3C,KAAKU,OAAOC,WAAWgC,iBAAiB9B,KAC3D+B,EAAW5C,KAAK4C,SAChBC,GAASC,EAAAA,EAAAA,GAAkBF,GAGjC,IAAIG,EACJ,OAYA,SAAexD,GAGb,OAFAwD,EAASxD,EACTH,EAAQgB,MAAM,qBACP4C,EAAOzD,EAChB,EAYA,SAASyD,EAAOzD,GACd,GAAIA,IAASwD,EAEX,OADA3D,EAAQkB,QAAQf,GACTyD,EAET,MAAMT,EAAQnD,EAAQmB,KAAK,qBAGrBb,GAAQoD,EAAAA,EAAAA,GAAkBvD,GAI1BY,GACHT,GAAoB,IAAVA,GAAemD,GAAWF,EAAiB7B,SAASvB,GAC3D0D,GACHJ,GAAsB,IAAXA,GAAgBnD,GAAUiD,EAAiB7B,SAAS8B,GAGlE,OAFAL,EAAMW,MAAQC,QAAmB,KAAXJ,EAAgB5C,EAAOA,IAAS0C,IAAWI,IACjEV,EAAMa,OAASD,QAAmB,KAAXJ,EAAgBE,EAAQA,IAAUvD,IAAUS,IAC5Dd,EAAGE,EACZ,CACF,EAlOE8D,WAQF,SAA6BC,EAAQC,GACnC,IAEIpD,EAEAqD,EAEAC,EAEAC,EAEAC,EAEAC,EAEAC,EAEAC,EAhBAC,GAAS,EAsBb,OAASA,EAAQT,EAAOU,QAEtB,GACuB,UAArBV,EAAOS,GAAO,IACY,sBAA1BT,EAAOS,GAAO,GAAGlC,MACjByB,EAAOS,GAAO,GAAGX,OAKjB,IAHAjD,EAAO4D,EAGA5D,KAEL,GACsB,SAApBmD,EAAOnD,GAAM,IACY,sBAAzBmD,EAAOnD,GAAM,GAAG0B,MAChByB,EAAOnD,GAAM,GAAG+C,OAEhBK,EAAQd,eAAea,EAAOnD,GAAM,IAAI8D,WAAW,KACjDV,EAAQd,eAAea,EAAOS,GAAO,IAAIE,WAAW,GACtD,CAKA,IACGX,EAAOnD,GAAM,GAAGiD,QAAUE,EAAOS,GAAO,GAAGb,SAC3CI,EAAOS,GAAO,GAAGG,IAAIJ,OAASR,EAAOS,GAAO,GAAGI,MAAML,QAAU,MAE7DR,EAAOnD,GAAM,GAAG+D,IAAIJ,OACnBR,EAAOnD,GAAM,GAAGgE,MAAML,OACtBR,EAAOS,GAAO,GAAGG,IAAIJ,OACrBR,EAAOS,GAAO,GAAGI,MAAML,QACzB,GAGF,SAIFF,EACEN,EAAOnD,GAAM,GAAG+D,IAAIJ,OAASR,EAAOnD,GAAM,GAAGgE,MAAML,OAAS,GAC5DR,EAAOS,GAAO,GAAGG,IAAIJ,OAASR,EAAOS,GAAO,GAAGI,MAAML,OAAS,EAC1D,EACA,EACN,MAAMK,EAAQC,OAAOC,OAAO,CAAC,EAAGf,EAAOnD,GAAM,GAAG+D,KAC1CA,EAAME,OAAOC,OAAO,CAAC,EAAGf,EAAOS,GAAO,GAAGI,OAC/CG,EAAUH,GAAQP,GAClBU,EAAUJ,EAAKN,GACfF,EAAkB,CAChB7B,KAAM+B,EAAM,EAAI,iBAAmB,mBACnCO,QACAD,IAAKE,OAAOC,OAAO,CAAC,EAAGf,EAAOnD,GAAM,GAAG+D,MAEzCP,EAAkB,CAChB9B,KAAM+B,EAAM,EAAI,iBAAmB,mBACnCO,MAAOC,OAAOC,OAAO,CAAC,EAAGf,EAAOS,GAAO,GAAGI,OAC1CD,OAEFT,EAAO,CACL5B,KAAM+B,EAAM,EAAI,aAAe,eAC/BO,MAAOC,OAAOC,OAAO,CAAC,EAAGf,EAAOnD,GAAM,GAAG+D,KACzCA,IAAKE,OAAOC,OAAO,CAAC,EAAGf,EAAOS,GAAO,GAAGI,QAE1CX,EAAQ,CACN3B,KAAM+B,EAAM,EAAI,SAAW,WAC3BO,MAAOC,OAAOC,OAAO,CAAC,EAAGX,EAAgBS,OACzCD,IAAKE,OAAOC,OAAO,CAAC,EAAGV,EAAgBO,MAEzCZ,EAAOnD,GAAM,GAAG+D,IAAME,OAAOC,OAAO,CAAC,EAAGX,EAAgBS,OACxDb,EAAOS,GAAO,GAAGI,MAAQC,OAAOC,OAAO,CAAC,EAAGV,EAAgBO,KAC3DL,EAAa,GAGTP,EAAOnD,GAAM,GAAG+D,IAAIJ,OAASR,EAAOnD,GAAM,GAAGgE,MAAML,SACrDD,GAAaU,EAAAA,EAAAA,GAAKV,EAAY,CAC5B,CAAC,QAASP,EAAOnD,GAAM,GAAIoD,GAC3B,CAAC,OAAQD,EAAOnD,GAAM,GAAIoD,MAK9BM,GAAaU,EAAAA,EAAAA,GAAKV,EAAY,CAC5B,CAAC,QAASL,EAAOD,GACjB,CAAC,QAASG,EAAiBH,GAC3B,CAAC,OAAQG,EAAiBH,GAC1B,CAAC,QAASE,EAAMF,KAMlBM,GAAaU,EAAAA,EAAAA,GACXV,GACAR,EAAAA,EAAAA,GACEE,EAAQ7C,OAAOC,WAAW6D,WAAW3D,KACrCyC,EAAOmB,MAAMtE,EAAO,EAAG4D,GACvBR,IAKJM,GAAaU,EAAAA,EAAAA,GAAKV,EAAY,CAC5B,CAAC,OAAQJ,EAAMF,GACf,CAAC,QAASI,EAAiBJ,GAC3B,CAAC,OAAQI,EAAiBJ,GAC1B,CAAC,OAAQC,EAAOD,KAIdD,EAAOS,GAAO,GAAGG,IAAIJ,OAASR,EAAOS,GAAO,GAAGI,MAAML,QACvDA,EAAS,EACTD,GAAaU,EAAAA,EAAAA,GAAKV,EAAY,CAC5B,CAAC,QAASP,EAAOS,GAAO,GAAIR,GAC5B,CAAC,OAAQD,EAAOS,GAAO,GAAIR,MAG7BO,EAAS,GAEXY,EAAAA,EAAAA,GAAOpB,EAAQnD,EAAO,EAAG4D,EAAQ5D,EAAO,EAAG0D,GAC3CE,EAAQ5D,EAAO0D,EAAWG,OAASF,EAAS,EAC5C,KACF,CAMNC,GAAS,EACT,OAASA,EAAQT,EAAOU,QACQ,sBAA1BV,EAAOS,GAAO,GAAGlC,OACnByB,EAAOS,GAAO,GAAGlC,KAAO,QAG5B,OAAOyB,CACT,GAyEA,SAASgB,EAAUK,EAAOb,GACxBa,EAAMC,QAAUd,EAChBa,EAAMb,QAAUA,EAChBa,EAAME,cAAgBf,CACxB,C,kDC5PO,MAAMgB,EAAkB,CAC7BhF,KAAM,kBACNX,SAOF,SAAiCC,EAASC,EAAIC,GAC5C,OAYA,SAAeC,GAKb,OAJAH,EAAQgB,MAAM,mBACdhB,EAAQgB,MAAM,gBACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,gBACNyC,CACT,EAYA,SAASA,EAAOzD,GAEd,OAAIwF,EAAAA,EAAAA,IAAiBxF,IACnBH,EAAQgB,MAAM,wBACdhB,EAAQkB,QAAQf,GAChBH,EAAQmB,KAAK,wBACbnB,EAAQmB,KAAK,mBACNlB,GAEFC,EAAIC,EACb,CACF,E","sources":["../node_modules/remark-parse/node_modules/micromark-core-commonmark/lib/blank-line.js","../node_modules/remark-parse/node_modules/micromark-core-commonmark/lib/block-quote.js","../node_modules/remark-parse/node_modules/micromark-core-commonmark/lib/autolink.js","../node_modules/remark-parse/node_modules/micromark-core-commonmark/lib/character-reference.js","../node_modules/remark-parse/node_modules/micromark-core-commonmark/lib/attention.js","../node_modules/remark-parse/node_modules/micromark-core-commonmark/lib/character-escape.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding, markdownSpace} from 'micromark-util-character'\n/** @type {Construct} */\nexport const blankLine = {\n  tokenize: tokenizeBlankLine,\n  partial: true\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeBlankLine(effects, ok, nok) {\n  return start\n\n  /**\n   * Start of blank line.\n   *\n   * > ðŸ‘‰ **Note**: `â ` represents a space character.\n   *\n   * ```markdown\n   * > | â â âŠ\n   *     ^\n   * > | âŠ\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    return markdownSpace(code)\n      ? factorySpace(effects, after, 'linePrefix')(code)\n      : after(code)\n  }\n\n  /**\n   * At eof/eol, after optional whitespace.\n   *\n   * > ðŸ‘‰ **Note**: `â ` represents a space character.\n   *\n   * ```markdown\n   * > | â â âŠ\n   *       ^\n   * > | âŠ\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Exiter} Exiter\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownSpace} from 'micromark-util-character'\n/** @type {Construct} */\nexport const blockQuote = {\n  name: 'blockQuote',\n  tokenize: tokenizeBlockQuoteStart,\n  continuation: {\n    tokenize: tokenizeBlockQuoteContinuation\n  },\n  exit\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeBlockQuoteStart(effects, ok, nok) {\n  const self = this\n  return start\n\n  /**\n   * Start of block quote.\n   *\n   * ```markdown\n   * > | > a\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (code === 62) {\n      const state = self.containerState\n      if (!state.open) {\n        effects.enter('blockQuote', {\n          _container: true\n        })\n        state.open = true\n      }\n      effects.enter('blockQuotePrefix')\n      effects.enter('blockQuoteMarker')\n      effects.consume(code)\n      effects.exit('blockQuoteMarker')\n      return after\n    }\n    return nok(code)\n  }\n\n  /**\n   * After `>`, before optional whitespace.\n   *\n   * ```markdown\n   * > | > a\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    if (markdownSpace(code)) {\n      effects.enter('blockQuotePrefixWhitespace')\n      effects.consume(code)\n      effects.exit('blockQuotePrefixWhitespace')\n      effects.exit('blockQuotePrefix')\n      return ok\n    }\n    effects.exit('blockQuotePrefix')\n    return ok(code)\n  }\n}\n\n/**\n * Start of block quote continuation.\n *\n * ```markdown\n *   | > a\n * > | > b\n *     ^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeBlockQuoteContinuation(effects, ok, nok) {\n  const self = this\n  return contStart\n\n  /**\n   * Start of block quote continuation.\n   *\n   * Also used to parse the first block quote opening.\n   *\n   * ```markdown\n   *   | > a\n   * > | > b\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function contStart(code) {\n    if (markdownSpace(code)) {\n      // Always populated by defaults.\n\n      return factorySpace(\n        effects,\n        contBefore,\n        'linePrefix',\n        self.parser.constructs.disable.null.includes('codeIndented')\n          ? undefined\n          : 4\n      )(code)\n    }\n    return contBefore(code)\n  }\n\n  /**\n   * At `>`, after optional whitespace.\n   *\n   * Also used to parse the first block quote opening.\n   *\n   * ```markdown\n   *   | > a\n   * > | > b\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function contBefore(code) {\n    return effects.attempt(blockQuote, ok, nok)(code)\n  }\n}\n\n/** @type {Exiter} */\nfunction exit(effects) {\n  effects.exit('blockQuote')\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {\n  asciiAlpha,\n  asciiAlphanumeric,\n  asciiAtext,\n  asciiControl\n} from 'micromark-util-character'\n/** @type {Construct} */\nexport const autolink = {\n  name: 'autolink',\n  tokenize: tokenizeAutolink\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeAutolink(effects, ok, nok) {\n  let size = 0\n  return start\n\n  /**\n   * Start of an autolink.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *      ^\n   * > | a<user@example.com>b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('autolink')\n    effects.enter('autolinkMarker')\n    effects.consume(code)\n    effects.exit('autolinkMarker')\n    effects.enter('autolinkProtocol')\n    return open\n  }\n\n  /**\n   * After `<`, at protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *       ^\n   * > | a<user@example.com>b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return schemeOrEmailAtext\n    }\n    return emailAtext(code)\n  }\n\n  /**\n   * At second byte of protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *        ^\n   * > | a<user@example.com>b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function schemeOrEmailAtext(code) {\n    // ASCII alphanumeric and `+`, `-`, and `.`.\n    if (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) {\n      // Count the previous alphabetical from `open` too.\n      size = 1\n      return schemeInsideOrEmailAtext(code)\n    }\n    return emailAtext(code)\n  }\n\n  /**\n   * In ambiguous protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *        ^\n   * > | a<user@example.com>b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function schemeInsideOrEmailAtext(code) {\n    if (code === 58) {\n      effects.consume(code)\n      size = 0\n      return urlInside\n    }\n\n    // ASCII alphanumeric and `+`, `-`, and `.`.\n    if (\n      (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) &&\n      size++ < 32\n    ) {\n      effects.consume(code)\n      return schemeInsideOrEmailAtext\n    }\n    size = 0\n    return emailAtext(code)\n  }\n\n  /**\n   * After protocol, in URL.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *             ^\n   * ```\n   *\n   * @type {State}\n   */\n  function urlInside(code) {\n    if (code === 62) {\n      effects.exit('autolinkProtocol')\n      effects.enter('autolinkMarker')\n      effects.consume(code)\n      effects.exit('autolinkMarker')\n      effects.exit('autolink')\n      return ok\n    }\n\n    // ASCII control, space, or `<`.\n    if (code === null || code === 32 || code === 60 || asciiControl(code)) {\n      return nok(code)\n    }\n    effects.consume(code)\n    return urlInside\n  }\n\n  /**\n   * In email atext.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *              ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailAtext(code) {\n    if (code === 64) {\n      effects.consume(code)\n      return emailAtSignOrDot\n    }\n    if (asciiAtext(code)) {\n      effects.consume(code)\n      return emailAtext\n    }\n    return nok(code)\n  }\n\n  /**\n   * In label, after at-sign or dot.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *                 ^       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailAtSignOrDot(code) {\n    return asciiAlphanumeric(code) ? emailLabel(code) : nok(code)\n  }\n\n  /**\n   * In label, where `.` and `>` are allowed.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *                   ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailLabel(code) {\n    if (code === 46) {\n      effects.consume(code)\n      size = 0\n      return emailAtSignOrDot\n    }\n    if (code === 62) {\n      // Exit, then change the token type.\n      effects.exit('autolinkProtocol').type = 'autolinkEmail'\n      effects.enter('autolinkMarker')\n      effects.consume(code)\n      effects.exit('autolinkMarker')\n      effects.exit('autolink')\n      return ok\n    }\n    return emailValue(code)\n  }\n\n  /**\n   * In label, where `.` and `>` are *not* allowed.\n   *\n   * Though, this is also used in `emailLabel` to parse other values.\n   *\n   * ```markdown\n   * > | a<user.name@ex-ample.com>b\n   *                    ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailValue(code) {\n    // ASCII alphanumeric or `-`.\n    if ((code === 45 || asciiAlphanumeric(code)) && size++ < 63) {\n      const next = code === 45 ? emailValue : emailLabel\n      effects.consume(code)\n      return next\n    }\n    return nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {decodeNamedCharacterReference} from 'decode-named-character-reference'\nimport {\n  asciiAlphanumeric,\n  asciiDigit,\n  asciiHexDigit\n} from 'micromark-util-character'\n/** @type {Construct} */\nexport const characterReference = {\n  name: 'characterReference',\n  tokenize: tokenizeCharacterReference\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCharacterReference(effects, ok, nok) {\n  const self = this\n  let size = 0\n  /** @type {number} */\n  let max\n  /** @type {(code: Code) => boolean} */\n  let test\n  return start\n\n  /**\n   * Start of character reference.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *      ^\n   * > | a&#123;b\n   *      ^\n   * > | a&#x9;b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('characterReference')\n    effects.enter('characterReferenceMarker')\n    effects.consume(code)\n    effects.exit('characterReferenceMarker')\n    return open\n  }\n\n  /**\n   * After `&`, at `#` for numeric references or alphanumeric for named\n   * references.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *       ^\n   * > | a&#123;b\n   *       ^\n   * > | a&#x9;b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (code === 35) {\n      effects.enter('characterReferenceMarkerNumeric')\n      effects.consume(code)\n      effects.exit('characterReferenceMarkerNumeric')\n      return numeric\n    }\n    effects.enter('characterReferenceValue')\n    max = 31\n    test = asciiAlphanumeric\n    return value(code)\n  }\n\n  /**\n   * After `#`, at `x` for hexadecimals or digit for decimals.\n   *\n   * ```markdown\n   * > | a&#123;b\n   *        ^\n   * > | a&#x9;b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function numeric(code) {\n    if (code === 88 || code === 120) {\n      effects.enter('characterReferenceMarkerHexadecimal')\n      effects.consume(code)\n      effects.exit('characterReferenceMarkerHexadecimal')\n      effects.enter('characterReferenceValue')\n      max = 6\n      test = asciiHexDigit\n      return value\n    }\n    effects.enter('characterReferenceValue')\n    max = 7\n    test = asciiDigit\n    return value(code)\n  }\n\n  /**\n   * After markers (`&#x`, `&#`, or `&`), in value, before `;`.\n   *\n   * The character reference kind defines what and how many characters are\n   * allowed.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *       ^^^\n   * > | a&#123;b\n   *        ^^^\n   * > | a&#x9;b\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function value(code) {\n    if (code === 59 && size) {\n      const token = effects.exit('characterReferenceValue')\n      if (\n        test === asciiAlphanumeric &&\n        !decodeNamedCharacterReference(self.sliceSerialize(token))\n      ) {\n        return nok(code)\n      }\n\n      // To do: `markdown-rs` uses a different name:\n      // `CharacterReferenceMarkerSemi`.\n      effects.enter('characterReferenceMarker')\n      effects.consume(code)\n      effects.exit('characterReferenceMarker')\n      effects.exit('characterReference')\n      return ok\n    }\n    if (test(code) && size++ < max) {\n      effects.consume(code)\n      return value\n    }\n    return nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {push, splice} from 'micromark-util-chunked'\nimport {classifyCharacter} from 'micromark-util-classify-character'\nimport {resolveAll} from 'micromark-util-resolve-all'\n/** @type {Construct} */\nexport const attention = {\n  name: 'attention',\n  tokenize: tokenizeAttention,\n  resolveAll: resolveAllAttention\n}\n\n/**\n * Take all events and resolve attention to emphasis or strong.\n *\n * @type {Resolver}\n */\nfunction resolveAllAttention(events, context) {\n  let index = -1\n  /** @type {number} */\n  let open\n  /** @type {Token} */\n  let group\n  /** @type {Token} */\n  let text\n  /** @type {Token} */\n  let openingSequence\n  /** @type {Token} */\n  let closingSequence\n  /** @type {number} */\n  let use\n  /** @type {Array<Event>} */\n  let nextEvents\n  /** @type {number} */\n  let offset\n\n  // Walk through all events.\n  //\n  // Note: performance of this is fine on an mb of normal markdown, but itâ€™s\n  // a bottleneck for malicious stuff.\n  while (++index < events.length) {\n    // Find a token that can close.\n    if (\n      events[index][0] === 'enter' &&\n      events[index][1].type === 'attentionSequence' &&\n      events[index][1]._close\n    ) {\n      open = index\n\n      // Now walk back to find an opener.\n      while (open--) {\n        // Find a token that can open the closer.\n        if (\n          events[open][0] === 'exit' &&\n          events[open][1].type === 'attentionSequence' &&\n          events[open][1]._open &&\n          // If the markers are the same:\n          context.sliceSerialize(events[open][1]).charCodeAt(0) ===\n            context.sliceSerialize(events[index][1]).charCodeAt(0)\n        ) {\n          // If the opening can close or the closing can open,\n          // and the close size *is not* a multiple of three,\n          // but the sum of the opening and closing size *is* multiple of three,\n          // then donâ€™t match.\n          if (\n            (events[open][1]._close || events[index][1]._open) &&\n            (events[index][1].end.offset - events[index][1].start.offset) % 3 &&\n            !(\n              (events[open][1].end.offset -\n                events[open][1].start.offset +\n                events[index][1].end.offset -\n                events[index][1].start.offset) %\n              3\n            )\n          ) {\n            continue\n          }\n\n          // Number of markers to use from the sequence.\n          use =\n            events[open][1].end.offset - events[open][1].start.offset > 1 &&\n            events[index][1].end.offset - events[index][1].start.offset > 1\n              ? 2\n              : 1\n          const start = Object.assign({}, events[open][1].end)\n          const end = Object.assign({}, events[index][1].start)\n          movePoint(start, -use)\n          movePoint(end, use)\n          openingSequence = {\n            type: use > 1 ? 'strongSequence' : 'emphasisSequence',\n            start,\n            end: Object.assign({}, events[open][1].end)\n          }\n          closingSequence = {\n            type: use > 1 ? 'strongSequence' : 'emphasisSequence',\n            start: Object.assign({}, events[index][1].start),\n            end\n          }\n          text = {\n            type: use > 1 ? 'strongText' : 'emphasisText',\n            start: Object.assign({}, events[open][1].end),\n            end: Object.assign({}, events[index][1].start)\n          }\n          group = {\n            type: use > 1 ? 'strong' : 'emphasis',\n            start: Object.assign({}, openingSequence.start),\n            end: Object.assign({}, closingSequence.end)\n          }\n          events[open][1].end = Object.assign({}, openingSequence.start)\n          events[index][1].start = Object.assign({}, closingSequence.end)\n          nextEvents = []\n\n          // If there are more markers in the opening, add them before.\n          if (events[open][1].end.offset - events[open][1].start.offset) {\n            nextEvents = push(nextEvents, [\n              ['enter', events[open][1], context],\n              ['exit', events[open][1], context]\n            ])\n          }\n\n          // Opening.\n          nextEvents = push(nextEvents, [\n            ['enter', group, context],\n            ['enter', openingSequence, context],\n            ['exit', openingSequence, context],\n            ['enter', text, context]\n          ])\n\n          // Always populated by defaults.\n\n          // Between.\n          nextEvents = push(\n            nextEvents,\n            resolveAll(\n              context.parser.constructs.insideSpan.null,\n              events.slice(open + 1, index),\n              context\n            )\n          )\n\n          // Closing.\n          nextEvents = push(nextEvents, [\n            ['exit', text, context],\n            ['enter', closingSequence, context],\n            ['exit', closingSequence, context],\n            ['exit', group, context]\n          ])\n\n          // If there are more markers in the closing, add them after.\n          if (events[index][1].end.offset - events[index][1].start.offset) {\n            offset = 2\n            nextEvents = push(nextEvents, [\n              ['enter', events[index][1], context],\n              ['exit', events[index][1], context]\n            ])\n          } else {\n            offset = 0\n          }\n          splice(events, open - 1, index - open + 3, nextEvents)\n          index = open + nextEvents.length - offset - 2\n          break\n        }\n      }\n    }\n  }\n\n  // Remove remaining sequences.\n  index = -1\n  while (++index < events.length) {\n    if (events[index][1].type === 'attentionSequence') {\n      events[index][1].type = 'data'\n    }\n  }\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeAttention(effects, ok) {\n  const attentionMarkers = this.parser.constructs.attentionMarkers.null\n  const previous = this.previous\n  const before = classifyCharacter(previous)\n\n  /** @type {NonNullable<Code>} */\n  let marker\n  return start\n\n  /**\n   * Before a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    marker = code\n    effects.enter('attentionSequence')\n    return inside(code)\n  }\n\n  /**\n   * In a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === marker) {\n      effects.consume(code)\n      return inside\n    }\n    const token = effects.exit('attentionSequence')\n\n    // To do: next major: move this to resolver, just like `markdown-rs`.\n    const after = classifyCharacter(code)\n\n    // Always populated by defaults.\n\n    const open =\n      !after || (after === 2 && before) || attentionMarkers.includes(code)\n    const close =\n      !before || (before === 2 && after) || attentionMarkers.includes(previous)\n    token._open = Boolean(marker === 42 ? open : open && (before || !close))\n    token._close = Boolean(marker === 42 ? close : close && (after || !open))\n    return ok(code)\n  }\n}\n\n/**\n * Move a point a bit.\n *\n * Note: `move` only works inside lines! Itâ€™s not possible to move past other\n * chunks (replacement characters, tabs, or line endings).\n *\n * @param {Point} point\n * @param {number} offset\n * @returns {void}\n */\nfunction movePoint(point, offset) {\n  point.column += offset\n  point.offset += offset\n  point._bufferIndex += offset\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {asciiPunctuation} from 'micromark-util-character'\n/** @type {Construct} */\nexport const characterEscape = {\n  name: 'characterEscape',\n  tokenize: tokenizeCharacterEscape\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCharacterEscape(effects, ok, nok) {\n  return start\n\n  /**\n   * Start of character escape.\n   *\n   * ```markdown\n   * > | a\\*b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('characterEscape')\n    effects.enter('escapeMarker')\n    effects.consume(code)\n    effects.exit('escapeMarker')\n    return inside\n  }\n\n  /**\n   * After `\\`, at punctuation.\n   *\n   * ```markdown\n   * > | a\\*b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    // ASCII punctuation.\n    if (asciiPunctuation(code)) {\n      effects.enter('characterEscapeValue')\n      effects.consume(code)\n      effects.exit('characterEscapeValue')\n      effects.exit('characterEscape')\n      return ok\n    }\n    return nok(code)\n  }\n}\n"],"names":["blankLine","tokenize","effects","ok","nok","code","markdownSpace","factorySpace","after","markdownLineEnding","partial","blockQuote","name","self","this","state","containerState","open","enter","_container","consume","exit","continuation","contBefore","parser","constructs","disable","null","includes","undefined","attempt","autolink","size","asciiAlpha","schemeOrEmailAtext","emailAtext","asciiAlphanumeric","schemeInsideOrEmailAtext","urlInside","asciiControl","emailAtSignOrDot","asciiAtext","emailLabel","type","emailValue","next","characterReference","max","test","numeric","value","asciiHexDigit","asciiDigit","token","decodeNamedCharacterReference","sliceSerialize","attention","attentionMarkers","previous","before","classifyCharacter","marker","inside","close","_open","Boolean","_close","resolveAll","events","context","group","text","openingSequence","closingSequence","use","nextEvents","offset","index","length","charCodeAt","end","start","Object","assign","movePoint","push","insideSpan","slice","splice","point","column","_bufferIndex","characterEscape","asciiPunctuation"],"sourceRoot":""}