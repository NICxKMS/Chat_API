{"version":3,"file":"static/js/markdown-0bdb5f0a.fc780c3e.chunk.js","mappings":"yNAmBO,MAAMA,EAAa,CACxBC,KAAM,aACNC,SAaF,SAA4BC,EAASC,EAAIC,GACvC,MAAMC,EAAOC,KAEb,IAAIC,EACJ,OAYA,SAAeC,GAKb,OADAN,EAAQO,MAAM,cAchB,SAAgBD,GAGd,OAAOE,EAAAA,EAAaC,KAClBN,EACAH,EACAU,EAEAR,EACA,kBACA,wBACA,wBARKM,CASLF,EACJ,CA1BSK,CAAOL,EAChB,EAqCA,SAASI,EAAWJ,GAIlB,OAHAD,GAAaO,EAAAA,EAAAA,GACXT,EAAKU,eAAeV,EAAKW,OAAOX,EAAKW,OAAOC,OAAS,GAAG,IAAIC,MAAM,GAAI,IAE3D,KAATV,GACFN,EAAQO,MAAM,oBACdP,EAAQiB,QAAQX,GAChBN,EAAQkB,KAAK,oBACNC,GAEFjB,EAAII,EACb,CAYA,SAASa,EAAYb,GAEnB,OAAOc,EAAAA,EAAAA,IAA0Bd,IAC7Be,EAAAA,EAAAA,GAAkBrB,EAASsB,EAA3BD,CAA8Cf,GAC9CgB,EAAkBhB,EACxB,CAYA,SAASgB,EAAkBhB,GACzB,OAAOiB,EAAAA,EAAAA,GACLvB,EACAwB,EAEAtB,EACA,wBACA,+BACA,qCACA,2BACA,8BATKqB,CAULjB,EACJ,CAYA,SAASkB,EAAiBlB,GACxB,OAAON,EAAQyB,QAAQC,EAAaC,EAAOA,EAApC3B,CAA2CM,EACpD,CAcA,SAASqB,EAAMrB,GACb,OAAOsB,EAAAA,EAAAA,IAActB,IACjBuB,EAAAA,EAAAA,GAAa7B,EAAS8B,EAAiB,aAAvCD,CAAqDvB,GACrDwB,EAAgBxB,EACtB,CAcA,SAASwB,EAAgBxB,GACvB,OAAa,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,IACtCN,EAAQkB,KAAK,cAKbf,EAAK6B,OAAOC,QAAQC,KAAK7B,GAKlBJ,EAAGK,IAELJ,EAAII,EACb,CACF,GAtLMoB,EAAc,CAClB3B,SA2LF,SAA6BC,EAASC,EAAIC,GACxC,OAcA,SAAqBI,GACnB,OAAOc,EAAAA,EAAAA,IAA0Bd,IAC7Be,EAAAA,EAAAA,GAAkBrB,EAASmC,EAA3Bd,CAAyCf,GACzCJ,EAAII,EACV,EAaA,SAAS6B,EAAa7B,GACpB,OAAO8B,EAAAA,EAAAA,GACLpC,EACAqC,EACAnC,EACA,kBACA,wBACA,wBANKkC,CAOL9B,EACJ,CAYA,SAAS+B,EAAW/B,GAClB,OAAOsB,EAAAA,EAAAA,IAActB,IACjBuB,EAAAA,EAAAA,GAAa7B,EAASsC,EAA8B,aAApDT,CAAkEvB,GAClEgC,EAA6BhC,EACnC,CAYA,SAASgC,EAA6BhC,GACpC,OAAgB,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,GAAQL,EAAGK,GAAQJ,EAAII,EACpE,CACF,EAlQEiC,SAAS,E,kDClBJ,MAAMC,EAAkB,CAC7B1C,KAAM,kBACNC,SAOF,SAAiCC,EAASC,EAAIC,GAC5C,OAaA,SAAeI,GAGb,OAFAN,EAAQO,MAAM,mBACdP,EAAQiB,QAAQX,GACTqB,CACT,EAaA,SAASA,EAAMrB,GACb,OAAIyB,EAAAA,EAAAA,IAAmBzB,IACrBN,EAAQkB,KAAK,mBACNjB,EAAGK,IAELJ,EAAII,EACb,CACF,E,6DC9CO,MAAMmC,EAAe,CAC1B3C,KAAM,eACNC,SAaF,SAA8BC,EAASC,EAAIC,GACzC,MAAMC,EAAOC,KACb,OAgBA,SAAeE,GAMb,OAHAN,EAAQO,MAAM,iBAGPsB,EAAAA,EAAAA,GAAa7B,EAAS0C,EAAa,aAAc,EAAjDb,CAAwDvB,EACjE,EAYA,SAASoC,EAAYpC,GACnB,MAAMqC,EAAOxC,EAAKW,OAAOX,EAAKW,OAAOC,OAAS,GAC9C,OAAO4B,GACY,eAAjBA,EAAK,GAAGC,MACRD,EAAK,GAAG9B,eAAe8B,EAAK,IAAI,GAAM5B,QAAU,EAC9C8B,EAAQvC,GACRJ,EAAII,EACV,CAYA,SAASuC,EAAQvC,GACf,OAAa,OAATA,EACKqB,EAAMrB,IAEXyB,EAAAA,EAAAA,IAAmBzB,GACdN,EAAQyB,QAAQqB,EAAcD,EAASlB,EAAvC3B,CAA8CM,IAEvDN,EAAQO,MAAM,iBACPwC,EAAOzC,GAChB,CAYA,SAASyC,EAAOzC,GACd,OAAa,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,IACtCN,EAAQkB,KAAK,iBACN2B,EAAQvC,KAEjBN,EAAQiB,QAAQX,GACTyC,EACT,CAGA,SAASpB,EAAMrB,GAKb,OAJAN,EAAQkB,KAAK,gBAINjB,EAAGK,EACZ,CACF,GAvGMwC,EAAe,CACnB/C,SA4GF,SAA8BC,EAASC,EAAIC,GACzC,MAAMC,EAAOC,KACb,OAAO0C,EAaP,SAASA,EAAaxC,GAGpB,OAAIH,EAAK6B,OAAOgB,KAAK7C,EAAK8C,MAAMC,MACvBhD,EAAII,IAETyB,EAAAA,EAAAA,IAAmBzB,IACrBN,EAAQO,MAAM,cACdP,EAAQiB,QAAQX,GAChBN,EAAQkB,KAAK,cACN4B,IASFjB,EAAAA,EAAAA,GAAa7B,EAAS0C,EAAa,aAAc,EAAjDb,CAAwDvB,EACjE,CAYA,SAASoC,EAAYpC,GACnB,MAAMqC,EAAOxC,EAAKW,OAAOX,EAAKW,OAAOC,OAAS,GAC9C,OAAO4B,GACY,eAAjBA,EAAK,GAAGC,MACRD,EAAK,GAAG9B,eAAe8B,EAAK,IAAI,GAAM5B,QAAU,EAC9Cd,EAAGK,IACHyB,EAAAA,EAAAA,IAAmBzB,GACnBwC,EAAaxC,GACbJ,EAAII,EACV,CACF,EApKEiC,SAAS,E,uECDJ,MAAMY,EAAa,CACxBrD,KAAM,aACNC,SA2DF,SAA4BC,EAASC,EAAIC,GACvC,IAAIkD,EAAO,EACX,OAYA,SAAe9C,GAGb,OADAN,EAAQO,MAAM,cAchB,SAAgBD,GAEd,OADAN,EAAQO,MAAM,sBACP8C,EAAa/C,EACtB,CAhBSK,CAAOL,EAChB,EA2BA,SAAS+C,EAAa/C,GACpB,OAAa,KAATA,GAAe8C,IAAS,GAC1BpD,EAAQiB,QAAQX,GACT+C,GAII,OAAT/C,IAAiBc,EAAAA,EAAAA,IAA0Bd,IAC7CN,EAAQkB,KAAK,sBACN2B,EAAQvC,IAEVJ,EAAII,EACb,CAYA,SAASuC,EAAQvC,GACf,OAAa,KAATA,GACFN,EAAQO,MAAM,sBACP+C,EAAgBhD,IAEZ,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,IACtCN,EAAQkB,KAAK,cAINjB,EAAGK,KAERsB,EAAAA,EAAAA,IAActB,IACTuB,EAAAA,EAAAA,GAAa7B,EAAS6C,EAAS,aAA/BhB,CAA6CvB,IAKtDN,EAAQO,MAAM,kBACPgD,EAAKjD,GACd,CAcA,SAASgD,EAAgBhD,GACvB,OAAa,KAATA,GACFN,EAAQiB,QAAQX,GACTgD,IAETtD,EAAQkB,KAAK,sBACN2B,EAAQvC,GACjB,CAYA,SAASiD,EAAKjD,GACZ,OAAa,OAATA,GAA0B,KAATA,IAAec,EAAAA,EAAAA,IAA0Bd,IAC5DN,EAAQkB,KAAK,kBACN2B,EAAQvC,KAEjBN,EAAQiB,QAAQX,GACTiD,EACT,CACF,EA5LEC,QAIF,SAA2B1C,EAAQ2C,GACjC,IAGIC,EAEAC,EALAC,EAAa9C,EAAOC,OAAS,EAC7B8C,EAAe,EAOkB,eAAjC/C,EAAO+C,GAAc,GAAGjB,OAC1BiB,GAAgB,GAKhBD,EAAa,EAAIC,GACc,eAA/B/C,EAAO8C,GAAY,GAAGhB,OAEtBgB,GAAc,GAGiB,uBAA/B9C,EAAO8C,GAAY,GAAGhB,OACrBiB,IAAiBD,EAAa,GAC5BA,EAAa,EAAIC,GACmB,eAAnC/C,EAAO8C,EAAa,GAAG,GAAGhB,QAE9BgB,GAAcC,EAAe,IAAMD,EAAa,EAAI,GAElDA,EAAaC,IACfH,EAAU,CACRd,KAAM,iBACNkB,MAAOhD,EAAO+C,GAAc,GAAGC,MAC/BC,IAAKjD,EAAO8C,GAAY,GAAGG,KAE7BJ,EAAO,CACLf,KAAM,YACNkB,MAAOhD,EAAO+C,GAAc,GAAGC,MAC/BC,IAAKjD,EAAO8C,GAAY,GAAGG,IAC3BC,YAAa,SAEfC,EAAAA,EAAAA,GAAOnD,EAAQ+C,EAAcD,EAAaC,EAAe,EAAG,CAC1D,CAAC,QAASH,EAASD,GACnB,CAAC,QAASE,EAAMF,GAChB,CAAC,OAAQE,EAAMF,GACf,CAAC,OAAQC,EAASD,MAGtB,OAAO3C,CACT,E,kDC5DO,MAAMoD,EAAW,CACtBpE,KAAM,WACNC,SA8EF,SAA0BC,EAASC,EAAIC,GAErC,IAEIkD,EAEAe,EAJAC,EAAW,EAKf,OAcA,SAAe9D,GAGb,OAFAN,EAAQO,MAAM,YACdP,EAAQO,MAAM,oBACP8C,EAAa/C,EACtB,EAYA,SAAS+C,EAAa/C,GACpB,OAAa,KAATA,GACFN,EAAQiB,QAAQX,GAChB8D,IACOf,IAETrD,EAAQkB,KAAK,oBACNmD,EAAQ/D,GACjB,CAYA,SAAS+D,EAAQ/D,GAEf,OAAa,OAATA,EACKJ,EAAII,GAMA,KAATA,GACFN,EAAQO,MAAM,SACdP,EAAQiB,QAAQX,GAChBN,EAAQkB,KAAK,SACNmD,GAII,KAAT/D,GACF6D,EAAQnE,EAAQO,MAAM,oBACtB6C,EAAO,EACAkB,EAAchE,KAEnByB,EAAAA,EAAAA,IAAmBzB,IACrBN,EAAQO,MAAM,cACdP,EAAQiB,QAAQX,GAChBN,EAAQkB,KAAK,cACNmD,IAITrE,EAAQO,MAAM,gBACPgD,EAAKjD,GACd,CAYA,SAASiD,EAAKjD,GACZ,OACW,OAATA,GACS,KAATA,GACS,KAATA,IACAyB,EAAAA,EAAAA,IAAmBzB,IAEnBN,EAAQkB,KAAK,gBACNmD,EAAQ/D,KAEjBN,EAAQiB,QAAQX,GACTiD,EACT,CAYA,SAASe,EAAchE,GAErB,OAAa,KAATA,GACFN,EAAQiB,QAAQX,GAChB8C,IACOkB,GAILlB,IAASgB,GACXpE,EAAQkB,KAAK,oBACblB,EAAQkB,KAAK,YACNjB,EAAGK,KAIZ6D,EAAMvB,KAAO,eACNW,EAAKjD,GACd,CACF,EA7NEkD,QAMF,SAAyB1C,GACvB,IAGIyD,EAEAhE,EALAiE,EAAgB1D,EAAOC,OAAS,EAChC0D,EAAiB,EAOrB,KACsC,eAAnC3D,EAAO2D,GAAgB,GAAG7B,MACU,UAAnC9B,EAAO2D,GAAgB,GAAG7B,MACO,eAAlC9B,EAAO0D,GAAe,GAAG5B,MACU,UAAlC9B,EAAO0D,GAAe,GAAG5B,MAK3B,IAHA2B,EAAQE,IAGCF,EAAQC,GACf,GAA8B,iBAA1B1D,EAAOyD,GAAO,GAAG3B,KAAyB,CAE5C9B,EAAO2D,GAAgB,GAAG7B,KAAO,kBACjC9B,EAAO0D,GAAe,GAAG5B,KAAO,kBAChC6B,GAAkB,EAClBD,GAAiB,EACjB,KACF,CAKJD,EAAQE,EAAiB,EACzBD,IACA,OAASD,GAASC,QACFE,IAAVnE,EACEgE,IAAUC,GAA2C,eAA1B1D,EAAOyD,GAAO,GAAG3B,OAC9CrC,EAAQgE,GAGVA,IAAUC,GACgB,eAA1B1D,EAAOyD,GAAO,GAAG3B,OAEjB9B,EAAOP,GAAO,GAAGqC,KAAO,eACpB2B,IAAUhE,EAAQ,IACpBO,EAAOP,GAAO,GAAGwD,IAAMjD,EAAOyD,EAAQ,GAAG,GAAGR,IAC5CjD,EAAOmD,OAAO1D,EAAQ,EAAGgE,EAAQhE,EAAQ,GACzCiE,GAAiBD,EAAQhE,EAAQ,EACjCgE,EAAQhE,EAAQ,GAElBA,OAAQmE,GAGZ,OAAO5D,CACT,EA1DE6D,SAgEF,SAAkBrE,GAEhB,OACW,KAATA,GACgD,oBAAhDF,KAAKU,OAAOV,KAAKU,OAAOC,OAAS,GAAG,GAAG6B,IAE3C,E,6DC3EA,MAAMgC,EAAsB,CAC1B7E,SAwbF,SAAqCC,EAASC,EAAIC,GAChD,MAAMC,EAAOC,KACb,OAOA,SAAeE,GACb,GAAa,OAATA,EACF,OAAOJ,EAAII,GAKb,OAHAN,EAAQO,MAAM,cACdP,EAAQiB,QAAQX,GAChBN,EAAQkB,KAAK,cACN2D,CACT,EAOA,SAASA,EAAUvE,GACjB,OAAOH,EAAK6B,OAAOgB,KAAK7C,EAAK8C,MAAMC,MAAQhD,EAAII,GAAQL,EAAGK,EAC5D,CACF,EAldEiC,SAAS,GAIEuC,EAAa,CACxBhF,KAAM,aACNC,SAQF,SAA4BC,EAASC,EAAIC,GACvC,MAAMC,EAAOC,KAEP2E,EAAa,CACjBhF,SA+SF,SAA4BC,EAASC,EAAIC,GACvC,IAAIkD,EAAO,EACX,OAAO4B,EAOP,SAASA,EAAY1E,GAInB,OAHAN,EAAQO,MAAM,cACdP,EAAQiB,QAAQX,GAChBN,EAAQkB,KAAK,cACN4C,CACT,CAcA,SAASA,EAAMxD,GAKb,OADAN,EAAQO,MAAM,oBACPqB,EAAAA,EAAAA,IAActB,IACjBuB,EAAAA,EAAAA,GACE7B,EACAiF,EACA,aACA9E,EAAK6B,OAAOkD,WAAWC,QAAQC,KAAKC,SAAS,qBACzCX,EACA,EANN7C,CAOEvB,GACF2E,EAAoB3E,EAC1B,CAcA,SAAS2E,EAAoB3E,GAC3B,OAAIA,IAASgF,GACXtF,EAAQO,MAAM,2BACP+D,EAAchE,IAEhBJ,EAAII,EACb,CAcA,SAASgE,EAAchE,GACrB,OAAIA,IAASgF,GACXlC,IACApD,EAAQiB,QAAQX,GACTgE,GAELlB,GAAQgB,GACVpE,EAAQkB,KAAK,4BACNU,EAAAA,EAAAA,IAActB,IACjBuB,EAAAA,EAAAA,GAAa7B,EAASuF,EAAoB,aAA1C1D,CAAwDvB,GACxDiF,EAAmBjF,IAElBJ,EAAII,EACb,CAcA,SAASiF,EAAmBjF,GAC1B,OAAa,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,IACtCN,EAAQkB,KAAK,mBACNjB,EAAGK,IAELJ,EAAII,EACb,CACF,EA7ZEiC,SAAS,GAEX,IAGI+C,EAHAE,EAAgB,EAChBpB,EAAW,EAGf,OAcA,SAAe9D,GAEb,OAeF,SAA4BA,GAC1B,MAAMqC,EAAOxC,EAAKW,OAAOX,EAAKW,OAAOC,OAAS,GAS9C,OARAyE,EACE7C,GAAyB,eAAjBA,EAAK,GAAGC,KACZD,EAAK,GAAG9B,eAAe8B,EAAK,IAAI,GAAM5B,OACtC,EACNuE,EAAShF,EACTN,EAAQO,MAAM,cACdP,EAAQO,MAAM,mBACdP,EAAQO,MAAM,2BACP8C,EAAa/C,EACtB,CA1BSmF,CAAmBnF,EAC5B,EAuCA,SAAS+C,EAAa/C,GACpB,OAAIA,IAASgF,GACXlB,IACApE,EAAQiB,QAAQX,GACT+C,GAELe,EAAW,EACNlE,EAAII,IAEbN,EAAQkB,KAAK,4BACNU,EAAAA,EAAAA,IAActB,IACjBuB,EAAAA,EAAAA,GAAa7B,EAAS0F,EAAY,aAAlC7D,CAAgDvB,GAChDoF,EAAWpF,GACjB,CAcA,SAASoF,EAAWpF,GAClB,OAAa,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,IACtCN,EAAQkB,KAAK,mBACNf,EAAKwF,UACR1F,EAAGK,GACHN,EAAQ4F,MAAMhB,EAAqBiB,EAAgBlE,EAAnD3B,CAA0DM,KAEhEN,EAAQO,MAAM,uBACdP,EAAQO,MAAM,cAAe,CAC3ByD,YAAa,WAER8B,EAAKxF,GACd,CAcA,SAASwF,EAAKxF,GACZ,OAAa,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,IACtCN,EAAQkB,KAAK,eACblB,EAAQkB,KAAK,uBACNwE,EAAWpF,KAEhBsB,EAAAA,EAAAA,IAActB,IAChBN,EAAQkB,KAAK,eACblB,EAAQkB,KAAK,wBACNW,EAAAA,EAAAA,GAAa7B,EAAS+F,EAAY,aAAlClE,CAAgDvB,IAE5C,KAATA,GAAeA,IAASgF,EACnBpF,EAAII,IAEbN,EAAQiB,QAAQX,GACTwF,EACT,CAcA,SAASC,EAAWzF,GAClB,OAAa,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,GAC/BoF,EAAWpF,IAEpBN,EAAQO,MAAM,uBACdP,EAAQO,MAAM,cAAe,CAC3ByD,YAAa,WAERgC,EAAK1F,GACd,CAcA,SAAS0F,EAAK1F,GACZ,OAAa,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,IACtCN,EAAQkB,KAAK,eACblB,EAAQkB,KAAK,uBACNwE,EAAWpF,IAEP,KAATA,GAAeA,IAASgF,EACnBpF,EAAII,IAEbN,EAAQiB,QAAQX,GACT0F,EACT,CAeA,SAASH,EAAevF,GACtB,OAAON,EAAQyB,QAAQsD,EAAYpD,EAAOsE,EAAnCjG,CAAkDM,EAC3D,CAcA,SAAS2F,EAAc3F,GAIrB,OAHAN,EAAQO,MAAM,cACdP,EAAQiB,QAAQX,GAChBN,EAAQkB,KAAK,cACN2C,CACT,CAcA,SAASA,EAAavD,GACpB,OAAOkF,EAAgB,IAAK5D,EAAAA,EAAAA,IAActB,IACtCuB,EAAAA,EAAAA,GACE7B,EACAkG,EACA,aACAV,EAAgB,EAJlB3D,CAKEvB,GACF4F,EAAmB5F,EACzB,CAcA,SAAS4F,EAAmB5F,GAC1B,OAAa,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,GAC/BN,EAAQ4F,MAAMhB,EAAqBiB,EAAgBlE,EAAnD3B,CAA0DM,IAEnEN,EAAQO,MAAM,iBACP4F,EAAa7F,GACtB,CAcA,SAAS6F,EAAa7F,GACpB,OAAa,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,IACtCN,EAAQkB,KAAK,iBACNgF,EAAmB5F,KAE5BN,EAAQiB,QAAQX,GACT6F,EACT,CAcA,SAASxE,EAAMrB,GAEb,OADAN,EAAQkB,KAAK,cACNjB,EAAGK,EACZ,CAsHF,EA1aE8F,UAAU,E,wECJL,MAAM1C,EAAU,CACrB3D,SAyBF,SAAyBC,EAASC,GAEhC,IAAI0E,EACJ,OAYA,SAAoBrE,GAKlB,OAJAN,EAAQO,MAAM,WACdoE,EAAW3E,EAAQO,MAAM,eAAgB,CACvCyD,YAAa,YAERqC,EAAY/F,EACrB,EAYA,SAAS+F,EAAY/F,GACnB,OAAa,OAATA,EACKsD,EAAWtD,IAKhByB,EAAAA,EAAAA,IAAmBzB,GACdN,EAAQ4F,MACbU,EACAC,EACA3C,EAHK5D,CAILM,IAIJN,EAAQiB,QAAQX,GACT+F,EACT,CAOA,SAASzC,EAAWtD,GAGlB,OAFAN,EAAQkB,KAAK,gBACblB,EAAQkB,KAAK,WACNjB,EAAGK,EACZ,CAOA,SAASiG,EAAgBjG,GAQvB,OAPAN,EAAQiB,QAAQX,GAChBN,EAAQkB,KAAK,gBACbyD,EAAS6B,KAAOxG,EAAQO,MAAM,eAAgB,CAC5CyD,YAAa,UACbW,aAEFA,EAAWA,EAAS6B,KACbH,CACT,CACF,EAvGE7C,QAeF,SAAwB1C,GAEtB,OADA2F,EAAAA,EAAAA,GAAY3F,GACLA,CACT,GAdMwF,EAAwB,CAC5BvG,SAwGF,SAA8BC,EAASC,EAAIC,GACzC,MAAMC,EAAOC,KACb,OAOA,SAAwBE,GAKtB,OAJAN,EAAQkB,KAAK,gBACblB,EAAQO,MAAM,cACdP,EAAQiB,QAAQX,GAChBN,EAAQkB,KAAK,eACNW,EAAAA,EAAAA,GAAa7B,EAAS0G,EAAU,aACzC,EAOA,SAASA,EAASpG,GAChB,GAAa,OAATA,IAAiByB,EAAAA,EAAAA,IAAmBzB,GACtC,OAAOJ,EAAII,GAKb,MAAMqC,EAAOxC,EAAKW,OAAOX,EAAKW,OAAOC,OAAS,GAC9C,OACGZ,EAAK6B,OAAOkD,WAAWC,QAAQC,KAAKC,SAAS,iBAC9C1C,GACiB,eAAjBA,EAAK,GAAGC,MACRD,EAAK,GAAG9B,eAAe8B,EAAK,IAAI,GAAM5B,QAAU,EAEzCd,EAAGK,GAELN,EAAQ2F,UAAUxF,EAAK6B,OAAOkD,WAAWyB,KAAMzG,EAAKD,EAApDD,CAAwDM,EACjE,CACF,EA/IEiC,SAAS,E","sources":["../node_modules/react-markdown/node_modules/micromark-core-commonmark/lib/definition.js","../node_modules/react-markdown/node_modules/micromark-core-commonmark/lib/hard-break-escape.js","../node_modules/react-markdown/node_modules/micromark-core-commonmark/lib/code-indented.js","../node_modules/react-markdown/node_modules/micromark-core-commonmark/lib/heading-atx.js","../node_modules/react-markdown/node_modules/micromark-core-commonmark/lib/code-text.js","../node_modules/react-markdown/node_modules/micromark-core-commonmark/lib/code-fenced.js","../node_modules/react-markdown/node_modules/micromark-core-commonmark/lib/content.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factoryDestination} from 'micromark-factory-destination'\nimport {factoryLabel} from 'micromark-factory-label'\nimport {factorySpace} from 'micromark-factory-space'\nimport {factoryTitle} from 'micromark-factory-title'\nimport {factoryWhitespace} from 'micromark-factory-whitespace'\nimport {\n  markdownLineEnding,\n  markdownLineEndingOrSpace,\n  markdownSpace\n} from 'micromark-util-character'\nimport {normalizeIdentifier} from 'micromark-util-normalize-identifier'\n/** @type {Construct} */\nexport const definition = {\n  name: 'definition',\n  tokenize: tokenizeDefinition\n}\n\n/** @type {Construct} */\nconst titleBefore = {\n  tokenize: tokenizeTitleBefore,\n  partial: true\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeDefinition(effects, ok, nok) {\n  const self = this\n  /** @type {string} */\n  let identifier\n  return start\n\n  /**\n   * At start of a definition.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // Do not interrupt paragraphs (but do follow definitions).\n    // To do: do `interrupt` the way `markdown-rs` does.\n    // To do: parse whitespace the way `markdown-rs` does.\n    effects.enter('definition')\n    return before(code)\n  }\n\n  /**\n   * After optional whitespace, at `[`.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    // To do: parse whitespace the way `markdown-rs` does.\n\n    return factoryLabel.call(\n      self,\n      effects,\n      labelAfter,\n      // Note: we don’t need to reset the way `markdown-rs` does.\n      nok,\n      'definitionLabel',\n      'definitionLabelMarker',\n      'definitionLabelString'\n    )(code)\n  }\n\n  /**\n   * After label.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelAfter(code) {\n    identifier = normalizeIdentifier(\n      self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1)\n    )\n    if (code === 58) {\n      effects.enter('definitionMarker')\n      effects.consume(code)\n      effects.exit('definitionMarker')\n      return markerAfter\n    }\n    return nok(code)\n  }\n\n  /**\n   * After marker.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function markerAfter(code) {\n    // Note: whitespace is optional.\n    return markdownLineEndingOrSpace(code)\n      ? factoryWhitespace(effects, destinationBefore)(code)\n      : destinationBefore(code)\n  }\n\n  /**\n   * Before destination.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function destinationBefore(code) {\n    return factoryDestination(\n      effects,\n      destinationAfter,\n      // Note: we don’t need to reset the way `markdown-rs` does.\n      nok,\n      'definitionDestination',\n      'definitionDestinationLiteral',\n      'definitionDestinationLiteralMarker',\n      'definitionDestinationRaw',\n      'definitionDestinationString'\n    )(code)\n  }\n\n  /**\n   * After destination.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function destinationAfter(code) {\n    return effects.attempt(titleBefore, after, after)(code)\n  }\n\n  /**\n   * After definition.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    return markdownSpace(code)\n      ? factorySpace(effects, afterWhitespace, 'whitespace')(code)\n      : afterWhitespace(code)\n  }\n\n  /**\n   * After definition, after optional whitespace.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterWhitespace(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('definition')\n\n      // Note: we don’t care about uniqueness.\n      // It’s likely that that doesn’t happen very frequently.\n      // It is more likely that it wastes precious time.\n      self.parser.defined.push(identifier)\n\n      // To do: `markdown-rs` interrupt.\n      // // You’d be interrupting.\n      // tokenizer.interrupt = true\n      return ok(code)\n    }\n    return nok(code)\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeTitleBefore(effects, ok, nok) {\n  return titleBefore\n\n  /**\n   * After destination, at whitespace.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleBefore(code) {\n    return markdownLineEndingOrSpace(code)\n      ? factoryWhitespace(effects, beforeMarker)(code)\n      : nok(code)\n  }\n\n  /**\n   * At title.\n   *\n   * ```markdown\n   *   | [a]: b\n   * > | \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeMarker(code) {\n    return factoryTitle(\n      effects,\n      titleAfter,\n      nok,\n      'definitionTitle',\n      'definitionTitleMarker',\n      'definitionTitleString'\n    )(code)\n  }\n\n  /**\n   * After title.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleAfter(code) {\n    return markdownSpace(code)\n      ? factorySpace(effects, titleAfterOptionalWhitespace, 'whitespace')(code)\n      : titleAfterOptionalWhitespace(code)\n  }\n\n  /**\n   * After title, after optional whitespace.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleAfterOptionalWhitespace(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {Construct} */\nexport const hardBreakEscape = {\n  name: 'hardBreakEscape',\n  tokenize: tokenizeHardBreakEscape\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeHardBreakEscape(effects, ok, nok) {\n  return start\n\n  /**\n   * Start of a hard break (escape).\n   *\n   * ```markdown\n   * > | a\\\n   *      ^\n   *   | b\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('hardBreakEscape')\n    effects.consume(code)\n    return after\n  }\n\n  /**\n   * After `\\`, at eol.\n   *\n   * ```markdown\n   * > | a\\\n   *       ^\n   *   | b\n   * ```\n   *\n   *  @type {State}\n   */\n  function after(code) {\n    if (markdownLineEnding(code)) {\n      effects.exit('hardBreakEscape')\n      return ok(code)\n    }\n    return nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding, markdownSpace} from 'micromark-util-character'\n/** @type {Construct} */\nexport const codeIndented = {\n  name: 'codeIndented',\n  tokenize: tokenizeCodeIndented\n}\n\n/** @type {Construct} */\nconst furtherStart = {\n  tokenize: tokenizeFurtherStart,\n  partial: true\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCodeIndented(effects, ok, nok) {\n  const self = this\n  return start\n\n  /**\n   * Start of code (indented).\n   *\n   * > **Parsing note**: it is not needed to check if this first line is a\n   * > filled line (that it has a non-whitespace character), because blank lines\n   * > are parsed already, so we never run into that.\n   *\n   * ```markdown\n   * > |     aaa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: manually check if interrupting like `markdown-rs`.\n\n    effects.enter('codeIndented')\n    // To do: use an improved `space_or_tab` function like `markdown-rs`,\n    // so that we can drop the next state.\n    return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)(code)\n  }\n\n  /**\n   * At start, after 1 or 4 spaces.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1]\n    return tail &&\n      tail[1].type === 'linePrefix' &&\n      tail[2].sliceSerialize(tail[1], true).length >= 4\n      ? atBreak(code)\n      : nok(code)\n  }\n\n  /**\n   * At a break.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^  ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (code === null) {\n      return after(code)\n    }\n    if (markdownLineEnding(code)) {\n      return effects.attempt(furtherStart, atBreak, after)(code)\n    }\n    effects.enter('codeFlowValue')\n    return inside(code)\n  }\n\n  /**\n   * In code content.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFlowValue')\n      return atBreak(code)\n    }\n    effects.consume(code)\n    return inside\n  }\n\n  /** @type {State} */\n  function after(code) {\n    effects.exit('codeIndented')\n    // To do: allow interrupting like `markdown-rs`.\n    // Feel free to interrupt.\n    // tokenizer.interrupt = false\n    return ok(code)\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeFurtherStart(effects, ok, nok) {\n  const self = this\n  return furtherStart\n\n  /**\n   * At eol, trying to parse another indent.\n   *\n   * ```markdown\n   * > |     aaa\n   *            ^\n   *   |     bbb\n   * ```\n   *\n   * @type {State}\n   */\n  function furtherStart(code) {\n    // To do: improve `lazy` / `pierce` handling.\n    // If this is a lazy line, it can’t be code.\n    if (self.parser.lazy[self.now().line]) {\n      return nok(code)\n    }\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return furtherStart\n    }\n\n    // To do: the code here in `micromark-js` is a bit different from\n    // `markdown-rs` because there it can attempt spaces.\n    // We can’t yet.\n    //\n    // To do: use an improved `space_or_tab` function like `markdown-rs`,\n    // so that we can drop the next state.\n    return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)(code)\n  }\n\n  /**\n   * At start, after 1 or 4 spaces.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1]\n    return tail &&\n      tail[1].type === 'linePrefix' &&\n      tail[2].sliceSerialize(tail[1], true).length >= 4\n      ? ok(code)\n      : markdownLineEnding(code)\n      ? furtherStart(code)\n      : nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {\n  markdownLineEnding,\n  markdownLineEndingOrSpace,\n  markdownSpace\n} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\n/** @type {Construct} */\nexport const headingAtx = {\n  name: 'headingAtx',\n  tokenize: tokenizeHeadingAtx,\n  resolve: resolveHeadingAtx\n}\n\n/** @type {Resolver} */\nfunction resolveHeadingAtx(events, context) {\n  let contentEnd = events.length - 2\n  let contentStart = 3\n  /** @type {Token} */\n  let content\n  /** @type {Token} */\n  let text\n\n  // Prefix whitespace, part of the opening.\n  if (events[contentStart][1].type === 'whitespace') {\n    contentStart += 2\n  }\n\n  // Suffix whitespace, part of the closing.\n  if (\n    contentEnd - 2 > contentStart &&\n    events[contentEnd][1].type === 'whitespace'\n  ) {\n    contentEnd -= 2\n  }\n  if (\n    events[contentEnd][1].type === 'atxHeadingSequence' &&\n    (contentStart === contentEnd - 1 ||\n      (contentEnd - 4 > contentStart &&\n        events[contentEnd - 2][1].type === 'whitespace'))\n  ) {\n    contentEnd -= contentStart + 1 === contentEnd ? 2 : 4\n  }\n  if (contentEnd > contentStart) {\n    content = {\n      type: 'atxHeadingText',\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end\n    }\n    text = {\n      type: 'chunkText',\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end,\n      contentType: 'text'\n    }\n    splice(events, contentStart, contentEnd - contentStart + 1, [\n      ['enter', content, context],\n      ['enter', text, context],\n      ['exit', text, context],\n      ['exit', content, context]\n    ])\n  }\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeHeadingAtx(effects, ok, nok) {\n  let size = 0\n  return start\n\n  /**\n   * Start of a heading (atx).\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: parse indent like `markdown-rs`.\n    effects.enter('atxHeading')\n    return before(code)\n  }\n\n  /**\n   * After optional whitespace, at `#`.\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    effects.enter('atxHeadingSequence')\n    return sequenceOpen(code)\n  }\n\n  /**\n   * In opening sequence.\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === 35 && size++ < 6) {\n      effects.consume(code)\n      return sequenceOpen\n    }\n\n    // Always at least one `#`.\n    if (code === null || markdownLineEndingOrSpace(code)) {\n      effects.exit('atxHeadingSequence')\n      return atBreak(code)\n    }\n    return nok(code)\n  }\n\n  /**\n   * After something, before something else.\n   *\n   * ```markdown\n   * > | ## aa\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (code === 35) {\n      effects.enter('atxHeadingSequence')\n      return sequenceFurther(code)\n    }\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('atxHeading')\n      // To do: interrupt like `markdown-rs`.\n      // // Feel free to interrupt.\n      // tokenizer.interrupt = false\n      return ok(code)\n    }\n    if (markdownSpace(code)) {\n      return factorySpace(effects, atBreak, 'whitespace')(code)\n    }\n\n    // To do: generate `data` tokens, add the `text` token later.\n    // Needs edit map, see: `markdown.rs`.\n    effects.enter('atxHeadingText')\n    return data(code)\n  }\n\n  /**\n   * In further sequence (after whitespace).\n   *\n   * Could be normal “visible” hashes in the heading or a final sequence.\n   *\n   * ```markdown\n   * > | ## aa ##\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceFurther(code) {\n    if (code === 35) {\n      effects.consume(code)\n      return sequenceFurther\n    }\n    effects.exit('atxHeadingSequence')\n    return atBreak(code)\n  }\n\n  /**\n   * In text.\n   *\n   * ```markdown\n   * > | ## aa\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function data(code) {\n    if (code === null || code === 35 || markdownLineEndingOrSpace(code)) {\n      effects.exit('atxHeadingText')\n      return atBreak(code)\n    }\n    effects.consume(code)\n    return data\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Previous} Previous\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {Construct} */\nexport const codeText = {\n  name: 'codeText',\n  tokenize: tokenizeCodeText,\n  resolve: resolveCodeText,\n  previous\n}\n\n// To do: next major: don’t resolve, like `markdown-rs`.\n/** @type {Resolver} */\nfunction resolveCodeText(events) {\n  let tailExitIndex = events.length - 4\n  let headEnterIndex = 3\n  /** @type {number} */\n  let index\n  /** @type {number | undefined} */\n  let enter\n\n  // If we start and end with an EOL or a space.\n  if (\n    (events[headEnterIndex][1].type === 'lineEnding' ||\n      events[headEnterIndex][1].type === 'space') &&\n    (events[tailExitIndex][1].type === 'lineEnding' ||\n      events[tailExitIndex][1].type === 'space')\n  ) {\n    index = headEnterIndex\n\n    // And we have data.\n    while (++index < tailExitIndex) {\n      if (events[index][1].type === 'codeTextData') {\n        // Then we have padding.\n        events[headEnterIndex][1].type = 'codeTextPadding'\n        events[tailExitIndex][1].type = 'codeTextPadding'\n        headEnterIndex += 2\n        tailExitIndex -= 2\n        break\n      }\n    }\n  }\n\n  // Merge adjacent spaces and data.\n  index = headEnterIndex - 1\n  tailExitIndex++\n  while (++index <= tailExitIndex) {\n    if (enter === undefined) {\n      if (index !== tailExitIndex && events[index][1].type !== 'lineEnding') {\n        enter = index\n      }\n    } else if (\n      index === tailExitIndex ||\n      events[index][1].type === 'lineEnding'\n    ) {\n      events[enter][1].type = 'codeTextData'\n      if (index !== enter + 2) {\n        events[enter][1].end = events[index - 1][1].end\n        events.splice(enter + 2, index - enter - 2)\n        tailExitIndex -= index - enter - 2\n        index = enter + 2\n      }\n      enter = undefined\n    }\n  }\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Previous}\n */\nfunction previous(code) {\n  // If there is a previous code, there will always be a tail.\n  return (\n    code !== 96 ||\n    this.events[this.events.length - 1][1].type === 'characterEscape'\n  )\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCodeText(effects, ok, nok) {\n  const self = this\n  let sizeOpen = 0\n  /** @type {number} */\n  let size\n  /** @type {Token} */\n  let token\n  return start\n\n  /**\n   * Start of code (text).\n   *\n   * ```markdown\n   * > | `a`\n   *     ^\n   * > | \\`a`\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('codeText')\n    effects.enter('codeTextSequence')\n    return sequenceOpen(code)\n  }\n\n  /**\n   * In opening sequence.\n   *\n   * ```markdown\n   * > | `a`\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === 96) {\n      effects.consume(code)\n      sizeOpen++\n      return sequenceOpen\n    }\n    effects.exit('codeTextSequence')\n    return between(code)\n  }\n\n  /**\n   * Between something and something else.\n   *\n   * ```markdown\n   * > | `a`\n   *      ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function between(code) {\n    // EOF.\n    if (code === null) {\n      return nok(code)\n    }\n\n    // To do: next major: don’t do spaces in resolve, but when compiling,\n    // like `markdown-rs`.\n    // Tabs don’t work, and virtual spaces don’t make sense.\n    if (code === 32) {\n      effects.enter('space')\n      effects.consume(code)\n      effects.exit('space')\n      return between\n    }\n\n    // Closing fence? Could also be data.\n    if (code === 96) {\n      token = effects.enter('codeTextSequence')\n      size = 0\n      return sequenceClose(code)\n    }\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return between\n    }\n\n    // Data.\n    effects.enter('codeTextData')\n    return data(code)\n  }\n\n  /**\n   * In data.\n   *\n   * ```markdown\n   * > | `a`\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function data(code) {\n    if (\n      code === null ||\n      code === 32 ||\n      code === 96 ||\n      markdownLineEnding(code)\n    ) {\n      effects.exit('codeTextData')\n      return between(code)\n    }\n    effects.consume(code)\n    return data\n  }\n\n  /**\n   * In closing sequence.\n   *\n   * ```markdown\n   * > | `a`\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceClose(code) {\n    // More.\n    if (code === 96) {\n      effects.consume(code)\n      size++\n      return sequenceClose\n    }\n\n    // Done!\n    if (size === sizeOpen) {\n      effects.exit('codeTextSequence')\n      effects.exit('codeText')\n      return ok(code)\n    }\n\n    // More or less accents: mark as data.\n    token.type = 'codeTextData'\n    return data(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding, markdownSpace} from 'micromark-util-character'\n/** @type {Construct} */\nconst nonLazyContinuation = {\n  tokenize: tokenizeNonLazyContinuation,\n  partial: true\n}\n\n/** @type {Construct} */\nexport const codeFenced = {\n  name: 'codeFenced',\n  tokenize: tokenizeCodeFenced,\n  concrete: true\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCodeFenced(effects, ok, nok) {\n  const self = this\n  /** @type {Construct} */\n  const closeStart = {\n    tokenize: tokenizeCloseStart,\n    partial: true\n  }\n  let initialPrefix = 0\n  let sizeOpen = 0\n  /** @type {NonNullable<Code>} */\n  let marker\n  return start\n\n  /**\n   * Start of code.\n   *\n   * ```markdown\n   * > | ~~~js\n   *     ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: parse whitespace like `markdown-rs`.\n    return beforeSequenceOpen(code)\n  }\n\n  /**\n   * In opening fence, after prefix, at sequence.\n   *\n   * ```markdown\n   * > | ~~~js\n   *     ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeSequenceOpen(code) {\n    const tail = self.events[self.events.length - 1]\n    initialPrefix =\n      tail && tail[1].type === 'linePrefix'\n        ? tail[2].sliceSerialize(tail[1], true).length\n        : 0\n    marker = code\n    effects.enter('codeFenced')\n    effects.enter('codeFencedFence')\n    effects.enter('codeFencedFenceSequence')\n    return sequenceOpen(code)\n  }\n\n  /**\n   * In opening fence sequence.\n   *\n   * ```markdown\n   * > | ~~~js\n   *      ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === marker) {\n      sizeOpen++\n      effects.consume(code)\n      return sequenceOpen\n    }\n    if (sizeOpen < 3) {\n      return nok(code)\n    }\n    effects.exit('codeFencedFenceSequence')\n    return markdownSpace(code)\n      ? factorySpace(effects, infoBefore, 'whitespace')(code)\n      : infoBefore(code)\n  }\n\n  /**\n   * In opening fence, after the sequence (and optional whitespace), before info.\n   *\n   * ```markdown\n   * > | ~~~js\n   *        ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function infoBefore(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFencedFence')\n      return self.interrupt\n        ? ok(code)\n        : effects.check(nonLazyContinuation, atNonLazyBreak, after)(code)\n    }\n    effects.enter('codeFencedFenceInfo')\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return info(code)\n  }\n\n  /**\n   * In info.\n   *\n   * ```markdown\n   * > | ~~~js\n   *        ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function info(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString')\n      effects.exit('codeFencedFenceInfo')\n      return infoBefore(code)\n    }\n    if (markdownSpace(code)) {\n      effects.exit('chunkString')\n      effects.exit('codeFencedFenceInfo')\n      return factorySpace(effects, metaBefore, 'whitespace')(code)\n    }\n    if (code === 96 && code === marker) {\n      return nok(code)\n    }\n    effects.consume(code)\n    return info\n  }\n\n  /**\n   * In opening fence, after info and whitespace, before meta.\n   *\n   * ```markdown\n   * > | ~~~js eval\n   *           ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function metaBefore(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return infoBefore(code)\n    }\n    effects.enter('codeFencedFenceMeta')\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return meta(code)\n  }\n\n  /**\n   * In meta.\n   *\n   * ```markdown\n   * > | ~~~js eval\n   *           ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function meta(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString')\n      effects.exit('codeFencedFenceMeta')\n      return infoBefore(code)\n    }\n    if (code === 96 && code === marker) {\n      return nok(code)\n    }\n    effects.consume(code)\n    return meta\n  }\n\n  /**\n   * At eol/eof in code, before a non-lazy closing fence or content.\n   *\n   * ```markdown\n   * > | ~~~js\n   *          ^\n   * > | alert(1)\n   *             ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function atNonLazyBreak(code) {\n    return effects.attempt(closeStart, after, contentBefore)(code)\n  }\n\n  /**\n   * Before code content, not a closing fence, at eol.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *             ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentBefore(code) {\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return contentStart\n  }\n\n  /**\n   * Before code content, not a closing fence.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentStart(code) {\n    return initialPrefix > 0 && markdownSpace(code)\n      ? factorySpace(\n          effects,\n          beforeContentChunk,\n          'linePrefix',\n          initialPrefix + 1\n        )(code)\n      : beforeContentChunk(code)\n  }\n\n  /**\n   * Before code content, after optional prefix.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeContentChunk(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return effects.check(nonLazyContinuation, atNonLazyBreak, after)(code)\n    }\n    effects.enter('codeFlowValue')\n    return contentChunk(code)\n  }\n\n  /**\n   * In code content.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^^^^^^^^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentChunk(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFlowValue')\n      return beforeContentChunk(code)\n    }\n    effects.consume(code)\n    return contentChunk\n  }\n\n  /**\n   * After code.\n   *\n   * ```markdown\n   *   | ~~~js\n   *   | alert(1)\n   * > | ~~~\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    effects.exit('codeFenced')\n    return ok(code)\n  }\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Tokenizer}\n   */\n  function tokenizeCloseStart(effects, ok, nok) {\n    let size = 0\n    return startBefore\n\n    /**\n     *\n     *\n     * @type {State}\n     */\n    function startBefore(code) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return start\n    }\n\n    /**\n     * Before closing fence, at optional whitespace.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function start(code) {\n      // Always populated by defaults.\n\n      // To do: `enter` here or in next state?\n      effects.enter('codeFencedFence')\n      return markdownSpace(code)\n        ? factorySpace(\n            effects,\n            beforeSequenceClose,\n            'linePrefix',\n            self.parser.constructs.disable.null.includes('codeIndented')\n              ? undefined\n              : 4\n          )(code)\n        : beforeSequenceClose(code)\n    }\n\n    /**\n     * In closing fence, after optional whitespace, at sequence.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function beforeSequenceClose(code) {\n      if (code === marker) {\n        effects.enter('codeFencedFenceSequence')\n        return sequenceClose(code)\n      }\n      return nok(code)\n    }\n\n    /**\n     * In closing fence sequence.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function sequenceClose(code) {\n      if (code === marker) {\n        size++\n        effects.consume(code)\n        return sequenceClose\n      }\n      if (size >= sizeOpen) {\n        effects.exit('codeFencedFenceSequence')\n        return markdownSpace(code)\n          ? factorySpace(effects, sequenceCloseAfter, 'whitespace')(code)\n          : sequenceCloseAfter(code)\n      }\n      return nok(code)\n    }\n\n    /**\n     * After closing fence sequence, after optional whitespace.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *        ^\n     * ```\n     *\n     * @type {State}\n     */\n    function sequenceCloseAfter(code) {\n      if (code === null || markdownLineEnding(code)) {\n        effects.exit('codeFencedFence')\n        return ok(code)\n      }\n      return nok(code)\n    }\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeNonLazyContinuation(effects, ok, nok) {\n  const self = this\n  return start\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (code === null) {\n      return nok(code)\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return lineStart\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function lineStart(code) {\n    return self.parser.lazy[self.now().line] ? nok(code) : ok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {subtokenize} from 'micromark-util-subtokenize'\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n}\n\n/** @type {Construct} */\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n}\n\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token | undefined} */\n  let previous\n  return chunkStart\n\n  /**\n   * Before a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkStart(code) {\n    effects.enter('content')\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    })\n    return chunkInside(code)\n  }\n\n  /**\n   * In a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkInside(code) {\n    if (code === null) {\n      return contentEnd(code)\n    }\n\n    // To do: in `markdown-rs`, each line is parsed on its own, and everything\n    // is stitched together resolving.\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    }\n\n    // Data.\n    effects.consume(code)\n    return chunkInside\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentEnd(code) {\n    effects.exit('chunkContent')\n    effects.exit('content')\n    return ok(code)\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentContinue(code) {\n    effects.consume(code)\n    effects.exit('chunkContent')\n    previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous\n    })\n    previous = previous.next\n    return chunkInside\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this\n  return startLookahead\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function startLookahead(code) {\n    effects.exit('chunkContent')\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, prefixed, 'linePrefix')\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    // Always populated by defaults.\n\n    const tail = self.events[self.events.length - 1]\n    if (\n      !self.parser.constructs.disable.null.includes('codeIndented') &&\n      tail &&\n      tail[1].type === 'linePrefix' &&\n      tail[2].sliceSerialize(tail[1], true).length >= 4\n    ) {\n      return ok(code)\n    }\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n  }\n}\n"],"names":["definition","name","tokenize","effects","ok","nok","self","this","identifier","code","enter","factoryLabel","call","labelAfter","before","normalizeIdentifier","sliceSerialize","events","length","slice","consume","exit","markerAfter","markdownLineEndingOrSpace","factoryWhitespace","destinationBefore","factoryDestination","destinationAfter","attempt","titleBefore","after","markdownSpace","factorySpace","afterWhitespace","markdownLineEnding","parser","defined","push","beforeMarker","factoryTitle","titleAfter","titleAfterOptionalWhitespace","partial","hardBreakEscape","codeIndented","afterPrefix","tail","type","atBreak","furtherStart","inside","lazy","now","line","headingAtx","size","sequenceOpen","sequenceFurther","data","resolve","context","content","text","contentEnd","contentStart","start","end","contentType","splice","codeText","token","sizeOpen","between","sequenceClose","index","tailExitIndex","headEnterIndex","undefined","previous","nonLazyContinuation","lineStart","codeFenced","closeStart","startBefore","beforeSequenceClose","constructs","disable","null","includes","marker","sequenceCloseAfter","initialPrefix","beforeSequenceOpen","infoBefore","interrupt","check","atNonLazyBreak","info","metaBefore","meta","contentBefore","beforeContentChunk","contentChunk","concrete","chunkInside","continuationConstruct","contentContinue","next","subtokenize","prefixed","flow"],"sourceRoot":""}