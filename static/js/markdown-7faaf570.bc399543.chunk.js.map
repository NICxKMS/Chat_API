{"version":3,"file":"static/js/markdown-7faaf570.bc399543.chunk.js","mappings":";oHASa,IAA4bA,EAAxbC,EAAEC,OAAOC,IAAI,iBAAiBC,EAAEF,OAAOC,IAAI,gBAAgBE,EAAEH,OAAOC,IAAI,kBAAkBG,EAAEJ,OAAOC,IAAI,qBAAqBI,EAAEL,OAAOC,IAAI,kBAAkBK,EAAEN,OAAOC,IAAI,kBAAkBM,EAAEP,OAAOC,IAAI,iBAAiBO,EAAER,OAAOC,IAAI,wBAAwBQ,EAAET,OAAOC,IAAI,qBAAqBS,EAAEV,OAAOC,IAAI,kBAAkBU,EAAEX,OAAOC,IAAI,uBAAuBW,EAAEZ,OAAOC,IAAI,cAAcY,EAAEb,OAAOC,IAAI,cAAca,EAAEd,OAAOC,IAAI,mBACtb,SAASc,EAAEC,GAAG,GAAG,iBAAkBA,GAAG,OAAOA,EAAE,CAAC,IAAIC,EAAED,EAAEE,SAAS,OAAOD,GAAG,KAAKlB,EAAE,OAAOiB,EAAEA,EAAEG,MAAQ,KAAKhB,EAAE,KAAKE,EAAE,KAAKD,EAAE,KAAKM,EAAE,KAAKC,EAAE,OAAOK,EAAE,QAAQ,OAAOA,EAAEA,GAAGA,EAAEE,UAAY,KAAKV,EAAE,KAAKD,EAAE,KAAKE,EAAE,KAAKI,EAAE,KAAKD,EAAE,KAAKN,EAAE,OAAOU,EAAE,QAAQ,OAAOC,GAAG,KAAKf,EAAE,OAAOe,EAAE,CAAC,CADkMnB,EAAEE,OAAOC,IAAI,0BAC9MmB,EAAQC,gBAAgBd,EAAEa,EAAQE,gBAAgBhB,EAAEc,EAAQG,QAAQxB,EAAEqB,EAAQI,WAAWf,EAAEW,EAAQK,SAAStB,EAAEiB,EAAQM,KAAKb,EAAEO,EAAQO,KAAKf,EAAEQ,EAAQQ,OAAO1B,EAAEkB,EAAQS,SAASxB,EAAEe,EAAQU,WAAW1B,EAAEgB,EAAQW,SAASrB,EACheU,EAAQY,aAAarB,EAAES,EAAQa,YAAY,WAAW,OAAM,CAAE,EAAEb,EAAQc,iBAAiB,WAAW,OAAM,CAAE,EAAEd,EAAQe,kBAAkB,SAASnB,GAAG,OAAOD,EAAEC,KAAKT,CAAC,EAAEa,EAAQgB,kBAAkB,SAASpB,GAAG,OAAOD,EAAEC,KAAKV,CAAC,EAAEc,EAAQiB,UAAU,SAASrB,GAAG,MAAM,iBAAkBA,GAAG,OAAOA,GAAGA,EAAEE,WAAWnB,CAAC,EAAEqB,EAAQkB,aAAa,SAAStB,GAAG,OAAOD,EAAEC,KAAKP,CAAC,EAAEW,EAAQmB,WAAW,SAASvB,GAAG,OAAOD,EAAEC,KAAKb,CAAC,EAAEiB,EAAQoB,OAAO,SAASxB,GAAG,OAAOD,EAAEC,KAAKH,CAAC,EAAEO,EAAQqB,OAAO,SAASzB,GAAG,OAAOD,EAAEC,KAAKJ,CAAC,EACveQ,EAAQsB,SAAS,SAAS1B,GAAG,OAAOD,EAAEC,KAAKd,CAAC,EAAEkB,EAAQuB,WAAW,SAAS3B,GAAG,OAAOD,EAAEC,KAAKX,CAAC,EAAEe,EAAQwB,aAAa,SAAS5B,GAAG,OAAOD,EAAEC,KAAKZ,CAAC,EAAEgB,EAAQyB,WAAW,SAAS7B,GAAG,OAAOD,EAAEC,KAAKN,CAAC,EAAEU,EAAQ0B,eAAe,SAAS9B,GAAG,OAAOD,EAAEC,KAAKL,CAAC,EAClPS,EAAQ2B,mBAAmB,SAAS/B,GAAG,MAAM,iBAAkBA,GAAG,mBAAoBA,GAAGA,IAAIb,GAAGa,IAAIX,GAAGW,IAAIZ,GAAGY,IAAIN,GAAGM,IAAIL,GAAGK,IAAIF,GAAG,iBAAkBE,GAAG,OAAOA,IAAIA,EAAEE,WAAWL,GAAGG,EAAEE,WAAWN,GAAGI,EAAEE,WAAWZ,GAAGU,EAAEE,WAAWX,GAAGS,EAAEE,WAAWT,GAAGO,EAAEE,WAAWpB,QAAG,IAASkB,EAAEgC,YAAkB,EAAE5B,EAAQ6B,OAAOlC,oCCEjT,MAAMmC,EAAS,cAKR,SAASC,IACd,IAKIC,EALAC,EAAS,EACTC,EAAS,GAETC,GAAQ,EAGZ,OAGA,SAAsBC,EAAOC,EAAUC,GAErC,MAAMC,EAAS,GAEf,IAAIC,EAEAC,EAEAC,EAEAC,EAEAC,EAGJR,EAAQF,EAASE,EAAMS,SAASR,GAChCK,EAAgB,EAChBR,EAAS,GACLC,IAE0B,QAAxBC,EAAMU,WAAW,IACnBJ,IAEFP,OAAQY,GAEV,KAAOL,EAAgBN,EAAMY,QAAQ,CAMnC,GALAlB,EAAOmB,UAAYP,EACnBF,EAAQV,EAAOoB,KAAKd,GACpBO,EACEH,QAAyBO,IAAhBP,EAAMW,MAAsBX,EAAMW,MAAQf,EAAMY,OAC3DJ,EAAOR,EAAMU,WAAWH,IACnBH,EAAO,CACVN,EAASE,EAAMgB,MAAMV,GACrB,KACF,CACA,GAAa,KAATE,GAAeF,IAAkBC,GAAeX,EAClDO,EAAOc,MAAM,GACbrB,OAAmBe,OAUnB,OARIf,IACFO,EAAOc,MAAM,GACbrB,OAAmBe,GAEjBL,EAAgBC,IAClBJ,EAAOc,KAAKjB,EAAMgB,MAAMV,EAAeC,IACvCV,GAAUU,EAAcD,GAElBE,GACN,KAAK,EACHL,EAAOc,KAAK,OACZpB,IACA,MAEF,KAAK,EAGH,IAFAQ,EAA+B,EAAxBa,KAAKC,KAAKtB,EAAS,GAC1BM,EAAOc,MAAM,GACNpB,IAAWQ,GAAMF,EAAOc,MAAM,GACrC,MAEF,KAAK,GACHd,EAAOc,MAAM,GACbpB,EAAS,EACT,MAEF,QACED,GAAmB,EACnBC,EAAS,EAIfS,EAAgBC,EAAc,CAChC,CACIL,IACEN,GAAkBO,EAAOc,MAAM,GAC/BnB,GAAQK,EAAOc,KAAKnB,GACxBK,EAAOc,KAAK,OAEd,OAAOd,CACT,CACF,mBC1GEiB,EAAOxD,QAAU,EAAjBwD,uDCOK,SAASC,EAAYC,GAC1B,OAAQC,EAAAA,EAAAA,GAAYD,KAGpB,OAAOA,CACT,iPCJO,MAAME,EAAU,CACrBC,SAOF,SAA2BC,GACzB,MAAMC,EAAeD,EAAQE,QAC3BC,KAAKC,OAAOC,WAAWC,gBASzB,SAAoCxB,GAClC,GAAa,OAATA,EAEF,YADAkB,EAAQO,QAAQzB,GAMlB,OAHAkB,EAAQQ,MAAM,cACdR,EAAQO,QAAQzB,GAChBkB,EAAQS,KAAK,eACNC,EAAAA,EAAAA,GAAaV,EAASC,EAAc,aAC7C,IAGA,SAA0BnB,GAExB,OADAkB,EAAQQ,MAAM,aACPG,EAAU7B,EACnB,IAnBA,IAAI8B,EACJ,OAAOX,EAqBP,SAASU,EAAU7B,GACjB,MAAM+B,EAAQb,EAAQQ,MAAM,YAAa,CACvCM,YAAa,OACbF,aAMF,OAJIA,IACFA,EAASjC,KAAOkC,GAElBD,EAAWC,EACJE,EAAKjC,EACd,CAGA,SAASiC,EAAKjC,GACZ,OAAa,OAATA,GACFkB,EAAQS,KAAK,aACbT,EAAQS,KAAK,kBACbT,EAAQO,QAAQzB,KAGdkC,EAAAA,EAAAA,IAAmBlC,IACrBkB,EAAQO,QAAQzB,GAChBkB,EAAQS,KAAK,aACNE,IAITX,EAAQO,QAAQzB,GACTiC,EACT,CACF,iBC1DO,MAAME,EAAW,CACtBlB,SAYF,SAA4BC,GAC1B,MAAMkB,EAAOf,KAEPgB,EAAQ,GACd,IAEIC,EAEAC,EAEAC,EANAC,EAAY,EAOhB,OAAOlD,EAGP,SAASA,EAAMS,GAWb,GAAIyC,EAAYJ,EAAMjC,OAAQ,CAC5B,MAAMsC,EAAOL,EAAMI,GAEnB,OADAL,EAAKO,eAAiBD,EAAK,GACpBxB,EAAQE,QACbsB,EAAK,GAAGE,aACRC,EACAC,EAHK5B,CAILlB,EACJ,CAGA,OAAO8C,EAAmB9C,EAC5B,CAGA,SAAS6C,EAAiB7C,GAMxB,GALAyC,IAKIL,EAAKO,eAAeI,WAAY,CAClCX,EAAKO,eAAeI,gBAAa5C,EAC7BmC,GACFU,IAKF,MAAMC,EAAmBb,EAAKtB,OAAOV,OACrC,IAEI8C,EAFAC,EAAkBF,EAKtB,KAAOE,KACL,GACsC,SAApCf,EAAKtB,OAAOqC,GAAiB,IACY,cAAzCf,EAAKtB,OAAOqC,GAAiB,GAAGhG,KAChC,CACA+F,EAAQd,EAAKtB,OAAOqC,GAAiB,GAAGzD,IACxC,KACF,CAEF0D,EAAeX,GAGf,IAAIlC,EAAQ0C,EACZ,KAAO1C,EAAQ6B,EAAKtB,OAAOV,QACzBgC,EAAKtB,OAAOP,GAAO,GAAGb,IAAM2D,OAAOC,OAAO,CAAC,EAAGJ,GAC9C3C,IAaF,OATAgD,EAAAA,EAAAA,GACEnB,EAAKtB,OACLqC,EAAkB,EAClB,EACAf,EAAKtB,OAAON,MAAMyC,IAIpBb,EAAKtB,OAAOV,OAASG,EACduC,EAAmB9C,EAC5B,CACA,OAAOT,EAAMS,EACf,CAGA,SAAS8C,EAAmB9C,GAM1B,GAAIyC,IAAcJ,EAAMjC,OAAQ,CAI9B,IAAKkC,EACH,OAAOkB,EAAkBxD,GAM3B,GAAIsC,EAAUmB,kBAAoBnB,EAAUmB,iBAAiBC,SAC3D,OAAOC,EAAU3D,GAQnBoC,EAAKwB,UAAYC,QACfvB,EAAUmB,mBAAqBnB,EAAUwB,8BAE7C,CAIA,OADA1B,EAAKO,eAAiB,CAAC,EAChBzB,EAAQ6C,MACbC,EACAC,EACAC,EAHKhD,CAILlB,EACJ,CAGA,SAASiE,EAAqBjE,GAG5B,OAFIsC,GAAWU,IACfI,EAAeX,GACRe,EAAkBxD,EAC3B,CAGA,SAASkE,EAAsBlE,GAG7B,OAFAoC,EAAKd,OAAO6C,KAAK/B,EAAKgC,MAAMC,MAAQ5B,IAAcJ,EAAMjC,OACxDoC,EAAkBJ,EAAKgC,MAAME,OACtBX,EAAU3D,EACnB,CAGA,SAASwD,EAAkBxD,GAGzB,OADAoC,EAAKO,eAAiB,CAAC,EAChBzB,EAAQE,QACb4C,EACAO,EACAZ,EAHKzC,CAILlB,EACJ,CAGA,SAASuE,EAAkBvE,GAIzB,OAHAyC,IACAJ,EAAM5B,KAAK,CAAC2B,EAAKqB,iBAAkBrB,EAAKO,iBAEjCa,EAAkBxD,EAC3B,CAGA,SAAS2D,EAAU3D,GACjB,OAAa,OAATA,GACEsC,GAAWU,IACfI,EAAe,QACflC,EAAQO,QAAQzB,KAGlBsC,EAAYA,GAAaF,EAAKd,OAAOkD,KAAKpC,EAAKgC,OAC/ClD,EAAQQ,MAAM,YAAa,CACzBM,YAAa,OACbF,SAAUS,EACVkC,WAAYnC,IAEPoC,EAAa1E,GACtB,CAGA,SAAS0E,EAAa1E,GACpB,OAAa,OAATA,GACF2E,EAAazD,EAAQS,KAAK,cAAc,GACxCyB,EAAe,QACflC,EAAQO,QAAQzB,KAGdkC,EAAAA,EAAAA,IAAmBlC,IACrBkB,EAAQO,QAAQzB,GAChB2E,EAAazD,EAAQS,KAAK,cAE1Bc,EAAY,EACZL,EAAKwB,eAAYzD,EACVZ,IAET2B,EAAQO,QAAQzB,GACT0E,EACT,CAOA,SAASC,EAAa5C,EAAO6C,GAC3B,MAAMC,EAASzC,EAAK0C,YAAY/C,GAyChC,GAxCI6C,GAAKC,EAAOpE,KAAK,MACrBsB,EAAMD,SAAWS,EACbA,IAAYA,EAAW1C,KAAOkC,GAClCQ,EAAaR,EACbO,EAAUyC,WAAWhD,EAAMxC,OAC3B+C,EAAU0C,MAAMH,GAmCZzC,EAAKd,OAAO6C,KAAKpC,EAAMxC,MAAM8E,MAAO,CACtC,IAAI9D,EAAQ+B,EAAUxB,OAAOV,OAC7B,KAAOG,KACL,GAEE+B,EAAUxB,OAAOP,GAAO,GAAGhB,MAAM+E,OAAS9B,KAExCF,EAAUxB,OAAOP,GAAO,GAAGb,KAE3B4C,EAAUxB,OAAOP,GAAO,GAAGb,IAAI4E,OAAS9B,GAI1C,OAMJ,MAAMS,EAAmBb,EAAKtB,OAAOV,OACrC,IAEI6E,EAEA/B,EAJAC,EAAkBF,EAOtB,KAAOE,KACL,GACsC,SAApCf,EAAKtB,OAAOqC,GAAiB,IACY,cAAzCf,EAAKtB,OAAOqC,GAAiB,GAAGhG,KAChC,CACA,GAAI8H,EAAM,CACR/B,EAAQd,EAAKtB,OAAOqC,GAAiB,GAAGzD,IACxC,KACF,CACAuF,GAAO,CACT,CAMF,IAJA7B,EAAeX,GAGflC,EAAQ0C,EACD1C,EAAQ6B,EAAKtB,OAAOV,QACzBgC,EAAKtB,OAAOP,GAAO,GAAGb,IAAM2D,OAAOC,OAAO,CAAC,EAAGJ,GAC9C3C,KAIFgD,EAAAA,EAAAA,GACEnB,EAAKtB,OACLqC,EAAkB,EAClB,EACAf,EAAKtB,OAAON,MAAMyC,IAIpBb,EAAKtB,OAAOV,OAASG,CACvB,CACF,CAMA,SAAS6C,EAAe8B,GACtB,IAAI3E,EAAQ8B,EAAMjC,OAGlB,KAAOG,KAAU2E,GAAM,CACrB,MAAMC,EAAQ9C,EAAM9B,GACpB6B,EAAKO,eAAiBwC,EAAM,GAC5BA,EAAM,GAAGxD,KAAKyD,KAAKhD,EAAMlB,EAC3B,CACAmB,EAAMjC,OAAS8E,CACjB,CACA,SAASlC,IACPV,EAAU0C,MAAM,CAAC,OACjBzC,OAAapC,EACbmC,OAAYnC,EACZiC,EAAKO,eAAeI,gBAAa5C,CACnC,CACF,GArVM6D,EAAqB,CACzB/C,SA0VF,SAA2BC,EAASmE,EAAIC,GAGtC,OAAO1D,EAAAA,EAAAA,GACLV,EACAA,EAAQE,QAAQC,KAAKC,OAAOC,WAAWY,SAAUkD,EAAIC,GACrD,aACAjE,KAAKC,OAAOC,WAAWgE,QAAQC,KAAKC,SAAS,qBAAkBtF,EAAY,EAE/E,6BClXO,MAAMqE,EAAO,CAClBvD,SAOF,SAAwBC,GACtB,MAAMkB,EAAOf,KACPqE,EAAUxE,EAAQE,QAEtBuE,EAAAA,GAoBF,SAAuB3F,GACrB,GAAa,OAATA,EAEF,YADAkB,EAAQO,QAAQzB,GAOlB,OAJAkB,EAAQQ,MAAM,mBACdR,EAAQO,QAAQzB,GAChBkB,EAAQS,KAAK,mBACbS,EAAKqB,sBAAmBtD,EACjBuF,CACT,GA3BExE,EAAQE,QACNC,KAAKC,OAAOC,WAAWqE,YACvBC,GACAjE,EAAAA,EAAAA,GACEV,EACAA,EAAQE,QACNC,KAAKC,OAAOC,WAAWiD,KACvBqB,EACA3E,EAAQE,QAAQJ,EAAAA,EAAS6E,IAE3B,gBAIN,OAAOH,EAgBP,SAASG,EAAe7F,GACtB,GAAa,OAATA,EAQJ,OAJAkB,EAAQQ,MAAM,cACdR,EAAQO,QAAQzB,GAChBkB,EAAQS,KAAK,cACbS,EAAKqB,sBAAmBtD,EACjBuF,EAPLxE,EAAQO,QAAQzB,EAQpB,CACF,GC1DO,MAAM8F,EAAW,CACtBC,WAAYC,KAEDC,EAASC,EAAkB,UAC3BC,EAAOD,EAAkB,QAMtC,SAASA,EAAkBE,GACzB,MAAO,CACLnF,SAUF,SAAwBC,GACtB,MAAMkB,EAAOf,KACPE,EAAaF,KAAKC,OAAOC,WAAW6E,GACpCD,EAAOjF,EAAQE,QAAQG,EAAYhC,EAAO8G,GAChD,OAAO9G,EAGP,SAASA,EAAMS,GACb,OAAOsG,EAAQtG,GAAQmG,EAAKnG,GAAQqG,EAAQrG,EAC9C,CAGA,SAASqG,EAAQrG,GACf,GAAa,OAATA,EAMJ,OAFAkB,EAAQQ,MAAM,QACdR,EAAQO,QAAQzB,GACTiC,EALLf,EAAQO,QAAQzB,EAMpB,CAGA,SAASiC,EAAKjC,GACZ,OAAIsG,EAAQtG,IACVkB,EAAQS,KAAK,QACNwE,EAAKnG,KAIdkB,EAAQO,QAAQzB,GACTiC,EACT,CAMA,SAASqE,EAAQtG,GACf,GAAa,OAATA,EACF,OAAO,EAET,MAAMuG,EAAOhF,EAAWvB,GACxB,IAAIO,GAAS,EACb,GAAIgG,EAGF,OAAShG,EAAQgG,EAAKnG,QAAQ,CAC5B,MAAMsC,EAAO6D,EAAKhG,GAClB,IAAKmC,EAAKZ,UAAYY,EAAKZ,SAASsD,KAAKhD,EAAMA,EAAKN,UAClD,OAAO,CAEX,CAEF,OAAO,CACT,CACF,EAjEEiE,WAAYC,EACA,SAAVI,EAAmBI,OAAyBrG,GAiElD,CAMA,SAAS6F,EAAeS,GACtB,OAGA,SAAwB3F,EAAQ4F,GAC9B,IAEIhF,EAFAnB,GAAS,EAMb,OAASA,GAASO,EAAOV,aACTD,IAAVuB,EACEZ,EAAOP,IAAoC,SAA1BO,EAAOP,GAAO,GAAGpD,OACpCuE,EAAQnB,EACRA,KAEQO,EAAOP,IAAoC,SAA1BO,EAAOP,GAAO,GAAGpD,OAExCoD,IAAUmB,EAAQ,IACpBZ,EAAOY,GAAO,GAAGhC,IAAMoB,EAAOP,EAAQ,GAAG,GAAGb,IAC5CoB,EAAOyC,OAAO7B,EAAQ,EAAGnB,EAAQmB,EAAQ,GACzCnB,EAAQmB,EAAQ,GAElBA,OAAQvB,GAGZ,OAAOsG,EAAgBA,EAAc3F,EAAQ4F,GAAW5F,CAC1D,CACF,CAaA,SAAS0F,EAAuB1F,EAAQ4F,GACtC,IAAIC,EAAa,EAEjB,OAASA,GAAc7F,EAAOV,QAC5B,IACGuG,IAAe7F,EAAOV,QACU,eAA/BU,EAAO6F,GAAY,GAAGxJ,OACW,SAAnC2D,EAAO6F,EAAa,GAAG,GAAGxJ,KAC1B,CACA,MAAM8E,EAAOnB,EAAO6F,EAAa,GAAG,GAC9BhH,EAAS+G,EAAQ5B,YAAY7C,GACnC,IAII2E,EAJArG,EAAQZ,EAAOS,OACfyG,GAAe,EACf3B,EAAO,EAGX,KAAO3E,KAAS,CACd,MAAMuG,EAAQnH,EAAOY,GACrB,GAAqB,iBAAVuG,EAAoB,CAE7B,IADAD,EAAcC,EAAM1G,OACyB,KAAtC0G,EAAM5G,WAAW2G,EAAc,IACpC3B,IACA2B,IAEF,GAAIA,EAAa,MACjBA,GAAe,CACjB,MAEK,IAAe,IAAXC,EACPF,GAAO,EACP1B,SACK,IAAe,IAAX4B,EAEJ,CAELvG,IACA,KACF,CACF,CACA,GAAI2E,EAAM,CACR,MAAMnD,EAAQ,CACZ5E,KACEwJ,IAAe7F,EAAOV,QAAUwG,GAAQ1B,EAAO,EAC3C,aACA,oBACN3F,MAAO,CACL8E,KAAMpC,EAAKvC,IAAI2E,KACfhF,OAAQ4C,EAAKvC,IAAIL,OAAS6F,EAC1BZ,OAAQrC,EAAKvC,IAAI4E,OAASY,EAC1B6B,OAAQ9E,EAAK1C,MAAMwH,OAASxG,EAC5ByG,aAAczG,EACVsG,EACA5E,EAAK1C,MAAMyH,aAAeH,GAEhCnH,IAAK2D,OAAOC,OAAO,CAAC,EAAGrB,EAAKvC,MAE9BuC,EAAKvC,IAAM2D,OAAOC,OAAO,CAAC,EAAGvB,EAAMxC,OAC/B0C,EAAK1C,MAAM+E,SAAWrC,EAAKvC,IAAI4E,OACjCjB,OAAOC,OAAOrB,EAAMF,IAEpBjB,EAAOyC,OACLoD,EACA,EACA,CAAC,QAAS5E,EAAO2E,GACjB,CAAC,OAAQ3E,EAAO2E,IAElBC,GAAc,EAElB,CACAA,GACF,CAEF,OAAO7F,CACT,gBClKO,SAASmG,EAAgB3F,EAAQ4F,EAAYC,GAElD,IAAIjE,EAAQG,OAAOC,OACjB6D,EACI9D,OAAOC,OAAO,CAAC,EAAG6D,GAClB,CACE9C,KAAM,EACNhF,OAAQ,EACRiF,OAAQ,GAEd,CACEyC,OAAQ,EACRC,cAAe,IAInB,MAAMI,EAAc,CAAC,EAEfC,EAAuB,GAE7B,IAAI1H,EAAS,GAET0C,EAAQ,GAERiF,GAAW,EAOf,MAAMpG,EAAU,CACdO,QAkJF,SAAiBzB,IACXkC,EAAAA,EAAAA,IAAmBlC,IACrBkD,EAAMmB,OACNnB,EAAM7D,OAAS,EACf6D,EAAMoB,SAAoB,IAAVtE,EAAc,EAAI,EAClCuH,MACmB,IAAVvH,IACTkD,EAAM7D,SACN6D,EAAMoB,UAIJpB,EAAM8D,aAAe,EACvB9D,EAAM6D,UAEN7D,EAAM8D,eAKF9D,EAAM8D,eAAiBrH,EAAOuD,EAAM6D,QAAQ3G,SAC9C8C,EAAM8D,cAAgB,EACtB9D,EAAM6D,WAKVL,EAAQ5E,SAAW9B,EAGnBsH,GAAW,CACb,EAhLE5F,MAmLF,SAAevE,EAAMqK,GAGnB,MAAMzF,EAAQyF,GAAU,CAAC,EAKzB,OAJAzF,EAAM5E,KAAOA,EACb4E,EAAMxC,MAAQ6E,IACdsC,EAAQ5F,OAAOL,KAAK,CAAC,QAASsB,EAAO2E,IACrCrE,EAAM5B,KAAKsB,GACJA,CACT,EA3LEJ,KA8LF,SAAcxE,GACZ,MAAM4E,EAAQM,EAAMoF,MAGpB,OAFA1F,EAAMrC,IAAM0E,IACZsC,EAAQ5F,OAAOL,KAAK,CAAC,OAAQsB,EAAO2E,IAC7B3E,CACT,EAlMEX,QAASsG,GAyMX,SAA+BC,EAAWC,GACxCC,EAAUF,EAAWC,EAAKT,KAC5B,IA1MEpD,MAAO2D,EAAiBI,GACxBlE,UAAW8D,EAAiBI,EAAmB,CAC7ClE,WAAW,KAST8C,EAAU,CACd5E,SAAU,KACV9B,KAAM,KACN2C,eAAgB,CAAC,EACjB7B,OAAQ,GACRQ,SACAwD,cACAiD,eA6CF,SAAwBhG,EAAOiG,GAC7B,OAsYJ,SAAyBrI,EAAQqI,GAC/B,IAAIzH,GAAS,EAEb,MAAM0H,EAAS,GAEf,IAAIC,EACJ,OAAS3H,EAAQZ,EAAOS,QAAQ,CAC9B,MAAM0G,EAAQnH,EAAOY,GAErB,IAAIf,EACJ,GAAqB,iBAAVsH,EACTtH,EAAQsH,OAER,OAAQA,GACN,KAAM,EACJtH,EAAQ,KACR,MAEF,KAAM,EACJA,EAAQ,KACR,MAEF,KAAM,EACJA,EAAQ,OACR,MAEF,KAAM,EACJA,EAAQwI,EAAa,IAAM,KAC3B,MAEF,KAAM,EACJ,IAAKA,GAAcE,EAAO,SAC1B1I,EAAQ,IACR,MAEF,QAEEA,EAAQ2I,OAAOC,aAAatB,GAGlCoB,GAAmB,IAAXpB,EACRmB,EAAOxH,KAAKjB,EACd,CACA,OAAOyI,EAAOI,KAAK,GACrB,CAlbWC,CAAgBxD,EAAY/C,GAAQiG,EAC7C,EA9CE5D,MACAW,WAkEF,SAAoBvF,GAClB4H,EAAY5H,EAAM6E,MAAQ7E,EAAMH,OAChCkI,GACF,EApEEvC,MAsBF,SAAexE,GAKb,GAJAb,GAASc,EAAAA,EAAAA,GAAKd,EAAQa,GACtB+H,IAGkC,OAA9B5I,EAAOA,EAAOS,OAAS,GACzB,MAAO,GAMT,OAJAyH,EAAUX,EAAY,GAGtBR,EAAQ5F,QAASiF,EAAAA,EAAAA,GAAWsB,EAAsBX,EAAQ5F,OAAQ4F,GAC3DA,EAAQ5F,MACjB,GA3BA,IAOI0H,EAPAC,EAAQvB,EAAWjG,SAASmE,KAAKsB,EAASxF,GAW9C,OAHIgG,EAAWnB,YACbsB,EAAqB5G,KAAKyG,GAErBR,EA4BP,SAAS5B,EAAY/C,GACnB,OA8VJ,SAAqBpC,EAAQoC,GAC3B,MAAM2G,EAAa3G,EAAMxC,MAAMwH,OACzB4B,EAAmB5G,EAAMxC,MAAMyH,aAC/B4B,EAAW7G,EAAMrC,IAAIqH,OACrB8B,EAAiB9G,EAAMrC,IAAIsH,aAEjC,IAAI8B,EACJ,GAAIJ,IAAeE,EAEjBE,EAAO,CAACnJ,EAAO+I,GAAYlI,MAAMmI,EAAkBE,QAC9C,CAEL,GADAC,EAAOnJ,EAAOa,MAAMkI,EAAYE,GAC5BD,GAAoB,EAAG,CACzB,MAAMI,EAAOD,EAAK,GACE,iBAATC,EACTD,EAAK,GAAKC,EAAKvI,MAAMmI,GAErBG,EAAKE,OAET,CACIH,EAAiB,GAEnBC,EAAKrI,KAAKd,EAAOiJ,GAAUpI,MAAM,EAAGqI,GAExC,CACA,OAAOC,CACT,CAxXWG,CAAYtJ,EAAQoC,EAC7B,CAGA,SAASqC,IAEP,MAAM,KAACC,EAAI,OAAEhF,EAAM,OAAEiF,EAAM,OAAEyC,EAAM,aAAEC,GAAgB9D,EACrD,MAAO,CACLmB,OACAhF,SACAiF,SACAyC,SACAC,eAEJ,CAsBA,SAASuB,IAEP,IAAIW,EACJ,KAAOhG,EAAM6D,OAASpH,EAAOS,QAAQ,CACnC,MAAM0G,EAAQnH,EAAOuD,EAAM6D,QAG3B,GAAqB,iBAAVD,EAKT,IAJAoC,EAAahG,EAAM6D,OACf7D,EAAM8D,aAAe,IACvB9D,EAAM8D,aAAe,GAGrB9D,EAAM6D,SAAWmC,GACjBhG,EAAM8D,aAAeF,EAAM1G,QAE3B+I,EAAGrC,EAAM5G,WAAWgD,EAAM8D,oBAG5BmC,EAAGrC,EAEP,CACF,CAQA,SAASqC,EAAGnJ,GACVsH,OAAWnH,EACXqI,EAAexI,EACfyI,EAAQA,EAAMzI,EAChB,CAsEA,SAAS8H,EAAkBsB,EAAGxB,GAC5BA,EAAKyB,SACP,CAQA,SAAS3B,EAAiB4B,EAAU9B,GAClC,OAWA,SAAcjG,EAAYgI,EAAaC,GAErC,IAAIC,EAEAC,EAEAjG,EAEAmE,EACJ,OAAO+B,MAAMC,QAAQrI,GACjBsI,EAAuBtI,GACvB,aAAcA,EAEdsI,EAAuB,CAACtI,IAS5B,SAA+BuI,GAC7B,OAAOvK,EAGP,SAASA,EAAMS,GACb,MAAM+J,EAAe,OAAT/J,GAAiB8J,EAAI9J,GAC3BgK,EAAe,OAAThK,GAAiB8J,EAAItE,KAOjC,OAAOqE,EANM,IAGPF,MAAMC,QAAQG,GAAOA,EAAMA,EAAM,CAACA,GAAO,MACzCJ,MAAMC,QAAQI,GAAOA,EAAMA,EAAM,CAACA,GAAO,IAExCH,CAA6B7J,EACtC,CACF,CAvBIiK,CAAsB1I,GA+B1B,SAASsI,EAAuBtD,GAG9B,OAFAkD,EAAmBlD,EACnBmD,EAAiB,EACG,IAAhBnD,EAAKnG,OACAoJ,EAEFU,EAAgB3D,EAAKmD,GAC9B,CAQA,SAASQ,EAAgBvC,GACvB,OAGA,SAAe3H,GAKb4H,EAwER,WACE,MAAMuC,EAAa/F,IACbgG,EAAgB1D,EAAQ5E,SACxBuI,EAAwB3D,EAAQjD,iBAChC6G,EAAmB5D,EAAQ5F,OAAOV,OAClCmK,EAAaZ,MAAMxC,KAAK9E,GAC9B,MAAO,CACLgH,UACAlC,KAAMmD,GAQR,SAASjB,IACPnG,EAAQiH,EACRzD,EAAQ5E,SAAWsI,EACnB1D,EAAQjD,iBAAmB4G,EAC3B3D,EAAQ5F,OAAOV,OAASkK,EACxBjI,EAAQkI,EACRhD,GACF,CACF,CAhGeiD,GACP/G,EAAmBkE,EACdA,EAAU8C,UACb/D,EAAQjD,iBAAmBkE,GAK7B,GACEA,EAAU+C,MACVhE,EAAQpF,OAAOC,WAAWgE,QAAQC,KAAKC,SAASkC,EAAU+C,MAE1D,OAAOpF,EAAItF,GAEb,OAAO2H,EAAU1G,SAASmE,KAIxBoC,EAASnE,OAAOC,OAAOD,OAAOsH,OAAOjE,GAAUc,GAAUd,EACzDxF,EACAmE,EACAC,EAPKqC,CAQL3H,EACJ,CACF,CAGA,SAASqF,EAAGrF,GAGV,OAFAsH,GAAW,EACXgC,EAAS7F,EAAkBmE,GACpB2B,CACT,CAGA,SAASjE,EAAItF,GAGX,OAFAsH,GAAW,EACXM,EAAKyB,YACCK,EAAiBD,EAAiBrJ,OAC/B8J,EAAgBT,EAAiBC,IAEnCF,CACT,CACF,CACF,CAOA,SAAS3B,EAAUF,EAAWR,GACxBQ,EAAU5B,aAAesB,EAAqB5B,SAASkC,IACzDN,EAAqB5G,KAAKkH,GAExBA,EAAUiD,UACZrH,EAAAA,EAAAA,GACEmD,EAAQ5F,OACRqG,EACAT,EAAQ5F,OAAOV,OAAS+G,EACxBQ,EAAUiD,QAAQlE,EAAQ5F,OAAON,MAAM2G,GAAOT,IAG9CiB,EAAUkD,YACZnE,EAAQ5F,OAAS6G,EAAUkD,UAAUnE,EAAQ5F,OAAQ4F,GAEzD,CAuCA,SAASa,IACHrE,EAAMmB,QAAQ+C,GAAelE,EAAM7D,OAAS,IAC9C6D,EAAM7D,OAAS+H,EAAYlE,EAAMmB,MACjCnB,EAAMoB,QAAU8C,EAAYlE,EAAMmB,MAAQ,EAE9C,CACF,8NChdO,MAAMlC,EAAW,CACtB,GAAMoE,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMuE,EAAAA,GAIKtJ,EAAiB,CAC5B,GAAMuJ,EAAAA,GAIKnF,EAAc,CACzB,EAAE,GAAIoF,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,GAAMA,EAAAA,GAIKxG,EAAO,CAClB,GAAMyG,EAAAA,EACN,GAAMC,EAAAA,EACN,GAAM,CAACC,EAAAA,EAAiBD,EAAAA,GACxB,GAAME,EAAAA,EACN,GAAMD,EAAAA,EACN,GAAMD,EAAAA,EACN,GAAMG,EAAAA,EACN,IAAOA,EAAAA,GAIIpF,EAAS,CACpB,GAAMqF,EAAAA,EACN,GAAMC,EAAAA,GAIKpF,EAAO,CAClB,EAAE,GAAIqF,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,GAAMC,EAAAA,EACN,GAAMH,EAAAA,EACN,GAAMI,EAAAA,EACN,GAAM,CAACC,EAAAA,EAAUC,EAAAA,GACjB,GAAMC,EAAAA,EACN,GAAM,CAACC,EAAAA,EAAiBP,EAAAA,GACxB,GAAMQ,EAAAA,EACN,GAAML,EAAAA,EACN,GAAMM,EAAAA,GAIKC,EAAa,CACxBzG,KAAM,CAACkG,EAAAA,EAAWQ,IAIPC,EAAmB,CAC9B3G,KAAM,CAAC,GAAI,KAIAD,EAAU,CACrBC,KAAM,ICpFD,SAAS4G,EAAMC,GACpB,MAAMC,EAAWD,GAAW,CAAC,EAMvB/K,EAAS,CACbiL,QAAS,GACTpI,KAAM,CAAC,EACP5C,YANAiL,EAAAA,EAAAA,GAAkB,CAACC,KAAuBH,EAASI,YAAc,KAOjE1L,QAAS2J,EAAO3J,GAChBmB,SAAUwI,EAAOxI,GACjBqC,KAAMmG,EAAOnG,GACbyB,OAAQ0E,EAAO1E,GACfE,KAAMwE,EAAOxE,IAEf,OAAO7E,EAKP,SAASqJ,EAAOjF,GACd,OAEA,SAAiByB,GACf,OAAOF,EAAgB3F,EAAQoE,EAASyB,EAC1C,CACF,CACF","sources":["../node_modules/react-markdown/node_modules/react-is/cjs/react-is.production.min.js","../node_modules/react-markdown/node_modules/micromark/lib/preprocess.js","../node_modules/react-markdown/node_modules/react-is/index.js","../node_modules/react-markdown/node_modules/micromark/lib/postprocess.js","../node_modules/react-markdown/node_modules/micromark/lib/initialize/content.js","../node_modules/react-markdown/node_modules/micromark/lib/initialize/document.js","../node_modules/react-markdown/node_modules/micromark/lib/initialize/flow.js","../node_modules/react-markdown/node_modules/micromark/lib/initialize/text.js","../node_modules/react-markdown/node_modules/micromark/lib/create-tokenizer.js","../node_modules/react-markdown/node_modules/micromark/lib/constructs.js","../node_modules/react-markdown/node_modules/micromark/lib/parse.js"],"sourcesContent":["/**\n * @license React\n * react-is.production.min.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n'use strict';var b=Symbol.for(\"react.element\"),c=Symbol.for(\"react.portal\"),d=Symbol.for(\"react.fragment\"),e=Symbol.for(\"react.strict_mode\"),f=Symbol.for(\"react.profiler\"),g=Symbol.for(\"react.provider\"),h=Symbol.for(\"react.context\"),k=Symbol.for(\"react.server_context\"),l=Symbol.for(\"react.forward_ref\"),m=Symbol.for(\"react.suspense\"),n=Symbol.for(\"react.suspense_list\"),p=Symbol.for(\"react.memo\"),q=Symbol.for(\"react.lazy\"),t=Symbol.for(\"react.offscreen\"),u;u=Symbol.for(\"react.module.reference\");\nfunction v(a){if(\"object\"===typeof a&&null!==a){var r=a.$$typeof;switch(r){case b:switch(a=a.type,a){case d:case f:case e:case m:case n:return a;default:switch(a=a&&a.$$typeof,a){case k:case h:case l:case q:case p:case g:return a;default:return r}}case c:return r}}}exports.ContextConsumer=h;exports.ContextProvider=g;exports.Element=b;exports.ForwardRef=l;exports.Fragment=d;exports.Lazy=q;exports.Memo=p;exports.Portal=c;exports.Profiler=f;exports.StrictMode=e;exports.Suspense=m;\nexports.SuspenseList=n;exports.isAsyncMode=function(){return!1};exports.isConcurrentMode=function(){return!1};exports.isContextConsumer=function(a){return v(a)===h};exports.isContextProvider=function(a){return v(a)===g};exports.isElement=function(a){return\"object\"===typeof a&&null!==a&&a.$$typeof===b};exports.isForwardRef=function(a){return v(a)===l};exports.isFragment=function(a){return v(a)===d};exports.isLazy=function(a){return v(a)===q};exports.isMemo=function(a){return v(a)===p};\nexports.isPortal=function(a){return v(a)===c};exports.isProfiler=function(a){return v(a)===f};exports.isStrictMode=function(a){return v(a)===e};exports.isSuspense=function(a){return v(a)===m};exports.isSuspenseList=function(a){return v(a)===n};\nexports.isValidElementType=function(a){return\"string\"===typeof a||\"function\"===typeof a||a===d||a===f||a===e||a===m||a===n||a===t||\"object\"===typeof a&&null!==a&&(a.$$typeof===q||a.$$typeof===p||a.$$typeof===g||a.$$typeof===h||a.$$typeof===l||a.$$typeof===u||void 0!==a.getModuleId)?!0:!1};exports.typeOf=v;\n","/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Value} Value\n */\n\n/**\n * @callback Preprocessor\n * @param {Value} value\n * @param {Encoding | null | undefined} [encoding]\n * @param {boolean | null | undefined} [end=false]\n * @returns {Array<Chunk>}\n */\n\nconst search = /[\\0\\t\\n\\r]/g\n\n/**\n * @returns {Preprocessor}\n */\nexport function preprocess() {\n  let column = 1\n  let buffer = ''\n  /** @type {boolean | undefined} */\n  let start = true\n  /** @type {boolean | undefined} */\n  let atCarriageReturn\n  return preprocessor\n\n  /** @type {Preprocessor} */\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = []\n    /** @type {RegExpMatchArray | null} */\n    let match\n    /** @type {number} */\n    let next\n    /** @type {number} */\n    let startPosition\n    /** @type {number} */\n    let endPosition\n    /** @type {Code} */\n    let code\n\n    // @ts-expect-error `Buffer` does allow an encoding.\n    value = buffer + value.toString(encoding)\n    startPosition = 0\n    buffer = ''\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++\n      }\n      start = undefined\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition =\n        match && match.index !== undefined ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5)\n          atCarriageReturn = undefined\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n        switch (code) {\n          case 0: {\n            chunks.push(65533)\n            column++\n            break\n          }\n          case 9: {\n            next = Math.ceil(column / 4) * 4\n            chunks.push(-2)\n            while (column++ < next) chunks.push(-1)\n            break\n          }\n          case 10: {\n            chunks.push(-4)\n            column = 1\n            break\n          }\n          default: {\n            atCarriageReturn = true\n            column = 1\n          }\n        }\n      }\n      startPosition = endPosition + 1\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5)\n      if (buffer) chunks.push(buffer)\n      chunks.push(null)\n    }\n    return chunks\n  }\n}\n","'use strict';\n\nif (process.env.NODE_ENV === 'production') {\n  module.exports = require('./cjs/react-is.production.min.js');\n} else {\n  module.exports = require('./cjs/react-is.development.js');\n}\n","/**\n * @typedef {import('micromark-util-types').Event} Event\n */\n\nimport {subtokenize} from 'micromark-util-subtokenize'\n\n/**\n * @param {Array<Event>} events\n * @returns {Array<Event>}\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  /** @type {Token} */\n  let previous\n  return contentStart\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, contentStart, 'linePrefix')\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter('paragraph')\n    return lineStart(code)\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter('chunkText', {\n      contentType: 'text',\n      previous\n    })\n    if (previous) {\n      previous.next = token\n    }\n    previous = token\n    return data(code)\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit('chunkText')\n      effects.exit('paragraph')\n      effects.consume(code)\n      return\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit('chunkText')\n      return lineStart\n    }\n\n    // Data.\n    effects.consume(code)\n    return data\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n}\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeDocument(effects) {\n  const self = this\n  /** @type {Array<StackItem>} */\n  const stack = []\n  let continued = 0\n  /** @type {TokenizeContext | undefined} */\n  let childFlow\n  /** @type {Token | undefined} */\n  let childToken\n  /** @type {number} */\n  let lineStartOffset\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued]\n      self.containerState = item[1]\n      return effects.attempt(\n        item[0].continuation,\n        documentContinue,\n        checkNewContainers\n      )(code)\n    }\n\n    // Done.\n    return checkNewContainers(code)\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined\n      if (childFlow) {\n        closeFlow()\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          point = self.events[indexBeforeFlow][1].end\n          break\n        }\n      }\n      exitContainers(continued)\n\n      // Fix positions.\n      let index = indexBeforeExits\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n      return checkNewContainers(code)\n    }\n    return start(code)\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code)\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code)\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(\n        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack\n      )\n    }\n\n    // Check if there is a new container.\n    self.containerState = {}\n    return effects.check(\n      containerConstruct,\n      thereIsANewContainer,\n      thereIsNoNewContainer\n    )(code)\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow()\n    exitContainers(continued)\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length\n    lineStartOffset = self.now().offset\n    return flowStart(code)\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++\n    stack.push([self.currentConstruct, self.containerState])\n    // Try another.\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow()\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n    return flowContinue(code)\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit('chunkFlow'), true)\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      writeToChild(effects.exit('chunkFlow'))\n      // Get ready for the next line.\n      continued = 0\n      self.interrupt = undefined\n      return start\n    }\n    effects.consume(code)\n    return flowContinue\n  }\n\n  /**\n   * @param {Token} token\n   * @param {boolean | undefined} [eof]\n   * @returns {void}\n   */\n  function writeToChild(token, eof) {\n    const stream = self.sliceStream(token)\n    if (eof) stream.push(null)\n    token.previous = childToken\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.defineSkip(token.start)\n    childFlow.write(stream)\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length\n      while (index--) {\n        if (\n          // The token starts before the line ending…\n          childFlow.events[index][1].start.offset < lineStartOffset &&\n          // …and either is not ended yet…\n          (!childFlow.events[index][1].end ||\n            // …or ends after it.\n            childFlow.events[index][1].end.offset > lineStartOffset)\n        ) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {boolean | undefined} */\n      let seen\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end\n            break\n          }\n          seen = true\n        }\n      }\n      exitContainers(continued)\n\n      // Fix positions.\n      index = indexBeforeExits\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n    }\n  }\n\n  /**\n   * @param {number} size\n   * @returns {void}\n   */\n  function exitContainers(size) {\n    let index = stack.length\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index]\n      self.containerState = entry[1]\n      entry[0].exit.call(self, effects)\n    }\n    stack.length = size\n  }\n  function closeFlow() {\n    childFlow.write([null])\n    childToken = undefined\n    childFlow = undefined\n    self.containerState._closeFlow = undefined\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4\n  )\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {blankLine, content} from 'micromark-core-commonmark'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeFlow(effects) {\n  const self = this\n  const initial = effects.attempt(\n    // Try to parse a blank line.\n    blankLine,\n    atBlankEnding,\n    // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        'linePrefix'\n      )\n    )\n  )\n  return initial\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEndingBlank')\n    effects.consume(code)\n    effects.exit('lineEndingBlank')\n    self.currentConstruct = undefined\n    return initial\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n}\nexport const string = initializeFactory('string')\nexport const text = initializeFactory('text')\n\n/**\n * @param {'string' | 'text'} field\n * @returns {InitialConstruct}\n */\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this\n    const constructs = this.parser.constructs[field]\n    const text = effects.attempt(constructs, start, notText)\n    return start\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code)\n        return\n      }\n      effects.enter('data')\n      effects.consume(code)\n      return data\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data')\n        return text(code)\n      }\n\n      // Data.\n      effects.consume(code)\n      return data\n    }\n\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true\n      }\n      const list = constructs[code]\n      let index = -1\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index]\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true\n          }\n        }\n      }\n      return false\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n * @returns {Resolver}\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1\n    /** @type {number | undefined} */\n    let enter\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n        enter = undefined\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0 // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === 'lineEnding') &&\n      events[eventIndex - 1][1].type === 'data'\n    ) {\n      const data = events[eventIndex - 1][1]\n      const chunks = context.sliceStream(data)\n      let index = chunks.length\n      let bufferIndex = -1\n      let size = 0\n      /** @type {boolean | undefined} */\n      let tabs\n      while (index--) {\n        const chunk = chunks[index]\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++\n            bufferIndex--\n          }\n          if (bufferIndex) break\n          bufferIndex = -1\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true\n          size++\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n      if (size) {\n        const token = {\n          type:\n            eventIndex === events.length || tabs || size < 2\n              ? 'lineSuffix'\n              : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        }\n        data.end = Object.assign({}, token.start)\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n      eventIndex++\n    }\n  }\n  return events\n}\n","/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenType} TokenType\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * @callback Restore\n * @returns {void}\n *\n * @typedef Info\n * @property {Restore} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {void}\n */\n\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {push, splice} from 'micromark-util-chunked'\nimport {resolveAll} from 'micromark-util-resolve-all'\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(\n    from\n      ? Object.assign({}, from)\n      : {\n          line: 1,\n          column: 1,\n          offset: 0\n        },\n    {\n      _index: 0,\n      _bufferIndex: -1\n    }\n  )\n  /** @type {Record<string, number>} */\n  const columnStart = {}\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = []\n  /** @type {Array<Chunk>} */\n  let chunks = []\n  /** @type {Array<Token>} */\n  let stack = []\n  /** @type {boolean | undefined} */\n  let consumed = true\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  }\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    previous: null,\n    code: null,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  }\n\n  /**\n   * The state function.\n   *\n   * @type {State | void}\n   */\n  let state = initialize.tokenize.call(context, effects)\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n  return context\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice)\n    main()\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n    addResult(initialize, 0)\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n    return context.events\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs)\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {line, column, offset, _index, _bufferIndex} = point\n    return {\n      line,\n      column,\n      offset,\n      _index,\n      _bufferIndex\n    }\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {void}\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index]\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {void}\n   */\n  function go(code) {\n    consumed = undefined\n    expectedCode = code\n    state = state(code)\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++\n\n      // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code\n\n    // Mark as consumed.\n    consumed = true\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {}\n    token.type = type\n    token.start = now()\n    context.events.push(['enter', token, context])\n    stack.push(token)\n    return token\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop()\n    token.end = now()\n    context.events.push(['exit', token, context])\n    return token\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore()\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   */\n  function constructFactory(onreturn, fields) {\n    return hook\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | Construct | ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State | undefined} [bogusState]\n     * @returns {State}\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Array<Construct>} */\n      let listOfConstructs\n      /** @type {number} */\n      let constructIndex\n      /** @type {Construct} */\n      let currentConstruct\n      /** @type {Info} */\n      let info\n      return Array.isArray(constructs) /* c8 ignore next 1 */\n        ? handleListOfConstructs(constructs)\n        : 'tokenize' in constructs\n        ? // @ts-expect-error Looks like a construct.\n          handleListOfConstructs([constructs])\n        : handleMapOfConstructs(constructs)\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n      function handleMapOfConstructs(map) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          const def = code !== null && map[code]\n          const all = code !== null && map.null\n          const list = [\n            // To do: add more extension tests.\n            /* c8 ignore next 2 */\n            ...(Array.isArray(def) ? def : def ? [def] : []),\n            ...(Array.isArray(all) ? all : all ? [all] : [])\n          ]\n          return handleListOfConstructs(list)(code)\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Array<Construct>} list\n       * @returns {State}\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n        if (list.length === 0) {\n          return bogusState\n        }\n        return handleConstruct(list[constructIndex])\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n      function handleConstruct(construct) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          // Always populated by defaults.\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.includes(construct.name)\n          ) {\n            return nok(code)\n          }\n          return construct.tokenize.call(\n            // If we do have fields, create an object w/ `context` as its\n            // prototype.\n            // This allows a “live binding”, which is needed for `interrupt`.\n            fields ? Object.assign(Object.create(context), fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true\n        info.restore()\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n        return bogusState\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {void}\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct)\n    }\n    if (construct.resolve) {\n      splice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n  function store() {\n    const startPoint = now()\n    const startPrevious = context.previous\n    const startCurrentConstruct = context.currentConstruct\n    const startEventsIndex = context.events.length\n    const startStack = Array.from(stack)\n    return {\n      restore,\n      from: startEventsIndex\n    }\n\n    /**\n     * Restore state.\n     *\n     * @returns {void}\n     */\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {void}\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Array<Chunk>} chunks\n * @param {Pick<Token, 'end' | 'start'>} token\n * @returns {Array<Chunk>}\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index\n  const startBufferIndex = token.start._bufferIndex\n  const endIndex = token.end._index\n  const endBufferIndex = token.end._bufferIndex\n  /** @type {Array<Chunk>} */\n  let view\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n    if (startBufferIndex > -1) {\n      const head = view[0]\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex)\n      } else {\n        view.shift()\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n  return view\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Array<Chunk>} chunks\n * @param {boolean | undefined} [expandTabs=false]\n * @returns {string}\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1\n  /** @type {Array<string>} */\n  const result = []\n  /** @type {boolean | undefined} */\n  let atTab\n  while (++index < chunks.length) {\n    const chunk = chunks[index]\n    /** @type {string} */\n    let value\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else\n      switch (chunk) {\n        case -5: {\n          value = '\\r'\n          break\n        }\n        case -4: {\n          value = '\\n'\n          break\n        }\n        case -3: {\n          value = '\\r' + '\\n'\n          break\n        }\n        case -2: {\n          value = expandTabs ? ' ' : '\\t'\n          break\n        }\n        case -1: {\n          if (!expandTabs && atTab) continue\n          value = ' '\n          break\n        }\n        default: {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk)\n        }\n      }\n    atTab = chunk === -2\n    result.push(value)\n  }\n  return result.join('')\n}\n","/**\n * @typedef {import('micromark-util-types').Extension} Extension\n */\n\nimport {\n  attention,\n  autolink,\n  blockQuote,\n  characterEscape,\n  characterReference,\n  codeFenced,\n  codeIndented,\n  codeText,\n  definition,\n  hardBreakEscape,\n  headingAtx,\n  htmlFlow,\n  htmlText,\n  labelEnd,\n  labelStartImage,\n  labelStartLink,\n  lineEnding,\n  list,\n  setextUnderline,\n  thematicBreak\n} from 'micromark-core-commonmark'\nimport {resolver as resolveText} from './initialize/text.js'\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n}\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n}\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n}\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n}\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n}\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n}\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n}\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n}\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n}\n","/**\n * @typedef {import('micromark-util-types').Create} Create\n * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').ParseOptions} ParseOptions\n */\n\nimport {combineExtensions} from 'micromark-util-combine-extensions'\nimport {content} from './initialize/content.js'\nimport {document} from './initialize/document.js'\nimport {flow} from './initialize/flow.js'\nimport {text, string} from './initialize/text.js'\nimport {createTokenizer} from './create-tokenizer.js'\nimport * as defaultConstructs from './constructs.js'\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n * @returns {ParseContext}\n */\nexport function parse(options) {\n  const settings = options || {}\n  const constructs =\n    /** @type {FullNormalizedExtension} */\n    combineExtensions([defaultConstructs, ...(settings.extensions || [])])\n\n  /** @type {ParseContext} */\n  const parser = {\n    defined: [],\n    lazy: {},\n    constructs,\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(string),\n    text: create(text)\n  }\n  return parser\n\n  /**\n   * @param {InitialConstruct} initial\n   */\n  function create(initial) {\n    return creator\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from)\n    }\n  }\n}\n"],"names":["u","b","Symbol","for","c","d","e","f","g","h","k","l","m","n","p","q","t","v","a","r","$$typeof","type","exports","ContextConsumer","ContextProvider","Element","ForwardRef","Fragment","Lazy","Memo","Portal","Profiler","StrictMode","Suspense","SuspenseList","isAsyncMode","isConcurrentMode","isContextConsumer","isContextProvider","isElement","isForwardRef","isFragment","isLazy","isMemo","isPortal","isProfiler","isStrictMode","isSuspense","isSuspenseList","isValidElementType","getModuleId","typeOf","search","preprocess","atCarriageReturn","column","buffer","start","value","encoding","end","chunks","match","next","startPosition","endPosition","code","toString","charCodeAt","undefined","length","lastIndex","exec","index","slice","push","Math","ceil","module","postprocess","events","subtokenize","content","tokenize","effects","contentStart","attempt","this","parser","constructs","contentInitial","consume","enter","exit","factorySpace","lineStart","previous","token","contentType","data","markdownLineEnding","document","self","stack","childFlow","childToken","lineStartOffset","continued","item","containerState","continuation","documentContinue","checkNewContainers","_closeFlow","closeFlow","indexBeforeExits","point","indexBeforeFlow","exitContainers","Object","assign","splice","documentContinued","currentConstruct","concrete","flowStart","interrupt","Boolean","_gfmTableDynamicInterruptHack","check","containerConstruct","thereIsANewContainer","thereIsNoNewContainer","lazy","now","line","offset","containerContinue","flow","_tokenizer","flowContinue","writeToChild","eof","stream","sliceStream","defineSkip","write","seen","size","entry","call","ok","nok","disable","null","includes","initial","blankLine","flowInitial","afterConstruct","resolver","resolveAll","createResolver","string","initializeFactory","text","field","notText","atBreak","list","resolveAllLineSuffixes","extraResolver","context","eventIndex","tabs","bufferIndex","chunk","_index","_bufferIndex","createTokenizer","initialize","from","columnStart","resolveAllConstructs","consumed","accountForPotentialSkip","fields","pop","constructFactory","construct","info","addResult","onsuccessfulcheck","sliceSerialize","expandTabs","result","atTab","String","fromCharCode","join","serializeChunks","main","expectedCode","state","startIndex","startBufferIndex","endIndex","endBufferIndex","view","head","shift","sliceChunks","chunkIndex","go","_","restore","onreturn","returnState","bogusState","listOfConstructs","constructIndex","Array","isArray","handleListOfConstructs","map","def","all","handleMapOfConstructs","handleConstruct","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","store","partial","name","create","resolve","resolveTo","blockQuote","definition","codeIndented","headingAtx","thematicBreak","setextUnderline","htmlFlow","codeFenced","characterReference","characterEscape","lineEnding","labelStartImage","attention","autolink","htmlText","labelStartLink","hardBreakEscape","labelEnd","codeText","insideSpan","resolveText","attentionMarkers","parse","options","settings","defined","combineExtensions","defaultConstructs","extensions"],"sourceRoot":""}