{"version":3,"file":"static/js/vendor.micromark-0d7ea0ba.34726a6c48.chunk.v1_7.js","mappings":"sJAUO,SAASA,EAAYC,GAC1B,OAAQC,EAAAA,EAAAA,GAAYD,KAGpB,OAAOA,CACT,C,sDCNO,MAAME,EAAW,CACtBC,WAAYC,KAEDC,EAASC,EAAkB,UAC3BC,EAAOD,EAAkB,QAMtC,SAASA,EAAkBE,GACzB,MAAO,CACLC,SAUF,SAAwBC,GACtB,MAAMC,EAAOC,KACPC,EAAaD,KAAKE,OAAOD,WAAWL,GACpCD,EAAOG,EAAQK,QAAQF,EAAYG,EAAOC,GAChD,OAAOD,EAGP,SAASA,EAAME,GACb,OAAOC,EAAQD,GAAQX,EAAKW,GAAQD,EAAQC,EAC9C,CAGA,SAASD,EAAQC,GACf,GAAa,OAATA,EAMJ,OAFAR,EAAQU,MAAM,QACdV,EAAQW,QAAQH,GACTI,EALLZ,EAAQW,QAAQH,EAMpB,CAGA,SAASI,EAAKJ,GACZ,OAAIC,EAAQD,IACVR,EAAQa,KAAK,QACNhB,EAAKW,KAIdR,EAAQW,QAAQH,GACTI,EACT,CAMA,SAASH,EAAQD,GACf,GAAa,OAATA,EACF,OAAO,EAET,MAAMM,EAAOX,EAAWK,GACxB,IAAIO,GAAS,EACb,GAAID,EAGF,OAASC,EAAQD,EAAKE,QAAQ,CAC5B,MAAMC,EAAOH,EAAKC,GAClB,IAAKE,EAAKC,UAAYD,EAAKC,SAASC,KAAKlB,EAAMA,EAAKiB,UAClD,OAAO,CAEX,CAEF,OAAO,CACT,CACF,EAjEEzB,WAAYC,EACA,SAAVI,EAAmBsB,OAAyBC,GAiElD,CAMA,SAAS3B,EAAe4B,GACtB,OAGA,SAAwBhC,EAAQiC,GAC9B,IAEIb,EAFAK,GAAS,EAMb,OAASA,GAASzB,EAAO0B,aACTK,IAAVX,EACEpB,EAAOyB,IAAoC,SAA1BzB,EAAOyB,GAAO,GAAGS,OACpCd,EAAQK,EACRA,KAEQzB,EAAOyB,IAAoC,SAA1BzB,EAAOyB,GAAO,GAAGS,OAExCT,IAAUL,EAAQ,IACpBpB,EAAOoB,GAAO,GAAGe,IAAMnC,EAAOyB,EAAQ,GAAG,GAAGU,IAC5CnC,EAAOoC,OAAOhB,EAAQ,EAAGK,EAAQL,EAAQ,GACzCK,EAAQL,EAAQ,GAElBA,OAAQW,GAGZ,OAAOC,EAAgBA,EAAchC,EAAQiC,GAAWjC,CAC1D,CACF,CAaA,SAAS8B,EAAuB9B,EAAQiC,GACtC,IAAII,EAAa,EAEjB,OAASA,GAAcrC,EAAO0B,QAC5B,IACGW,IAAerC,EAAO0B,QACU,eAA/B1B,EAAOqC,GAAY,GAAGH,OACW,SAAnClC,EAAOqC,EAAa,GAAG,GAAGH,KAC1B,CACA,MAAMZ,EAAOtB,EAAOqC,EAAa,GAAG,GAC9BC,EAASL,EAAQM,YAAYjB,GACnC,IAIIkB,EAJAf,EAAQa,EAAOZ,OACfe,GAAe,EACfC,EAAO,EAGX,KAAOjB,KAAS,CACd,MAAMkB,EAAQL,EAAOb,GACrB,GAAqB,iBAAVkB,EAAoB,CAE7B,IADAF,EAAcE,EAAMjB,OACyB,KAAtCiB,EAAMC,WAAWH,EAAc,IACpCC,IACAD,IAEF,GAAIA,EAAa,MACjBA,GAAe,CACjB,MAEK,IAAe,IAAXE,EACPH,GAAO,EACPE,SACK,IAAe,IAAXC,EAEJ,CAELlB,IACA,KACF,CACF,CACA,GAAIiB,EAAM,CACR,MAAMG,EAAQ,CACZX,KACEG,IAAerC,EAAO0B,QAAUc,GAAQE,EAAO,EAC3C,aACA,oBACN1B,MAAO,CACL8B,KAAMxB,EAAKa,IAAIW,KACfC,OAAQzB,EAAKa,IAAIY,OAASL,EAC1BM,OAAQ1B,EAAKa,IAAIa,OAASN,EAC1BO,OAAQ3B,EAAKN,MAAMiC,OAASxB,EAC5ByB,aAAczB,EACVgB,EACAnB,EAAKN,MAAMkC,aAAeT,GAEhCN,IAAKgB,OAAOC,OAAO,CAAC,EAAG9B,EAAKa,MAE9Bb,EAAKa,IAAMgB,OAAOC,OAAO,CAAC,EAAGP,EAAM7B,OAC/BM,EAAKN,MAAMgC,SAAW1B,EAAKa,IAAIa,OACjCG,OAAOC,OAAO9B,EAAMuB,IAEpB7C,EAAOoC,OACLC,EACA,EACA,CAAC,QAASQ,EAAOZ,GACjB,CAAC,OAAQY,EAAOZ,IAElBI,GAAc,EAElB,CACAA,GACF,CAEF,OAAOrC,CACT,C,oCC1L0BqD,EAAW,YAcJA,EAAW,cAuBlBA,EAAW,uBAgCXA,EAAW,MAoBRA,EAAW,cAeRA,EAAW,kBAiBpC,SAASC,EAAmBpC,GACjC,OAAgB,OAATA,GAAiBA,GAAQ,CAClC,CAuDkCmC,EC9LhC,wwCDoN+BA,EAAW,MAQ5C,SAASA,EAAWE,GAClB,OAUA,SAAerC,GACb,OAAgB,OAATA,GAAiBqC,EAAMC,KAAKC,OAAOC,aAAaxC,GACzD,CACF,C,wEE1OO,MAAMyC,EAAU,CACrBlD,SAOF,SAA2BC,GACzB,MAAMkD,EAAelD,EAAQK,QAC3BH,KAAKE,OAAOD,WAAWgD,gBASzB,SAAoC3C,GAClC,GAAa,OAATA,EAEF,YADAR,EAAQW,QAAQH,GAMlB,OAHAR,EAAQU,MAAM,cACdV,EAAQW,QAAQH,GAChBR,EAAQa,KAAK,eACNuC,EAAAA,EAAAA,GAAapD,EAASkD,EAAc,aAC7C,IAGA,SAA0B1C,GAExB,OADAR,EAAQU,MAAM,aACP2C,EAAU7C,EACnB,IAnBA,IAAIU,EACJ,OAAOgC,EAqBP,SAASG,EAAU7C,GACjB,MAAM2B,EAAQnC,EAAQU,MAAM,YAAa,CACvC4C,YAAa,OACbpC,aAMF,OAJIA,IACFA,EAASqC,KAAOpB,GAElBjB,EAAWiB,EACJvB,EAAKJ,EACd,CAGA,SAASI,EAAKJ,GACZ,OAAa,OAATA,GACFR,EAAQa,KAAK,aACbb,EAAQa,KAAK,kBACbb,EAAQW,QAAQH,KAGdoC,EAAAA,EAAAA,IAAmBpC,IACrBR,EAAQW,QAAQH,GAChBR,EAAQa,KAAK,aACNwC,IAITrD,EAAQW,QAAQH,GACTI,EACT,CACF,G,cC1DO,MAAM4C,EAAW,CACtBzD,SAYF,SAA4BC,GAC1B,MAAMC,EAAOC,KAEPuD,EAAQ,GACd,IAEIC,EAEAC,EAEAC,EANAC,EAAY,EAOhB,OAAOvD,EAGP,SAASA,EAAME,GAWb,GAAIqD,EAAYJ,EAAMzC,OAAQ,CAC5B,MAAMC,EAAOwC,EAAMI,GAEnB,OADA5D,EAAK6D,eAAiB7C,EAAK,GACpBjB,EAAQK,QACbY,EAAK,GAAG8C,aACRC,EACAC,EAHKjE,CAILQ,EACJ,CAGA,OAAOyD,EAAmBzD,EAC5B,CAGA,SAASwD,EAAiBxD,GAMxB,GALAqD,IAKI5D,EAAK6D,eAAeI,WAAY,CAClCjE,EAAK6D,eAAeI,gBAAa7C,EAC7BqC,GACFS,IAKF,MAAMC,EAAmBnE,EAAKX,OAAO0B,OACrC,IAEIqD,EAFAC,EAAkBF,EAKtB,KAAOE,KACL,GACsC,SAApCrE,EAAKX,OAAOgF,GAAiB,IACY,cAAzCrE,EAAKX,OAAOgF,GAAiB,GAAG9C,KAChC,CACA6C,EAAQpE,EAAKX,OAAOgF,GAAiB,GAAG7C,IACxC,KACF,CAEF8C,EAAeV,GAGf,IAAI9C,EAAQqD,EACZ,KAAOrD,EAAQd,EAAKX,OAAO0B,QACzBf,EAAKX,OAAOyB,GAAO,GAAGU,IAAMgB,OAAOC,OAAO,CAAC,EAAG2B,GAC9CtD,IAaF,OATAW,EAAAA,EAAAA,GACEzB,EAAKX,OACLgF,EAAkB,EAClB,EACArE,EAAKX,OAAOkF,MAAMJ,IAIpBnE,EAAKX,OAAO0B,OAASD,EACdkD,EAAmBzD,EAC5B,CACA,OAAOF,EAAME,EACf,CAGA,SAASyD,EAAmBzD,GAM1B,GAAIqD,IAAcJ,EAAMzC,OAAQ,CAI9B,IAAK0C,EACH,OAAOe,EAAkBjE,GAM3B,GAAIkD,EAAUgB,kBAAoBhB,EAAUgB,iBAAiBC,SAC3D,OAAOC,EAAUpE,GAQnBP,EAAK4E,UAAYC,QACfpB,EAAUgB,mBAAqBhB,EAAUqB,8BAE7C,CAIA,OADA9E,EAAK6D,eAAiB,CAAC,EAChB9D,EAAQgF,MACbC,EACAC,EACAC,EAHKnF,CAILQ,EACJ,CAGA,SAAS0E,EAAqB1E,GAG5B,OAFIkD,GAAWS,IACfI,EAAeV,GACRY,EAAkBjE,EAC3B,CAGA,SAAS2E,EAAsB3E,GAG7B,OAFAP,EAAKG,OAAOgF,KAAKnF,EAAKoF,MAAMjD,MAAQyB,IAAcJ,EAAMzC,OACxD4C,EAAkB3D,EAAKoF,MAAM/C,OACtBsC,EAAUpE,EACnB,CAGA,SAASiE,EAAkBjE,GAGzB,OADAP,EAAK6D,eAAiB,CAAC,EAChB9D,EAAQK,QACb4E,EACAK,EACAV,EAHK5E,CAILQ,EACJ,CAGA,SAAS8E,EAAkB9E,GAIzB,OAHAqD,IACAJ,EAAM8B,KAAK,CAACtF,EAAKyE,iBAAkBzE,EAAK6D,iBAEjCW,EAAkBjE,EAC3B,CAGA,SAASoE,EAAUpE,GACjB,OAAa,OAATA,GACEkD,GAAWS,IACfI,EAAe,QACfvE,EAAQW,QAAQH,KAGlBkD,EAAYA,GAAazD,EAAKG,OAAOoF,KAAKvF,EAAKoF,OAC/CrF,EAAQU,MAAM,YAAa,CACzB4C,YAAa,OACbpC,SAAUyC,EACV8B,WAAY/B,IAEPgC,EAAalF,GACtB,CAGA,SAASkF,EAAalF,GACpB,OAAa,OAATA,GACFmF,EAAa3F,EAAQa,KAAK,cAAc,GACxC0D,EAAe,QACfvE,EAAQW,QAAQH,KAGdoC,EAAAA,EAAAA,IAAmBpC,IACrBR,EAAQW,QAAQH,GAChBmF,EAAa3F,EAAQa,KAAK,cAE1BgD,EAAY,EACZ5D,EAAK4E,eAAYxD,EACVf,IAETN,EAAQW,QAAQH,GACTkF,EACT,CAOA,SAASC,EAAaxD,EAAOyD,GAC3B,MAAMC,EAAS5F,EAAK4B,YAAYM,GAyChC,GAxCIyD,GAAKC,EAAON,KAAK,MACrBpD,EAAMjB,SAAWyC,EACbA,IAAYA,EAAWJ,KAAOpB,GAClCwB,EAAaxB,EACbuB,EAAUoC,WAAW3D,EAAM7B,OAC3BoD,EAAUqC,MAAMF,GAmCZ5F,EAAKG,OAAOgF,KAAKjD,EAAM7B,MAAM8B,MAAO,CACtC,IAAIrB,EAAQ2C,EAAUpE,OAAO0B,OAC7B,KAAOD,KACL,GAEE2C,EAAUpE,OAAOyB,GAAO,GAAGT,MAAMgC,OAASsB,KAExCF,EAAUpE,OAAOyB,GAAO,GAAGU,KAE3BiC,EAAUpE,OAAOyB,GAAO,GAAGU,IAAIa,OAASsB,GAI1C,OAMJ,MAAMQ,EAAmBnE,EAAKX,OAAO0B,OACrC,IAEIgF,EAEA3B,EAJAC,EAAkBF,EAOtB,KAAOE,KACL,GACsC,SAApCrE,EAAKX,OAAOgF,GAAiB,IACY,cAAzCrE,EAAKX,OAAOgF,GAAiB,GAAG9C,KAChC,CACA,GAAIwE,EAAM,CACR3B,EAAQpE,EAAKX,OAAOgF,GAAiB,GAAG7C,IACxC,KACF,CACAuE,GAAO,CACT,CAMF,IAJAzB,EAAeV,GAGf9C,EAAQqD,EACDrD,EAAQd,EAAKX,OAAO0B,QACzBf,EAAKX,OAAOyB,GAAO,GAAGU,IAAMgB,OAAOC,OAAO,CAAC,EAAG2B,GAC9CtD,KAIFW,EAAAA,EAAAA,GACEzB,EAAKX,OACLgF,EAAkB,EAClB,EACArE,EAAKX,OAAOkF,MAAMJ,IAIpBnE,EAAKX,OAAO0B,OAASD,CACvB,CACF,CAMA,SAASwD,EAAevC,GACtB,IAAIjB,EAAQ0C,EAAMzC,OAGlB,KAAOD,KAAUiB,GAAM,CACrB,MAAMiE,EAAQxC,EAAM1C,GACpBd,EAAK6D,eAAiBmC,EAAM,GAC5BA,EAAM,GAAGpF,KAAKM,KAAKlB,EAAMD,EAC3B,CACAyD,EAAMzC,OAASgB,CACjB,CACA,SAASmC,IACPT,EAAUqC,MAAM,CAAC,OACjBpC,OAAatC,EACbqC,OAAYrC,EACZpB,EAAK6D,eAAeI,gBAAa7C,CACnC,CACF,GArVM4D,EAAqB,CACzBlF,SA0VF,SAA2BC,EAASkG,EAAIC,GAGtC,OAAO/C,EAAAA,EAAAA,GACLpD,EACAA,EAAQK,QAAQH,KAAKE,OAAOD,WAAWqD,SAAU0C,EAAIC,GACrD,aACAjG,KAAKE,OAAOD,WAAWiG,QAAQC,KAAKC,SAAS,qBAAkBjF,EAAY,EAE/E,G,0BClXO,MAAMmE,EAAO,CAClBzF,SAOF,SAAwBC,GACtB,MAAMC,EAAOC,KACPqG,EAAUvG,EAAQK,QAEtBmG,EAAAA,GAoBF,SAAuBhG,GACrB,GAAa,OAATA,EAEF,YADAR,EAAQW,QAAQH,GAOlB,OAJAR,EAAQU,MAAM,mBACdV,EAAQW,QAAQH,GAChBR,EAAQa,KAAK,mBACbZ,EAAKyE,sBAAmBrD,EACjBkF,CACT,GA3BEvG,EAAQK,QACNH,KAAKE,OAAOD,WAAWsG,YACvBC,GACAtD,EAAAA,EAAAA,GACEpD,EACAA,EAAQK,QACNH,KAAKE,OAAOD,WAAWqF,KACvBkB,EACA1G,EAAQK,QAAQ4C,EAAAA,EAASyD,IAE3B,gBAIN,OAAOH,EAgBP,SAASG,EAAelG,GACtB,GAAa,OAATA,EAQJ,OAJAR,EAAQU,MAAM,cACdV,EAAQW,QAAQH,GAChBR,EAAQa,KAAK,cACbZ,EAAKyE,sBAAmBrD,EACjBkF,EAPLvG,EAAQW,QAAQH,EAQpB,CACF,G,qCC/CO,SAASmG,EAAMC,GACpB,MAAMC,EAAWD,GAAW,CAAC,EAMvBxG,EAAS,CACb0G,QAAS,GACT1B,KAAM,CAAC,EACPjF,YANA4G,EAAAA,EAAAA,GAAkB,CAACC,KAAuBH,EAASI,YAAc,KAOjEhE,QAASiE,EAAOjE,GAChBO,SAAU0D,EAAO1D,GACjBgC,KAAM0B,EAAO1B,GACb7F,OAAQuH,EAAOvH,EAAAA,IACfE,KAAMqH,EAAOrH,EAAAA,KAEf,OAAOO,EAKP,SAAS8G,EAAOX,GACd,OAEA,SAAiBY,GACf,OAAOC,EAAAA,EAAAA,GAAgBhH,EAAQmG,EAASY,EAC1C,CACF,CACF,C,mCClCA,MAAME,EAAS,cAKR,SAASC,IACd,IAKIC,EALAlF,EAAS,EACTmF,EAAS,GAETlH,GAAQ,EAGZ,OAGA,SAAsBmH,EAAOC,EAAUjG,GAErC,MAAMG,EAAS,GAEf,IAAI+F,EAEApE,EAEAqE,EAEAC,EAEArH,EAGJiH,EAAQD,EAASC,EAAMK,SAASJ,GAChCE,EAAgB,EAChBJ,EAAS,GACLlH,IAE0B,QAAxBmH,EAAMvF,WAAW,IACnB0F,IAEFtH,OAAQe,GAEV,KAAOuG,EAAgBH,EAAMzG,QAAQ,CAMnC,GALAqG,EAAOU,UAAYH,EACnBD,EAAQN,EAAOW,KAAKP,GACpBI,EACEF,QAAyBtG,IAAhBsG,EAAM5G,MAAsB4G,EAAM5G,MAAQ0G,EAAMzG,OAC3DR,EAAOiH,EAAMvF,WAAW2F,IACnBF,EAAO,CACVH,EAASC,EAAMjD,MAAMoD,GACrB,KACF,CACA,GAAa,KAATpH,GAAeoH,IAAkBC,GAAeN,EAClD3F,EAAO2D,MAAM,GACbgC,OAAmBlG,OAUnB,OARIkG,IACF3F,EAAO2D,MAAM,GACbgC,OAAmBlG,GAEjBuG,EAAgBC,IAClBjG,EAAO2D,KAAKkC,EAAMjD,MAAMoD,EAAeC,IACvCxF,GAAUwF,EAAcD,GAElBpH,GACN,KAAK,EACHoB,EAAO2D,KAAK,OACZlD,IACA,MAEF,KAAK,EAGH,IAFAkB,EAA+B,EAAxB0E,KAAKC,KAAK7F,EAAS,GAC1BT,EAAO2D,MAAM,GACNlD,IAAWkB,GAAM3B,EAAO2D,MAAM,GACrC,MAEF,KAAK,GACH3D,EAAO2D,MAAM,GACblD,EAAS,EACT,MAEF,QACEkF,GAAmB,EACnBlF,EAAS,EAIfuF,EAAgBC,EAAc,CAChC,CACIpG,IACE8F,GAAkB3F,EAAO2D,MAAM,GAC/BiC,GAAQ5F,EAAO2D,KAAKiC,GACxB5F,EAAO2D,KAAK,OAEd,OAAO3D,CACT,CACF,C","sources":["../node_modules/micromark/lib/postprocess.js","../node_modules/micromark/lib/initialize/text.js","../node_modules/micromark/node_modules/micromark-util-character/index.js","../node_modules/micromark/node_modules/micromark-util-character/lib/unicode-punctuation-regex.js","../node_modules/micromark/lib/initialize/content.js","../node_modules/micromark/lib/initialize/document.js","../node_modules/micromark/lib/initialize/flow.js","../node_modules/micromark/lib/parse.js","../node_modules/micromark/lib/preprocess.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Event} Event\n */\n\nimport {subtokenize} from 'micromark-util-subtokenize'\n\n/**\n * @param {Array<Event>} events\n * @returns {Array<Event>}\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n}\nexport const string = initializeFactory('string')\nexport const text = initializeFactory('text')\n\n/**\n * @param {'string' | 'text'} field\n * @returns {InitialConstruct}\n */\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this\n    const constructs = this.parser.constructs[field]\n    const text = effects.attempt(constructs, start, notText)\n    return start\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code)\n        return\n      }\n      effects.enter('data')\n      effects.consume(code)\n      return data\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data')\n        return text(code)\n      }\n\n      // Data.\n      effects.consume(code)\n      return data\n    }\n\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true\n      }\n      const list = constructs[code]\n      let index = -1\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index]\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true\n          }\n        }\n      }\n      return false\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n * @returns {Resolver}\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1\n    /** @type {number | undefined} */\n    let enter\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n        enter = undefined\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0 // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === 'lineEnding') &&\n      events[eventIndex - 1][1].type === 'data'\n    ) {\n      const data = events[eventIndex - 1][1]\n      const chunks = context.sliceStream(data)\n      let index = chunks.length\n      let bufferIndex = -1\n      let size = 0\n      /** @type {boolean | undefined} */\n      let tabs\n      while (index--) {\n        const chunk = chunks[index]\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++\n            bufferIndex--\n          }\n          if (bufferIndex) break\n          bufferIndex = -1\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true\n          size++\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n      if (size) {\n        const token = {\n          type:\n            eventIndex === events.length || tabs || size < 2\n              ? 'lineSuffix'\n              : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        }\n        data.end = Object.assign({}, token.start)\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n      eventIndex++\n    }\n  }\n  return events\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n */\n\nimport {unicodePunctuationRegex} from './lib/unicode-punctuation-regex.js'\n\n/**\n * Check whether the character code represents an ASCII alpha (`a` through `z`,\n * case insensitive).\n *\n * An **ASCII alpha** is an ASCII upper alpha or ASCII lower alpha.\n *\n * An **ASCII upper alpha** is a character in the inclusive range U+0041 (`A`)\n * to U+005A (`Z`).\n *\n * An **ASCII lower alpha** is a character in the inclusive range U+0061 (`a`)\n * to U+007A (`z`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAlpha = regexCheck(/[A-Za-z]/)\n\n/**\n * Check whether the character code represents an ASCII alphanumeric (`a`\n * through `z`, case insensitive, or `0` through `9`).\n *\n * An **ASCII alphanumeric** is an ASCII digit (see `asciiDigit`) or ASCII alpha\n * (see `asciiAlpha`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAlphanumeric = regexCheck(/[\\dA-Za-z]/)\n\n/**\n * Check whether the character code represents an ASCII atext.\n *\n * atext is an ASCII alphanumeric (see `asciiAlphanumeric`), or a character in\n * the inclusive ranges U+0023 NUMBER SIGN (`#`) to U+0027 APOSTROPHE (`'`),\n * U+002A ASTERISK (`*`), U+002B PLUS SIGN (`+`), U+002D DASH (`-`), U+002F\n * SLASH (`/`), U+003D EQUALS TO (`=`), U+003F QUESTION MARK (`?`), U+005E\n * CARET (`^`) to U+0060 GRAVE ACCENT (`` ` ``), or U+007B LEFT CURLY BRACE\n * (`{`) to U+007E TILDE (`~`).\n *\n * See:\n * **\\[RFC5322]**:\n * [Internet Message Format](https://tools.ietf.org/html/rfc5322).\n * P. Resnick.\n * IETF.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAtext = regexCheck(/[#-'*+\\--9=?A-Z^-~]/)\n\n/**\n * Check whether a character code is an ASCII control character.\n *\n * An **ASCII control** is a character in the inclusive range U+0000 NULL (NUL)\n * to U+001F (US), or U+007F (DEL).\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function asciiControl(code) {\n  return (\n    // Special whitespace codes (which have negative values), C0 and Control\n    // character DEL\n    code !== null && (code < 32 || code === 127)\n  )\n}\n\n/**\n * Check whether the character code represents an ASCII digit (`0` through `9`).\n *\n * An **ASCII digit** is a character in the inclusive range U+0030 (`0`) to\n * U+0039 (`9`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiDigit = regexCheck(/\\d/)\n\n/**\n * Check whether the character code represents an ASCII hex digit (`a` through\n * `f`, case insensitive, or `0` through `9`).\n *\n * An **ASCII hex digit** is an ASCII digit (see `asciiDigit`), ASCII upper hex\n * digit, or an ASCII lower hex digit.\n *\n * An **ASCII upper hex digit** is a character in the inclusive range U+0041\n * (`A`) to U+0046 (`F`).\n *\n * An **ASCII lower hex digit** is a character in the inclusive range U+0061\n * (`a`) to U+0066 (`f`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiHexDigit = regexCheck(/[\\dA-Fa-f]/)\n\n/**\n * Check whether the character code represents ASCII punctuation.\n *\n * An **ASCII punctuation** is a character in the inclusive ranges U+0021\n * EXCLAMATION MARK (`!`) to U+002F SLASH (`/`), U+003A COLON (`:`) to U+0040 AT\n * SIGN (`@`), U+005B LEFT SQUARE BRACKET (`[`) to U+0060 GRAVE ACCENT\n * (`` ` ``), or U+007B LEFT CURLY BRACE (`{`) to U+007E TILDE (`~`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/)\n\n/**\n * Check whether a character code is a markdown line ending.\n *\n * A **markdown line ending** is the virtual characters M-0003 CARRIAGE RETURN\n * LINE FEED (CRLF), M-0004 LINE FEED (LF) and M-0005 CARRIAGE RETURN (CR).\n *\n * In micromark, the actual character U+000A LINE FEED (LF) and U+000D CARRIAGE\n * RETURN (CR) are replaced by these virtual characters depending on whether\n * they occurred together.\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownLineEnding(code) {\n  return code !== null && code < -2\n}\n\n/**\n * Check whether a character code is a markdown line ending (see\n * `markdownLineEnding`) or markdown space (see `markdownSpace`).\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownLineEndingOrSpace(code) {\n  return code !== null && (code < 0 || code === 32)\n}\n\n/**\n * Check whether a character code is a markdown space.\n *\n * A **markdown space** is the concrete character U+0020 SPACE (SP) and the\n * virtual characters M-0001 VIRTUAL SPACE (VS) and M-0002 HORIZONTAL TAB (HT).\n *\n * In micromark, the actual character U+0009 CHARACTER TABULATION (HT) is\n * replaced by one M-0002 HORIZONTAL TAB (HT) and between 0 and 3 M-0001 VIRTUAL\n * SPACE (VS) characters, depending on the column at which the tab occurred.\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownSpace(code) {\n  return code === -2 || code === -1 || code === 32\n}\n\n// Size note: removing ASCII from the regex and using `asciiPunctuation` here\n// In fact adds to the bundle size.\n/**\n * Check whether the character code represents Unicode punctuation.\n *\n * A **Unicode punctuation** is a character in the Unicode `Pc` (Punctuation,\n * Connector), `Pd` (Punctuation, Dash), `Pe` (Punctuation, Close), `Pf`\n * (Punctuation, Final quote), `Pi` (Punctuation, Initial quote), `Po`\n * (Punctuation, Other), or `Ps` (Punctuation, Open) categories, or an ASCII\n * punctuation (see `asciiPunctuation`).\n *\n * See:\n * **\\[UNICODE]**:\n * [The Unicode Standard](https://www.unicode.org/versions/).\n * Unicode Consortium.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const unicodePunctuation = regexCheck(unicodePunctuationRegex)\n\n/**\n * Check whether the character code represents Unicode whitespace.\n *\n * Note that this does handle micromark specific markdown whitespace characters.\n * See `markdownLineEndingOrSpace` to check that.\n *\n * A **Unicode whitespace** is a character in the Unicode `Zs` (Separator,\n * Space) category, or U+0009 CHARACTER TABULATION (HT), U+000A LINE FEED (LF),\n * U+000C (FF), or U+000D CARRIAGE RETURN (CR) (**\\[UNICODE]**).\n *\n * See:\n * **\\[UNICODE]**:\n * [The Unicode Standard](https://www.unicode.org/versions/).\n * Unicode Consortium.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const unicodeWhitespace = regexCheck(/\\s/)\n\n/**\n * Create a code check from a regex.\n *\n * @param {RegExp} regex\n * @returns {(code: Code) => boolean}\n */\nfunction regexCheck(regex) {\n  return check\n\n  /**\n   * Check whether a code matches the bound regex.\n   *\n   * @param {Code} code\n   *   Character code.\n   * @returns {boolean}\n   *   Whether the character code matches the bound regex.\n   */\n  function check(code) {\n    return code !== null && regex.test(String.fromCharCode(code))\n  }\n}\n","// This module is generated by `script/`.\n//\n// CommonMark handles attention (emphasis, strong) markers based on what comes\n// before or after them.\n// One such difference is if those characters are Unicode punctuation.\n// This script is generated from the Unicode data.\n\n/**\n * Regular expression that matches a unicode punctuation character.\n */\nexport const unicodePunctuationRegex =\n  /[!-\\/:-@\\[-`\\{-~\\xA1\\xA7\\xAB\\xB6\\xB7\\xBB\\xBF\\u037E\\u0387\\u055A-\\u055F\\u0589\\u058A\\u05BE\\u05C0\\u05C3\\u05C6\\u05F3\\u05F4\\u0609\\u060A\\u060C\\u060D\\u061B\\u061D-\\u061F\\u066A-\\u066D\\u06D4\\u0700-\\u070D\\u07F7-\\u07F9\\u0830-\\u083E\\u085E\\u0964\\u0965\\u0970\\u09FD\\u0A76\\u0AF0\\u0C77\\u0C84\\u0DF4\\u0E4F\\u0E5A\\u0E5B\\u0F04-\\u0F12\\u0F14\\u0F3A-\\u0F3D\\u0F85\\u0FD0-\\u0FD4\\u0FD9\\u0FDA\\u104A-\\u104F\\u10FB\\u1360-\\u1368\\u1400\\u166E\\u169B\\u169C\\u16EB-\\u16ED\\u1735\\u1736\\u17D4-\\u17D6\\u17D8-\\u17DA\\u1800-\\u180A\\u1944\\u1945\\u1A1E\\u1A1F\\u1AA0-\\u1AA6\\u1AA8-\\u1AAD\\u1B5A-\\u1B60\\u1B7D\\u1B7E\\u1BFC-\\u1BFF\\u1C3B-\\u1C3F\\u1C7E\\u1C7F\\u1CC0-\\u1CC7\\u1CD3\\u2010-\\u2027\\u2030-\\u2043\\u2045-\\u2051\\u2053-\\u205E\\u207D\\u207E\\u208D\\u208E\\u2308-\\u230B\\u2329\\u232A\\u2768-\\u2775\\u27C5\\u27C6\\u27E6-\\u27EF\\u2983-\\u2998\\u29D8-\\u29DB\\u29FC\\u29FD\\u2CF9-\\u2CFC\\u2CFE\\u2CFF\\u2D70\\u2E00-\\u2E2E\\u2E30-\\u2E4F\\u2E52-\\u2E5D\\u3001-\\u3003\\u3008-\\u3011\\u3014-\\u301F\\u3030\\u303D\\u30A0\\u30FB\\uA4FE\\uA4FF\\uA60D-\\uA60F\\uA673\\uA67E\\uA6F2-\\uA6F7\\uA874-\\uA877\\uA8CE\\uA8CF\\uA8F8-\\uA8FA\\uA8FC\\uA92E\\uA92F\\uA95F\\uA9C1-\\uA9CD\\uA9DE\\uA9DF\\uAA5C-\\uAA5F\\uAADE\\uAADF\\uAAF0\\uAAF1\\uABEB\\uFD3E\\uFD3F\\uFE10-\\uFE19\\uFE30-\\uFE52\\uFE54-\\uFE61\\uFE63\\uFE68\\uFE6A\\uFE6B\\uFF01-\\uFF03\\uFF05-\\uFF0A\\uFF0C-\\uFF0F\\uFF1A\\uFF1B\\uFF1F\\uFF20\\uFF3B-\\uFF3D\\uFF3F\\uFF5B\\uFF5D\\uFF5F-\\uFF65]/\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  /** @type {Token} */\n  let previous\n  return contentStart\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, contentStart, 'linePrefix')\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter('paragraph')\n    return lineStart(code)\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter('chunkText', {\n      contentType: 'text',\n      previous\n    })\n    if (previous) {\n      previous.next = token\n    }\n    previous = token\n    return data(code)\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit('chunkText')\n      effects.exit('paragraph')\n      effects.consume(code)\n      return\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit('chunkText')\n      return lineStart\n    }\n\n    // Data.\n    effects.consume(code)\n    return data\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n}\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeDocument(effects) {\n  const self = this\n  /** @type {Array<StackItem>} */\n  const stack = []\n  let continued = 0\n  /** @type {TokenizeContext | undefined} */\n  let childFlow\n  /** @type {Token | undefined} */\n  let childToken\n  /** @type {number} */\n  let lineStartOffset\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued]\n      self.containerState = item[1]\n      return effects.attempt(\n        item[0].continuation,\n        documentContinue,\n        checkNewContainers\n      )(code)\n    }\n\n    // Done.\n    return checkNewContainers(code)\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined\n      if (childFlow) {\n        closeFlow()\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          point = self.events[indexBeforeFlow][1].end\n          break\n        }\n      }\n      exitContainers(continued)\n\n      // Fix positions.\n      let index = indexBeforeExits\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n      return checkNewContainers(code)\n    }\n    return start(code)\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code)\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code)\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(\n        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack\n      )\n    }\n\n    // Check if there is a new container.\n    self.containerState = {}\n    return effects.check(\n      containerConstruct,\n      thereIsANewContainer,\n      thereIsNoNewContainer\n    )(code)\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow()\n    exitContainers(continued)\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length\n    lineStartOffset = self.now().offset\n    return flowStart(code)\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++\n    stack.push([self.currentConstruct, self.containerState])\n    // Try another.\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow()\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n    return flowContinue(code)\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit('chunkFlow'), true)\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      writeToChild(effects.exit('chunkFlow'))\n      // Get ready for the next line.\n      continued = 0\n      self.interrupt = undefined\n      return start\n    }\n    effects.consume(code)\n    return flowContinue\n  }\n\n  /**\n   * @param {Token} token\n   * @param {boolean | undefined} [eof]\n   * @returns {void}\n   */\n  function writeToChild(token, eof) {\n    const stream = self.sliceStream(token)\n    if (eof) stream.push(null)\n    token.previous = childToken\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.defineSkip(token.start)\n    childFlow.write(stream)\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length\n      while (index--) {\n        if (\n          // The token starts before the line ending…\n          childFlow.events[index][1].start.offset < lineStartOffset &&\n          // …and either is not ended yet…\n          (!childFlow.events[index][1].end ||\n            // …or ends after it.\n            childFlow.events[index][1].end.offset > lineStartOffset)\n        ) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {boolean | undefined} */\n      let seen\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end\n            break\n          }\n          seen = true\n        }\n      }\n      exitContainers(continued)\n\n      // Fix positions.\n      index = indexBeforeExits\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n    }\n  }\n\n  /**\n   * @param {number} size\n   * @returns {void}\n   */\n  function exitContainers(size) {\n    let index = stack.length\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index]\n      self.containerState = entry[1]\n      entry[0].exit.call(self, effects)\n    }\n    stack.length = size\n  }\n  function closeFlow() {\n    childFlow.write([null])\n    childToken = undefined\n    childFlow = undefined\n    self.containerState._closeFlow = undefined\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4\n  )\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {blankLine, content} from 'micromark-core-commonmark'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeFlow(effects) {\n  const self = this\n  const initial = effects.attempt(\n    // Try to parse a blank line.\n    blankLine,\n    atBlankEnding,\n    // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        'linePrefix'\n      )\n    )\n  )\n  return initial\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEndingBlank')\n    effects.consume(code)\n    effects.exit('lineEndingBlank')\n    self.currentConstruct = undefined\n    return initial\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Create} Create\n * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').ParseOptions} ParseOptions\n */\n\nimport {combineExtensions} from 'micromark-util-combine-extensions'\nimport {content} from './initialize/content.js'\nimport {document} from './initialize/document.js'\nimport {flow} from './initialize/flow.js'\nimport {text, string} from './initialize/text.js'\nimport {createTokenizer} from './create-tokenizer.js'\nimport * as defaultConstructs from './constructs.js'\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n * @returns {ParseContext}\n */\nexport function parse(options) {\n  const settings = options || {}\n  const constructs =\n    /** @type {FullNormalizedExtension} */\n    combineExtensions([defaultConstructs, ...(settings.extensions || [])])\n\n  /** @type {ParseContext} */\n  const parser = {\n    defined: [],\n    lazy: {},\n    constructs,\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(string),\n    text: create(text)\n  }\n  return parser\n\n  /**\n   * @param {InitialConstruct} initial\n   */\n  function create(initial) {\n    return creator\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from)\n    }\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Value} Value\n */\n\n/**\n * @callback Preprocessor\n * @param {Value} value\n * @param {Encoding | null | undefined} [encoding]\n * @param {boolean | null | undefined} [end=false]\n * @returns {Array<Chunk>}\n */\n\nconst search = /[\\0\\t\\n\\r]/g\n\n/**\n * @returns {Preprocessor}\n */\nexport function preprocess() {\n  let column = 1\n  let buffer = ''\n  /** @type {boolean | undefined} */\n  let start = true\n  /** @type {boolean | undefined} */\n  let atCarriageReturn\n  return preprocessor\n\n  /** @type {Preprocessor} */\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = []\n    /** @type {RegExpMatchArray | null} */\n    let match\n    /** @type {number} */\n    let next\n    /** @type {number} */\n    let startPosition\n    /** @type {number} */\n    let endPosition\n    /** @type {Code} */\n    let code\n\n    // @ts-expect-error `Buffer` does allow an encoding.\n    value = buffer + value.toString(encoding)\n    startPosition = 0\n    buffer = ''\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++\n      }\n      start = undefined\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition =\n        match && match.index !== undefined ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5)\n          atCarriageReturn = undefined\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n        switch (code) {\n          case 0: {\n            chunks.push(65533)\n            column++\n            break\n          }\n          case 9: {\n            next = Math.ceil(column / 4) * 4\n            chunks.push(-2)\n            while (column++ < next) chunks.push(-1)\n            break\n          }\n          case 10: {\n            chunks.push(-4)\n            column = 1\n            break\n          }\n          default: {\n            atCarriageReturn = true\n            column = 1\n          }\n        }\n      }\n      startPosition = endPosition + 1\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5)\n      if (buffer) chunks.push(buffer)\n      chunks.push(null)\n    }\n    return chunks\n  }\n}\n"],"names":["postprocess","events","subtokenize","resolver","resolveAll","createResolver","string","initializeFactory","text","field","tokenize","effects","self","this","constructs","parser","attempt","start","notText","code","atBreak","enter","consume","data","exit","list","index","length","item","previous","call","resolveAllLineSuffixes","undefined","extraResolver","context","type","end","splice","eventIndex","chunks","sliceStream","tabs","bufferIndex","size","chunk","charCodeAt","token","line","column","offset","_index","_bufferIndex","Object","assign","regexCheck","markdownLineEnding","regex","test","String","fromCharCode","content","contentStart","contentInitial","factorySpace","lineStart","contentType","next","document","stack","childFlow","childToken","lineStartOffset","continued","containerState","continuation","documentContinue","checkNewContainers","_closeFlow","closeFlow","indexBeforeExits","point","indexBeforeFlow","exitContainers","slice","documentContinued","currentConstruct","concrete","flowStart","interrupt","Boolean","_gfmTableDynamicInterruptHack","check","containerConstruct","thereIsANewContainer","thereIsNoNewContainer","lazy","now","containerContinue","push","flow","_tokenizer","flowContinue","writeToChild","eof","stream","defineSkip","write","seen","entry","ok","nok","disable","null","includes","initial","blankLine","flowInitial","afterConstruct","parse","options","settings","defined","combineExtensions","defaultConstructs","extensions","create","from","createTokenizer","search","preprocess","atCarriageReturn","buffer","value","encoding","match","startPosition","endPosition","toString","lastIndex","exec","Math","ceil"],"sourceRoot":""}