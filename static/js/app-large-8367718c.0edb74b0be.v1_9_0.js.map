{"version":3,"file":"static/js/app-large-8367718c.0edb74b0be.v1_9_0.js","mappings":"2LAGA,MAAMA,GAAiBC,EAAAA,EAAAA,IAAc,MAKxBC,EAAkBC,IAAmB,IAAlB,SAAEC,GAAUD,EAC1C,MAAOE,EAAYC,IAAiBC,EAAAA,EAAAA,IAAS,CAAC,GAExCC,GAAaC,EAAAA,EAAAA,KAAY,CAACC,EAAKC,KACnCL,GAAcM,IAAI,IAAUA,EAAM,CAACF,GAAMC,KAAa,GACrD,IAEGA,GAAYF,EAAAA,EAAAA,KAAYC,KAASL,EAAWK,IAAM,CAACL,IACnDQ,EAAaC,OAAOC,OAAOV,GAAYW,MAAKC,GAAOA,IAEzD,OACEC,EAAAA,EAAAA,GAAClB,EAAemB,SAAQ,CAACC,MAAO,CAAEZ,aAAYG,YAAWE,cAAaT,SACnEA,GACuB,EASjBiB,EAAcX,IACzB,MAAMY,GAAUC,EAAAA,EAAAA,IAAWvB,GAC3B,IAAKsB,EAAS,MAAM,IAAIE,MAAM,kDAC9B,MAAM,WAAEhB,EAAU,UAAEG,GAAcW,EAC5BG,GAAehB,EAAAA,EAAAA,KAAY,IAAMD,EAAWE,GAAK,IAAO,CAACF,EAAYE,IACrEgB,GAAcjB,EAAAA,EAAAA,KAAY,IAAMD,EAAWE,GAAK,IAAQ,CAACF,EAAYE,IAC3E,MAAO,CAACC,EAAUD,GAAMe,EAAcC,EAAY,C,4LCtBpD,MAAMC,GAAyB1B,EAAAA,EAAAA,MAElB2B,EAAqBA,KAChC,MAAMN,GAAUC,EAAAA,EAAAA,IAAWI,GAC3B,QAAgBE,IAAZP,EACF,MAAM,IAAIE,MAAM,oEAElB,OAAOF,CAAO,EAGHQ,EAA0B3B,IAAmB,IAAlB,SAAEC,GAAUD,EAClD,MAAM,OAAE4B,IAAWC,EAAAA,EAAAA,MACb,cAAEC,IAAkBC,EAAAA,EAAAA,OACpB,yBAAEC,IAA6BC,EAAAA,EAAAA,MAC/B,QAAEC,IAAYC,EAAAA,EAAAA,MACd,eAAEC,EAAc,eAAEC,EAAc,oBAAEC,EAAmB,sBAAEC,IAA0BC,EAAAA,EAAAA,MACjF,wBAAEC,EAAuB,SAAEC,IAAaC,EAAAA,EAAAA,MACxC,wBAAEC,EAAuB,sBAAEC,EAAqB,yBAAEC,IAA6BC,EAAAA,EAAAA,KAG/EC,GAAmBC,EAAAA,EAAAA,IAAO,IAC1BC,GAAsBD,EAAAA,EAAAA,IAAO,MAC7BE,GAAqBF,EAAAA,EAAAA,IAAO,MAC5BG,GAAiBH,EAAAA,EAAAA,KAAO,GACxBI,GAAwBJ,EAAAA,EAAAA,KAAO,GAG/BK,GAAsBC,EAAAA,EAAAA,KAC1B,IAAMC,KAAUC,GAAYlB,EAAsBkB,IAAU,KAC5D,CAAClB,IAKGmB,IADqBT,EAAAA,EAAAA,IAAO,OACVA,EAAAA,EAAAA,IAAO,OACzBU,GAA0BrD,EAAAA,EAAAA,KAAY,KACrCoD,EAAgBE,UACnBF,EAAgBE,QAAU,IAAIC,EAAAA,GAEzBH,EAAgBE,UACtB,IAEGE,GAAmBxD,EAAAA,EAAAA,KAAayD,GAAU,IAAIC,SAAQ,CAACC,EAASC,KACpE,MAAMC,EAASR,IACfQ,EAAOC,UAAaC,GAAMJ,EAAQI,EAAEC,MACpCH,EAAOI,QAAUL,EACjBC,EAAOK,YAAYT,EAAM,KACvB,CAACJ,IAGCc,GAAyBnE,EAAAA,EAAAA,KAAYoE,eAAOC,GAA+B,IAAtBC,EAASC,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,KAErE,MAAME,EAA+B,oBAAXC,QAA0BA,OAAOC,WACvDD,OAAOC,aACPC,KAAKC,SAASC,SAAS,IAAIC,UAAU,GAAKC,KAAKC,MAAMH,SAAS,IAClElC,EAAoBU,QAAUmB,EAC9B,MAAMS,EAA0B,OAAdZ,GAAsBa,OAAOC,UAAUd,IAAcA,GAAa,EACpF,IAAKD,IAAY7C,EAEf,OADAY,EAAS,6CACF,KAET,MAAMiD,EAAU,GAAG7D,EAAc8D,YAAY9D,EAAc+D,KAC3D,IAAKF,EAEH,OADAjD,EAAS,2BACF,KAET,IAAIoD,EACAN,EACFnD,GAAe5B,IACb,MAAMsF,EAAYtF,EAAKuF,MAAM,EAAGpB,GAC1BqB,EAAWxF,EAAKmE,GAGtB,OADAkB,EAAc,IAAKG,EAAUxC,QAASkB,GAC/B,IAAIoB,EAAWD,EAAY,IAGpCA,EAAcxD,EAAoB,OAAQqC,GAE5C/B,IACAC,IACAQ,EAAsBO,SAAU,EAChCnB,GAAwB,GACxBC,EAAS,MACTM,EAAiBY,QAAU,GAC3BR,EAAeQ,SAAU,EACzBtB,EAAoB,YAAa,IACjC,IAAI4D,EAAYC,YAAW,KAAO,IAADC,EACL,QAA1BA,EAAAjD,EAAmBS,eAAO,IAAAwC,GAA1BA,EAA4BC,MAAM,WAClC3D,EAAS,wBACTD,GAAwB,EAAM,GAC7B,KACH,MAAM6D,EAAkB,IAAIC,gBAC5BpD,EAAmBS,QAAU0C,EAC7B,IACE,MAAME,EAAWxE,EAAyBF,GAEpC2E,EAAgBrE,EAAewB,QAClCoC,MAAM,GAAI,GACVU,KAAIC,IAAA,IAAC,QAAEC,KAAYC,GAAGF,EAAA,OAAKE,CAAC,KAC3BL,EAASM,cAAkBL,EAAc3B,QAAoC,WAA1B2B,EAAc,GAAGM,MACtEN,EAAcO,QAAQ,CAAED,KAAM,SAAUtD,QAAS+C,EAASM,aAAcG,UAAW3B,KAAKC,MAAQ,IAElG,MAAM2B,EAAU,CACdnC,YACAoC,MAAOxB,EACPyB,SAAUX,EACVY,YAAab,EAASa,YACtBC,WAAYd,EAASc,WACrBC,MAAOf,EAASe,MAChBC,kBAAmBhB,EAASgB,kBAC5BC,iBAAkBjB,EAASiB,kBAEvBC,EAAU,CAAE,eAAgB,mBAAoB,OAAU,oBAAqB,gBAAiB,YAClGxF,IAASwF,EAAuB,cAAI,UAAUxF,KAClD,MAAMyF,QAAiBC,EAAAA,EAAAA,GAAe,IAAIC,IAAI,mBAAoBjG,GAAQwD,WAAY,CACpF0C,OAAQ,OAAQJ,UAASK,KAAMC,KAAKC,UAAUf,GAAUgB,OAAQ5B,EAAgB4B,OAAQC,MAAO,aAEjG,IAAKR,EAASS,GAAI,MAAM,IAAI/G,MAAM,cAAcsG,EAASU,UACzD,MAAMC,EAASX,EAASI,KAAKQ,YACvBC,EAAU,IAAIC,YAAY,SAChC,IAAIC,EAAqB,GACzB,OAAa,CACX,MAAM,KAAEC,EAAI,MAAE1H,SAAgBqH,EAAOM,OAOrC,GANAC,aAAa3C,GACbA,EAAYC,YAAW,KAAO,IAAD2C,EACD,QAA1BA,EAAA3F,EAAmBS,eAAO,IAAAkF,GAA1BA,EAA4BzC,QAC5B3D,EAAS,wBACTD,GAAwB,EAAM,GAC7B,KACCkG,EAEF,MAEF,MAAM5E,EAAQyE,EAAQO,OAAO9H,EAAO,CAAE+H,QAAQ,IAI9C,IACE,MAAMC,QAAanF,EAAiBC,GACpC,IAAK,MAAMmF,KAAOD,EAAM,CAAC,IAADE,EAAAC,EAAAC,EAEtB,GAAgB,QAAZF,EAAAD,EAAII,gBAAQ,IAAAH,GAAZA,EAAcI,OAA8B,UAArBL,EAAIM,aAA0B,CAAC,IAADC,EAAAC,EACvD,MAAMC,GAAqB,QAAZF,EAAAP,EAAII,gBAAQ,IAAAG,GAAO,QAAPC,EAAZD,EAAcF,aAAK,IAAAG,OAAP,EAAZA,EAAqB/E,UAAW,mCAe/C,OAbAjC,EAASiH,GACTtH,GAAe5B,IACb,MAAMmJ,EAAa,IAAInJ,GACjBoJ,EAAUD,EAAWA,EAAW9E,OAAS,GAQ/C,OAPI+E,GAA4B,cAAjBA,EAAQ9C,OACrB8C,EAAQpG,SAAW,kBAAkBkG,IACjCE,EAAQjD,UACViD,EAAQjD,QAAQkD,YAAa,EAC7BD,EAAQjD,QAAQ2C,OAAQ,IAGrBK,CAAU,IAEZ,IACT,CAEIV,EAAIzF,UAEDJ,EAAsBO,UACzBd,EAAyB,GACzBO,EAAsBO,SAAU,GAElC8E,GAAsBQ,EAAIzF,QAC1BT,EAAiBY,QAAU8E,EAC3BpF,EAAoBoF,IAGtB,MAAMqB,EAA8C,QAA9BX,EAAY,QAAZC,EAAGH,EAAIc,aAAK,IAAAX,OAAA,EAATA,EAAWU,wBAAgB,IAAAX,EAAAA,EAAI,EACxDtG,EAAyBiH,EAAkBb,EAAIe,OAAQf,EAAIc,MAAOd,EAAIM,aACxE,CACF,CAAE,MAAO,CACX,CAGA,OAFAlG,EAAoB4G,QACpB3H,EAAsBS,EAAiBY,SAChCZ,EAAiBY,OAC1B,CAAE,MAAO2F,GAgBP,OAdA7G,EAAS6G,EAAM5E,SAEftC,GAAe5B,IACb,MAAMmJ,EAAa,IAAInJ,GACjBoJ,EAAUD,EAAWA,EAAW9E,OAAS,GAQ/C,OAPI+E,GAA4B,cAAjBA,EAAQ9C,OACrB8C,EAAQpG,SAAW,kBAAkB8F,EAAM5E,SAAW,qCAClDkF,EAAQjD,UACViD,EAAQjD,QAAQkD,YAAa,EAC7BD,EAAQjD,QAAQ2C,OAAQ,IAGrBK,CAAU,IAEZ,IACT,CAAC,QACCf,aAAa3C,GACb9C,EAAeQ,SAAU,EACzBnB,GAAwB,GAExBS,EAAoBU,QAAU,IAChC,CACF,GAAG,CACDhC,EAAQE,EAAeE,EAA0BE,EACjDE,EAAgBC,EAAgBC,EAAqBC,EACrDe,EAAqBZ,EAAUD,EAC/BG,EAAyBC,EAAuBC,EAChDgB,IAGIqG,GAAgB7J,EAAAA,EAAAA,KAAYoE,UAC5BvB,EAAmBS,SAAST,EAAmBS,QAAQyC,MAAM,gBACjE,MAAM+D,EAAQlH,EAAoBU,QAClC,GAAIwG,EAAO,CACT,MAAM1C,EAAU,CAAE,eAAgB,oBAC9BxF,IAASwF,EAAuB,cAAI,UAAUxF,KAClD,UACQ0F,EAAAA,EAAAA,GAAe,IAAIC,IAAI,iBAAkBjG,GAAQwD,WAAY,CACjE0C,OAAQ,OAAQJ,UAASK,KAAMC,KAAKC,UAAU,CAAElD,UAAWqF,KAE/D,CAAE,MAAO,CAAC,QACRlH,EAAoBU,QAAU,KAC9BT,EAAmBS,QAAU,IAC/B,CACF,CAGA,OAFAR,EAAeQ,SAAU,EACzBnB,GAAwB,IACjB,CAAI,GACV,CAACb,EAAQM,EAASO,IAEfxB,GAAQsC,EAAAA,EAAAA,KAAQ,MACpBkB,yBACA0F,gBACArG,mBACAd,mBACAqH,YAAaA,IAAMjH,EAAeQ,WAChC,CAACa,EAAwB0F,EAAerG,IAE5C,OACE/C,EAAAA,EAAAA,GAACS,EAAuBR,SAAQ,CAACC,MAAOA,EAAMhB,SAC3CA,GAC+B,C,+EC5PtC,MAAMqK,EAAmB,CACvBjD,YAAa,GACbE,MAAO,EACPD,WAAY,KACZE,kBAAmB,EACnBC,iBAAkB,EAClB8C,WAAW,EACXzD,aAAc,45CAyBV0D,GAAkB1K,EAAAA,EAAAA,MAGXmC,EAAcA,KACzB,MAAMd,GAAUC,EAAAA,EAAAA,IAAWoJ,GAC3B,QAAgB9I,IAAZP,EACF,MAAM,IAAIE,MAAM,sDAElB,OAAOF,CAAO,EAIHsJ,EAAmBzK,IAAmB,IAAlB,SAAEC,GAAUD,EAE3C,MAAO0K,EAAUC,IAAeC,EAAAA,EAAAA,GAAgB,cAAeN,GAGzDO,GAAgBvK,EAAAA,EAAAA,KAAY,CAACwK,EAAK7J,KAElC6J,KAAOR,GACTK,GAAYlK,IAAI,IACXA,EACH,CAACqK,GAAM7J,KAEX,GACC,CAAC0J,IAGEI,GAAgBzK,EAAAA,EAAAA,KAAY,KAChCqK,EAAYL,EAAiB,GAC5B,CAACK,IAGEK,GAA4B1K,EAAAA,EAAAA,KAAa6G,KACxCA,KAKgC,IAAnCA,EAAM8D,0BACL9D,EAAM+D,YAAc/D,EAAM+D,WAAWC,SAAS,sBAC9ChE,EAAMtB,IAAMsB,EAAMtB,GAAGuF,cAAcC,WAAW,MAC9ClE,EAAMmE,QAAyC,aAA/BnE,EAAMmE,OAAOF,gBAE/B,IAGGpJ,GAA2B1B,EAAAA,EAAAA,KAAa6G,GACxC6D,EAA0B7D,GACrB,IACFuD,EACHrD,YAAa,GAGVqD,GACN,CAACA,EAAUM,IAGR/J,GAAQsC,EAAAA,EAAAA,KAAQ,MACpBmH,WACAG,gBACAE,gBACAC,4BACAhJ,8BACE,CACF0I,EACAG,EACAE,EACAC,EACAhJ,IAGF,OACEjB,EAAAA,EAAAA,GAACyJ,EAAgBxJ,SAAQ,CAACC,MAAOA,EAAMhB,SACpCA,GACwB,C,gJCtG/B,MAGMsL,GAAezL,EAAAA,EAAAA,MACf0L,GAAqB1L,EAAAA,EAAAA,MAGdiC,EAAWA,KACtB,MAAMZ,GAAUC,EAAAA,EAAAA,IAAWmK,GAC3B,QAAgB7J,IAAZP,EACF,MAAM,IAAIE,MAAM,gDAElB,OAAOF,CAAO,EAIHsK,EAAiBA,KAC5B,MAAMtK,GAAUC,EAAAA,EAAAA,IAAWoK,GAC3B,QAAgB9J,IAAZP,EACF,MAAM,IAAIE,MAAM,sDAElB,OAAOF,CAAO,EAIHuK,EAAgB1L,IAAmB,IAAlB,SAAEC,GAAUD,EACxC,MAAM,aAAE2L,IAAiBC,EAAAA,EAAAA,MACnB,OAAEhK,IAAWC,EAAAA,EAAAA,MACb,QAAEK,IAAYC,EAAAA,EAAAA,MACd,UAAE0J,IAAcC,EAAAA,EAAAA,MAGfC,EAAWC,IAAgB5L,EAAAA,EAAAA,IAAS,KACpC6L,EAAiBC,IAAsB9L,EAAAA,EAAAA,IAAS,CAAC,IACjD+L,EAAoBC,IAAyBhM,EAAAA,EAAAA,IAAS,KACtD0B,EAAeuK,IAAoBzB,EAAAA,EAAAA,GAAgB,gBAAiB,OACpEpK,EAAW8L,IAAgBlM,EAAAA,EAAAA,KAAS,IACpCmJ,EAAO7G,IAAYtC,EAAAA,EAAAA,IAAS,OAG5BmM,EAAkBC,IAAuB5B,EAAAA,EAAAA,GAAgB,oBAAoB,IAC7E6B,EAAaC,IAAkBtM,EAAAA,EAAAA,IAAS,CAC7CuM,OAAQ,GACRC,WAAY,CACV,MAAQ,EACR,OAAS,EACT,WAAa,MAKV,CAAEC,EAAoBC,IAAqB5L,EAAAA,EAAAA,IAAW,WAC7D6L,EAAAA,EAAAA,KAAU,KACJvM,EAAWqM,IACVC,GAAmB,GACvB,CAACtM,EAAWqM,EAAoBC,IAGnC,MAAME,GAAe1M,EAAAA,EAAAA,KAAa6H,GAE9BA,GACAA,EAAMlB,WACN3B,KAAKC,MAAQ4C,EAAMlB,UA9DC,OA+DpBkB,EAAM4D,WACN5D,EAAM8D,iBACN9D,EAAMgE,oBAEP,KAGHY,EAAAA,EAAAA,KAAU,KAER,GAAsB,oBAAXE,OAGX,OAFAA,OAAOD,aAAeA,EAEf,YACEC,OAAOD,YAAY,CAC3B,GACA,CAACA,IAGJ,MAAME,GAAc5M,EAAAA,EAAAA,KAAagE,IAC/B,IACE,MAAM6D,EAAQ,CACZ4D,UAAWzH,EAAKyH,UAChBE,gBAAiB3H,EAAK2H,gBACtBE,mBAAoB7H,EAAK6H,mBACzBlF,UAAW3B,KAAKC,OAGlB4H,aAAaC,QAAQ,qBAAsBpF,KAAKC,UAAUE,GAC5D,CAAE,MAAOoB,GAET,IACC,IAGG8D,GAAuB/M,EAAAA,EAAAA,KAAY,CAACgN,EAAUC,KAClDb,GAAejM,IAAI,IACdA,EACHmM,WAAY,IACPnM,EAAKmM,WACR,CAACU,GAAWC,MAEb,GACF,IAGGC,GAAqBlN,EAAAA,EAAAA,KAAamN,IACtCf,GAAejM,IAAI,IACdA,EACHkM,OAAQc,KACP,GACF,IAGGC,GAAcpN,EAAAA,EAAAA,KAAa6G,KAE3BrF,aAAa,EAAbA,EAAe+D,OAAOsB,aAAK,EAALA,EAAOtB,KAC/BwG,EAAiBlF,EACnB,GACC,CAACrF,EAAeuK,IAGbsB,GAAcrN,EAAAA,EAAAA,KAAYoE,iBAAuD,IAAhDkJ,EAAY/I,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,IAAAA,UAAA,GAAUgJ,EAAahJ,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,KAC3EyH,GAAa,GACb5J,EAAS,MAGT,IACE,MAAMgF,EAAU,CAAE,OAAU,oBAC5B,GAAIkG,EAAc,CAEhB,MAAME,EAAaD,GAAiB3L,EAChC4L,IACFpG,EAAuB,cAAI,UAAUoG,IAEzC,CACA,MAAMC,EAAY,IAAIlG,IAAI,yBAA0BjG,GAAQwD,WACtDuC,QAAiBqG,MAAMD,EAAW,CAAErG,YAG1C,IAAKC,EAASS,GAAI,CAChB,IAAI6F,EAAW,0BAA0BtG,EAASU,SAElD,MAAM,IAAIhH,MAAM4M,EAClB,CAEA,MAAMC,QAAgBvG,EAASwG,OAIzBhK,EAAS,IAAIiK,OAAO,IAAIvG,IAAI,gBAAkD,CAAEwG,UAAM,IAC5FlK,EAAOK,YAAY0J,GACnB/J,EAAOC,UAAYuC,IAAoB,IAAjBrC,KAAM4E,GAAKvC,EAC/B,GAAIuC,EAAIK,MAEN7G,EAASwG,EAAIK,OACbsC,EAAU,CAAEwC,KAAM,QAAS1J,QAASuE,EAAIK,YACnC,CACL,MACEwC,UAAWuC,EACXrC,gBAAiBsC,EACjBpC,mBAAoBqC,GAClBtF,EACJ,GAAIyC,EAAc,CAChB,MAAM8C,EAAUtB,aAAauB,QAAQ,sBACrC,IAAIC,EACJ,IAAMA,EAAY3G,KAAK4G,MAAMH,EAAU,CAAE,MAAQE,EAAY,IAAM,GAClDA,GACf3G,KAAKC,UAAU0G,EAAU5C,aAAe/D,KAAKC,UAAUqG,IACvDtG,KAAKC,UAAU0G,EAAU1C,mBAAqBjE,KAAKC,UAAUsG,IAC7DvG,KAAKC,UAAU0G,EAAUxC,sBAAwBnE,KAAKC,UAAUuG,MAEhExC,EAAasC,GACbpC,EAAmBqC,GACnBnC,EAAsBoC,GACtBtB,EAAY,CAAEnB,UAAWuC,EAAkBrC,gBAAiBsC,EAAwBpC,mBAAoBqC,IAE5G,MACExC,EAAasC,GACbpC,EAAmBqC,GACnBnC,EAAsBoC,EAG1B,CACAlC,GAAa,GACbnI,EAAO0K,WAAW,EAEpB1K,EAAOI,QAAWuK,IAEhBpM,EAASoM,EAAInK,SACbkH,EAAU,CAAEwC,KAAM,QAAS1J,QAASmK,EAAInK,UACxC2H,GAAa,GACbnI,EAAO0K,WAAW,CAEtB,CAAE,MAAOC,GAEPpM,EAASoM,EAAInK,SAAW,6BACxBkH,EAAU,CAAEwC,KAAM,QAAS1J,QAASmK,EAAInK,SAAW,6BAErD,CACF,GAAG,CAAC/C,EAAQsL,EAAahL,EAASyJ,EAAcE,IAG1CkD,GAAsB9L,EAAAA,EAAAA,KAAO,GAE7B+L,GAAkB/L,EAAAA,EAAAA,KAAO,IAE/B8J,EAAAA,EAAAA,KAAU,KACR,IAAKgC,EAAoBnL,QAAS,CAChC,GAAI+H,EAAc,CAChB,MAAMsD,EAAW9B,aAAauB,QAAQ,sBACtC,IAAIQ,EACJ,IAAMA,EAAclH,KAAK4G,MAAMK,EAAW,CAAE,MAAQC,EAAc,IAAM,CACpEA,GAAejC,OAAOD,aAAakC,KACrClD,EAAakD,EAAYnD,WACzBG,EAAmBgD,EAAYjD,iBAC/BG,EAAsB8C,EAAY/C,oBAClCG,GAAa,GAEjB,CACA,IAAI6C,EAAc,KAClB,IAAMA,EAAchC,aAAauB,QAAQ,UAAY,CAAE,MAAO,CAC1DS,GAEFH,EAAgBpL,SAAU,EAC1B+J,GAAY,EAAMwB,IAGlBxB,GAAY,GAEdoB,EAAoBnL,SAAU,CAChC,IAEC,KAGHmJ,EAAAA,EAAAA,KAAU,KAEJgC,EAAoBnL,SAAW1B,IAAY8M,EAAgBpL,UAC7DoL,EAAgBpL,SAAU,EAC1B+J,GAAY,GACd,GACC,CAACzL,EAASyL,KAGbZ,EAAAA,EAAAA,KAAU,MAEHjL,GAAiBiK,EAAUjH,OAAS,GACvCuH,EAAiBN,EAAU,GAC7B,GACC,CAACA,EAAWjK,EAAeuK,IAG9B,MAAM+C,GAA2B9O,EAAAA,EAAAA,KAAY,KAC3CkM,GAAoB/L,IAASA,GAAK,GACjC,CAAC+L,IAGE6C,GAAa9L,EAAAA,EAAAA,KAAQ,MACzBwI,YACAE,kBACAE,qBACArK,gBACAtB,YACA+I,QACAgD,mBACA+C,4BAA6B/C,EAC7B6C,2BACA5C,sBACAkB,cACA6B,cAAe5B,KACb,CACF5B,EACAE,EACAE,EACArK,EACAtB,EACA+I,EACAgD,EACA6C,EACA5C,EACAkB,EACAC,IAII6B,GAAcjM,EAAAA,EAAAA,KAAQ,MAC1BkJ,cACAY,uBACAG,wBACE,CACFf,EACAY,EACAG,IAGF,OACEzM,EAAAA,EAAAA,GAACwK,EAAavK,SAAQ,CAACC,MAAOoO,EAAWpP,UACvCc,EAAAA,EAAAA,GAACyK,EAAmBxK,SAAQ,CAACC,MAAOuO,EAAYvP,SAC7CA,KAEmB,C,gFCpT5B,MAAMwP,GAA4B3P,EAAAA,EAAAA,MAGrBiD,EAAwBA,KACnC,MAAM5B,GAAUC,EAAAA,EAAAA,IAAWqO,GAC3B,QAAgB/N,IAAZP,EACF,MAAM,IAAIE,MAAM,0EAElB,OAAOF,CAAO,EAIHuO,EAA6B1P,IAAmB,IAAlB,SAAEC,GAAUD,EACrD,MAAM,eAAEqC,IAAmBG,EAAAA,EAAAA,MACpBmN,EAAuBC,IAA4BxP,EAAAA,EAAAA,IAAS,CACjEyP,UAAW,KACXC,QAAS,KACTC,YAAa,KACbC,WAAY,KACZC,gBAAiB,KACjBnG,YAAY,EACZoG,iBAAkB,KAClBC,aAAc,KACdpG,iBAAkB,KAClBqG,YAAa,KACb5G,aAAc,OAGV5G,GAA0BtC,EAAAA,EAAAA,KAAY,KAC1CsP,EAAyB,CACvBC,UAAW,KACXC,QAAS,KACTC,YAAa,KACbC,WAAY,KACZC,gBAAiB,KACjBnG,YAAY,EACZoG,iBAAkB,KAClBC,aAAc,KACdpG,iBAAkB,KAClBqG,YAAa,KACb5G,aAAc,MACd,GACD,IAEG3G,GAAwBvC,EAAAA,EAAAA,KAAY,KACxCsP,GAAyBnP,IAAI,IACxBA,EACHoP,UAAWvK,KAAKC,MAChBuE,YAAY,KACX,GACF,IAGGhH,GAA2BxC,EAAAA,EAAAA,KAAY,SAAC+P,GAA8E,IAA/DvG,EAAUjF,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,IAAAA,UAAA,GAAUyL,EAASzL,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,KAAM2E,EAAY3E,UAAAC,OAAA,QAAApD,IAAAmD,UAAA,GAAAA,UAAA,GAAG,KAChH+K,GAAyBnP,IACvB,MAAMqP,EAAUxK,KAAKC,MACfwK,EAActP,EAAKoP,UAAYC,EAAUrP,EAAKoP,UAAY,EAC1DI,EAAkBI,GAAiBN,EACvC7K,KAAKqL,MAAOF,GAAiBN,EAAc,KAAS,IAAM,GAC1DtP,EAAKwP,gBACDC,EAAmBzP,EAAKyP,mBAC3BG,EAAgB,EAAIN,EAAc,MAgBrC,MAdmB,CACjBF,UAAWpP,EAAKoP,UAChBC,UACAC,cACAC,WAAYK,EACZJ,kBACAnG,aACAoG,mBACAC,cAAcG,aAAS,EAATA,EAAWH,eAAgB1P,EAAK0P,aAC9CpG,kBAAkBuG,aAAS,EAATA,EAAWvG,mBAAoBtJ,EAAKsJ,iBACtDqG,aAAaE,aAAS,EAATA,EAAWF,cAAe3P,EAAK2P,YAC5C5G,aAAcA,GAAgB/I,EAAK+I,aAGpB,GAErB,GAAG,KAGHuD,EAAAA,EAAAA,KAAU,KAC6B,MAAjC4C,EAAsBG,SACxBzN,GAAemO,IACb,MAAM5G,EAAa,IAAI4G,GACjB3G,EAAUD,EAAWA,EAAW9E,OAAS,GAI/C,OAHI+E,GAA4B,cAAjBA,EAAQ9C,OACrB8C,EAAQjD,QAAU,IAAK+I,IAElB/F,CAAU,GAErB,GACC,CAAC+F,EAAuBtN,IAG3B,MAAMoO,GAAgCnQ,EAAAA,EAAAA,KAAasG,IACjDvE,GAAemO,IACb,MAAM5G,EAAa,IAAI4G,GACjB3G,EAAUD,EAAWA,EAAW9E,OAAS,GAQ/C,OAPI+E,GAA4B,cAAjBA,EAAQ9C,OACrB8C,EAAQjD,QAAU,IACZiD,EAAQjD,SAAW,CAAC,KACrBA,EACHkD,YAAY,IAGTF,CAAU,GACjB,GACD,CAACvH,IAEEpB,GAAQsC,EAAAA,EAAAA,KAAQ,MACpBoM,wBACA/M,0BACAC,wBACAC,2BACA2N,mCACE,CAACd,EAAuB/M,EAAyBC,EAAuBC,EAA0B2N,IAEtG,OACE1P,EAAAA,EAAAA,GAAC0O,EAA0BzO,SAAQ,CAACC,MAAOA,EAAMhB,SAC9CA,GACkC,C,qEC3HzC,MAAMyQ,GAAe5Q,EAAAA,EAAAA,MAGR6Q,EAAWA,KACtB,MAAMxP,GAAUC,EAAAA,EAAAA,IAAWsP,GAC3B,QAAgBhP,IAAZP,EACF,MAAM,IAAIE,MAAM,gDAElB,OAAOF,CAAO,EAIHyP,EAAgB5Q,IAAmB,IAAlB,SAAEC,GAAUD,EAExC,MAAO6Q,EAAOC,IAAY1Q,EAAAA,EAAAA,KAAS,IACd+M,aAAauB,QAAQ,UACnB,SAIjBqC,GAAczQ,EAAAA,EAAAA,KAAY,KAC9BwQ,GAASE,IACP,MAAMC,EAAyB,SAAdD,EAAuB,QAAU,OAElD,OADA7D,aAAaC,QAAQ,QAAS6D,GACvBA,CAAQ,GACf,GACD,KAGHlE,EAAAA,EAAAA,KAAU,KACRmE,SAASnJ,KAAKoJ,UAAUC,OAAO,aAAc,aAC7CF,SAASnJ,KAAKoJ,UAAUE,IAAI,GAAGR,SAAa,GAC3C,CAACA,IAGJ,MAAM5P,GAAQsC,EAAAA,EAAAA,KAAQ,MACpBsN,QACAE,cACAO,OAAkB,SAAVT,KACN,CAACA,EAAOE,IAEZ,OACEhQ,EAAAA,EAAAA,GAAC2P,EAAa1P,SAAQ,CAACC,MAAOA,EAAMhB,SACjCA,GACqB,C,gFC3C5B,MAAMsR,GAAezR,EAAAA,EAAAA,MAGRgM,EAAWA,KACtB,MAAM3K,GAAUC,EAAAA,EAAAA,IAAWmQ,GAC3B,IAAKpQ,EACH,MAAM,IAAIE,MAAM,gDAElB,OAAOF,CAAO,EAIVqQ,EAAY,YACZC,EAAe,eAGrB,SAASC,EAAaC,EAAOC,GAC3B,OAAQA,EAAOvD,MACb,KAAKmD,EACH,MAAO,IAAIG,EAAOC,EAAO1K,SAC3B,KAAKuK,EACH,OAAOE,EAAME,QAAOC,GAASA,EAAMjM,KAAO+L,EAAO1K,UACnD,QACE,OAAOyK,EAEb,CAGO,MAAMI,EAAgB/R,IAAmB,IAAlB,SAAEC,GAAUD,EACxC,MAAOgS,EAAQC,IAAYC,EAAAA,EAAAA,IAAWR,EAAc,IAG9C7F,GAAYvL,EAAAA,EAAAA,KAAYqG,IAAyC,IAAxC,KAAE0H,EAAI,QAAE1J,EAAO,SAAEwN,EAAW,KAAMxL,EAC/D,MAAMd,EAAKP,KAAKC,MAAMH,WAAaF,KAAKC,SAASC,SAAS,IAAIgN,OAAO,EAAG,GAIxE,OAHAH,EAAS,CAAE5D,KAAMmD,EAAWtK,QAAS,CAAErB,KAAIwI,OAAM1J,UAASwN,cAE1DhM,YAAW,IAAM8L,EAAS,CAAE5D,KAAMoD,EAAcvK,QAASrB,KAAOsM,GACzDtM,CAAE,GACR,IAGGwM,GAAe/R,EAAAA,EAAAA,KAAYuF,IAC/BoM,EAAS,CAAE5D,KAAMoD,EAAcvK,QAASrB,GAAK,GAC5C,IAEH,OACEyM,EAAAA,EAAAA,IAACf,EAAavQ,SAAQ,CAACC,MAAO,CAAE4K,YAAWwG,gBAAepS,SAAA,CACvDA,GACDc,EAAAA,EAAAA,GAACwR,EAAAA,EAAc,CAACP,OAAQA,EAAQK,aAAcA,MACxB,C,2KCxC5B,MAAMG,GAAwB1S,EAAAA,EAAAA,IAAc,MAc/B2S,EAAiBzS,IAAmB,IAAlB,SAAEC,GAAUD,EAEzC,MAAM0S,GAAsBnP,EAAAA,EAAAA,KAAQ,MAClCoP,eAAe,EACfC,eAAiB3R,IACfyR,EAAoBC,cAAgB1R,CAAK,KAEzC,IAMJ,OAJA8L,EAAAA,EAAAA,KAAU,KACR2F,EAAoBE,gBAAe,EAAK,GACvC,CAACF,KAGF3R,EAAAA,EAAAA,GAACyR,EAAsBxR,SAAQ,CAACC,MAAOyR,EAAoBzS,UACzDc,EAAAA,EAAAA,GAAC6P,EAAAA,EAAa,CAAA3Q,UACZc,EAAAA,EAAAA,GAAC8R,EAAAA,EAAW,CAAA5S,UACVc,EAAAA,EAAAA,GAAC2K,EAAAA,GAAa,CAAAzL,UACZc,EAAAA,EAAAA,GAAC0J,EAAAA,EAAgB,CAAAxK,UACfc,EAAAA,EAAAA,GAAC+R,EAAAA,EAAkB,CAAA7S,UACjBc,EAAAA,EAAAA,GAACgS,EAAAA,EAAmB,CAAA9S,UAClBc,EAAAA,EAAAA,GAAC2O,EAAAA,EAA0B,CAAAzP,UACzBc,EAAAA,EAAAA,GAACY,EAAAA,EAAuB,CAAA1B,UACtBc,EAAAA,EAAAA,GAACiS,EAAAA,EAAiB,CAAA/S,UAChBc,EAAAA,EAAAA,GAACkS,EAAAA,EAAmB,CAAAhT,SACjBA,uBAWU,C","sources":["contexts/LoadingContext.js","contexts/StreamingEventsContext.js","contexts/SettingsContext.js","contexts/ModelContext.js","contexts/PerformanceMetricsContext.js","contexts/ThemeContext.js","contexts/ToastContext.js","contexts/ContextManager.js"],"sourcesContent":["import React, { createContext, useContext, useState, useCallback } from 'react';\n\n// Context to track multiple loading tags\nconst LoadingContext = createContext(null);\n\n/**\n * Provider to wrap application and manage loading states by tags\n */\nexport const LoadingProvider = ({ children }) => {\n  const [loadingMap, setLoadingMap] = useState({});\n\n  const setLoading = useCallback((tag, isLoading) => {\n    setLoadingMap(prev => ({ ...prev, [tag]: isLoading }));\n  }, []);\n\n  const isLoading = useCallback(tag => !!loadingMap[tag], [loadingMap]);\n  const anyLoading = Object.values(loadingMap).some(val => val);\n\n  return (\n    <LoadingContext.Provider value={{ setLoading, isLoading, anyLoading }}>\n      {children}\n    </LoadingContext.Provider>\n  );\n};\n\n/**\n * Hook to control loading for a specific tag\n * @param {string} tag - Unique identifier for loading scope\n * @returns {[boolean, function, function]} [isLoading, startLoading, stopLoading]\n */\nexport const useLoading = (tag) => {\n  const context = useContext(LoadingContext);\n  if (!context) throw new Error('useLoading must be used within LoadingProvider');\n  const { setLoading, isLoading } = context;\n  const startLoading = useCallback(() => setLoading(tag, true), [setLoading, tag]);\n  const stopLoading = useCallback(() => setLoading(tag, false), [setLoading, tag]);\n  return [isLoading(tag), startLoading, stopLoading];\n};\n\n/**\n * Hook to check if any loading is active globally\n * @returns {boolean}\n */\nexport const useGlobalLoading = () => {\n  const context = useContext(LoadingContext);\n  if (!context) throw new Error('useGlobalLoading must be used within LoadingProvider');\n  return context.anyLoading;\n}; ","import React, { createContext, useContext, useRef, useCallback, useMemo, useEffect } from 'react';\nimport { useApi } from './ApiContext';\nimport { useModel } from './ModelContext';\nimport { useSettings } from './SettingsContext';\nimport { useAuth } from './AuthContext';\nimport { useChatHistory } from './ChatHistoryContext';\nimport { useChatStatus } from './ChatStatusContext';\nimport { usePerformanceMetrics } from './PerformanceMetricsContext';\nimport { fetchWithRetry } from '../utils/network';\nimport debounce from 'lodash.debounce';\n// Inline worker via worker-loader to avoid separate chunk files\nimport StreamProcessorWorker from 'worker-loader?inline=no-fallback!../workers/streamProcessor.js';\n\n// Create a context for streaming events and logic\nconst StreamingEventsContext = createContext();\n\nexport const useStreamingEvents = () => {\n  const context = useContext(StreamingEventsContext);\n  if (context === undefined) {\n    throw new Error('useStreamingEvents must be used within a StreamingEventsProvider');\n  }\n  return context;\n};\n\nexport const StreamingEventsProvider = ({ children }) => {\n  const { apiUrl } = useApi();\n  const { selectedModel } = useModel();\n  const { getModelAdjustedSettings } = useSettings();\n  const { idToken } = useAuth();\n  const { chatHistoryRef, setChatHistory, addMessageToHistory, updateChatWithContent } = useChatHistory();\n  const { setIsWaitingForResponse, setError } = useChatStatus();\n  const { resetPerformanceMetrics, startPerformanceTimer, updatePerformanceMetrics } = usePerformanceMetrics();\n\n  // Refs for streaming\n  const streamingTextRef = useRef('');\n  const currentRequestIdRef = useRef(null);\n  const abortControllerRef = useRef(null);\n  const isStreamingRef = useRef(false);\n  const firstTokenReceivedRef = useRef(false);\n\n  // Debounced content updater\n  const debouncedUpdateChat = useMemo(\n    () => debounce((content) => updateChatWithContent(content), 20),\n    [updateChatWithContent]\n  );\n\n  // SSE parsing worker setup\n  const streamWorkerUrlRef = useRef(null);\n  const streamWorkerRef = useRef(null);\n  const getOrCreateStreamWorker = useCallback(() => {\n    if (!streamWorkerRef.current) {\n      streamWorkerRef.current = new StreamProcessorWorker();\n    }\n    return streamWorkerRef.current;\n  }, []);\n\n  const parseStreamChunk = useCallback((chunk) => new Promise((resolve, reject) => {\n    const worker = getOrCreateStreamWorker();\n    worker.onmessage = (e) => resolve(e.data);\n    worker.onerror = reject;\n    worker.postMessage(chunk);\n  }), [getOrCreateStreamWorker]);\n\n  // Stream a message using fetch SSE\n  const streamMessageWithFetch = useCallback(async (message, editIndex = null) => {\n    // Generate and store a client-side requestId for this stream\n    const requestId = (typeof crypto !== 'undefined' && crypto.randomUUID)\n      ? crypto.randomUUID()\n      : Math.random().toString(36).substring(2) + Date.now().toString(36);\n    currentRequestIdRef.current = requestId;\n    const isEditing = editIndex !== null && Number.isInteger(editIndex) && editIndex >= 0;\n    if (!message || !selectedModel) {\n      setError('Please enter a message and select a model');\n      return null;\n    }\n    const modelId = `${selectedModel.provider}/${selectedModel.id}`;\n    if (!modelId) {\n      setError('Invalid model selection');\n      return null;\n    }\n    let userMessage;\n    if (isEditing) {\n      setChatHistory(prev => {\n        const truncated = prev.slice(0, editIndex);\n        const original = prev[editIndex];\n        // Preserve original id/timestamp, only update content\n        userMessage = { ...original, content: message };\n        return [...truncated, userMessage];\n      });\n    } else {\n      userMessage = addMessageToHistory('user', message);\n    }\n    resetPerformanceMetrics();\n    startPerformanceTimer();\n    firstTokenReceivedRef.current = false;\n    setIsWaitingForResponse(true);\n    setError(null);\n    streamingTextRef.current = '';\n    isStreamingRef.current = true;\n    addMessageToHistory('assistant', '');\n    let timeoutId = setTimeout(() => {\n      abortControllerRef.current?.abort('timeout');\n      setError('Connection timed out');\n      setIsWaitingForResponse(false);\n    }, 60000);\n    const abortController = new AbortController();\n    abortControllerRef.current = abortController;\n    try {\n      const adjusted = getModelAdjustedSettings(selectedModel);\n      // Build API history without the placeholder assistant message (empty content)\n      const historyForApi = chatHistoryRef.current\n        .slice(0, -1)\n        .map(({ metrics, ...m }) => m);\n      if (adjusted.systemPrompt && (!historyForApi.length || historyForApi[0].role !== 'system')) {\n        historyForApi.unshift({ role: 'system', content: adjusted.systemPrompt, timestamp: Date.now() - 1 });\n      }\n      const payload = {\n        requestId,\n        model: modelId,\n        messages: historyForApi,\n        temperature: adjusted.temperature,\n        max_tokens: adjusted.max_tokens,\n        top_p: adjusted.top_p,\n        frequency_penalty: adjusted.frequency_penalty,\n        presence_penalty: adjusted.presence_penalty\n      };\n      const headers = { 'Content-Type': 'application/json', 'Accept': 'text/event-stream', 'Cache-Control': 'no-cache' };\n      if (idToken) headers['Authorization'] = `Bearer ${idToken}`;\n      const response = await fetchWithRetry(new URL('/api/chat/stream', apiUrl).toString(), {\n        method: 'POST', headers, body: JSON.stringify(payload), signal: abortController.signal, cache: 'no-store'\n      });\n      if (!response.ok) throw new Error(`API error: ${response.status}`);\n      const reader = response.body.getReader();\n      const decoder = new TextDecoder('utf-8');\n      let accumulatedContent = '';\n      while (true) {\n        const { done, value } = await reader.read();\n        clearTimeout(timeoutId);\n        timeoutId = setTimeout(() => {\n          abortControllerRef.current?.abort();\n          setError('Connection timed out');\n          setIsWaitingForResponse(false);\n        }, 60000);\n        if (done) {\n          // handle leftover buffer\n          break;\n        }\n        const chunk = decoder.decode(value, { stream: true });\n\n        console.log('Received stream chunk:', chunk);\n\n        try {\n          const msgs = await parseStreamChunk(chunk);\n          for (const msg of msgs) {\n            // Handle server-sent error payload\n            if (msg.rawChunk?.error || msg.finishReason === 'error') {\n              const errMsg = msg.rawChunk?.error?.message || 'Error occurred during generation';\n              console.error('Error in SSE payload:', errMsg);\n              setError(errMsg);\n              setChatHistory(prev => {\n                const newHistory = [...prev];\n                const lastMsg = newHistory[newHistory.length - 1];\n                if (lastMsg && lastMsg.role === 'assistant') {\n                  lastMsg.content += `\\n\\n**Error:** ${errMsg}`;\n                  if (lastMsg.metrics) {\n                    lastMsg.metrics.isComplete = true;\n                    lastMsg.metrics.error = true;\n                  }\n                }\n                return newHistory;\n              });\n              return null;\n            }\n            // Append any content from the chunk\n            if (msg.content) {\n              // Record time to first token once\n              if (!firstTokenReceivedRef.current) {\n                updatePerformanceMetrics(1);\n                firstTokenReceivedRef.current = true;\n              }\n              accumulatedContent += msg.content;\n              streamingTextRef.current = accumulatedContent;\n              debouncedUpdateChat(accumulatedContent);\n            }\n            // Always use server-reported completion tokens for metrics\n            const completionTokens = msg.usage?.completionTokens ?? 0;\n            updatePerformanceMetrics(completionTokens, msg.isDone, msg.usage, msg.finishReason);\n          }\n        } catch {}\n      }\n      debouncedUpdateChat.flush();\n      updateChatWithContent(streamingTextRef.current);\n      return streamingTextRef.current;\n    } catch (error) {\n      console.error('Error streaming message:', error);\n      setError(error.message);\n      // Show the server error content as the assistant's message\n      setChatHistory(prev => {\n        const newHistory = [...prev];\n        const lastMsg = newHistory[newHistory.length - 1];\n        if (lastMsg && lastMsg.role === 'assistant') {\n          lastMsg.content += `\\n\\n**Error:** ${error.message || 'Error occurred during generation'}`;\n          if (lastMsg.metrics) {\n            lastMsg.metrics.isComplete = true;\n            lastMsg.metrics.error = true;\n          }\n        }\n        return newHistory;\n      });\n      return null;\n    } finally {\n      clearTimeout(timeoutId);\n      isStreamingRef.current = false;\n      setIsWaitingForResponse(false);\n      // Do not auto-call stop endpoint here; only explicit stop should trigger it\n      currentRequestIdRef.current = null;\n    }\n  }, [\n    apiUrl, selectedModel, getModelAdjustedSettings, idToken,\n    chatHistoryRef, setChatHistory, addMessageToHistory, updateChatWithContent,\n    debouncedUpdateChat, setError, setIsWaitingForResponse,\n    resetPerformanceMetrics, startPerformanceTimer, updatePerformanceMetrics,\n    parseStreamChunk\n  ]);\n\n  const stopStreaming = useCallback(async () => {\n    if (abortControllerRef.current) abortControllerRef.current.abort('user_stopped');\n    const reqId = currentRequestIdRef.current;\n    if (reqId) {\n      const headers = { 'Content-Type': 'application/json' };\n      if (idToken) headers['Authorization'] = `Bearer ${idToken}`;\n      try {\n        await fetchWithRetry(new URL('/api/chat/stop', apiUrl).toString(), {\n          method: 'POST', headers, body: JSON.stringify({ requestId: reqId })\n        });\n      } catch {} finally {\n        currentRequestIdRef.current = null;\n        abortControllerRef.current = null;\n      }\n    }\n    isStreamingRef.current = false;\n    setIsWaitingForResponse(false);\n    return true;\n  }, [apiUrl, idToken, setIsWaitingForResponse]);\n\n  const value = useMemo(() => ({\n    streamMessageWithFetch,\n    stopStreaming,\n    parseStreamChunk,\n    streamingTextRef,\n    isStreaming: () => isStreamingRef.current\n  }), [streamMessageWithFetch, stopStreaming, parseStreamChunk]);\n\n  return (\n    <StreamingEventsContext.Provider value={value}>\n      {children}\n    </StreamingEventsContext.Provider>\n  );\n}; ","import { createContext, useContext, useCallback, useMemo } from 'react';\nimport { useLocalStorage } from '../hooks/useLocalStorage';\n\n// Default settings values\nconst DEFAULT_SETTINGS = {\n  temperature: 0.7,\n  top_p: 1.0,\n  max_tokens: 8191,\n  frequency_penalty: 0,\n  presence_penalty: 0,\n  streaming: true,\n  systemPrompt: `You are a knowledgeable, friendly, and supportive university-level assistant.\n\nFor every question or topic, provide a clear, engaging, and well-structured answer, styled like an expert mentor or senior student.\n\nStyle and Structure:\n\nBegin with a welcoming, positive intro (e.g., \"Alright! I'll break this down for you in detail section by section, with clear explanations and important points.\").\nOrganize your response into numbered sections, each with a descriptive header and an emoji (e.g., # ðŸ“š 1. Core Concept).\nIn each section, explain:\nCore ideas and definitions\nHow things work (step-by-step, or process overview)\nAny relevant formulas, code, or examples\nKey points, tips, or comparisons\nUse subheadings, bullet points, tables, and diagrams (ASCII or LaTeX) for clarity when helpful.\nAt the end, summarize with a \"Key Takeaways\" or \"Next Steps/Related Topics\" section, with quick revision notes, further reading, or suggestions for deeper exploration if relevant.\nAlways offer to provide summary tables, code snippets, or quick revision notes if the user wants them.\nTone: Friendly, supportive, and approachableâ€”like a helpful peer or mentor. Formatting: Use bold, italics, emojis, markdown headers, and tables to maximize clarity.\n\nUse emojis befitting the context\n\nYour goal: Make complex ideas easy to understand, memorable, and actionable for the studentâ€”whether for study, projects, or curiosity.`\n//  systemPrompt: \"You are ChatGPT, a helpful and knowledgeable AI assistant. Your primary role is to assist Nikhil, a university engineering student, by providing clear, concise, and technically accurate information. Adopt a friendly and approachable tone, akin to a knowledgeable peer or mentor. Enhance your responses with relevant emojis to convey tone and emotion, making interactions more engaging. Structure your answers logically, using bullet points or numbered lists where appropriate to enhance clarity. When applicable, incorporate interactive elements such as code snippets or diagrams to facilitate deeper understanding. Encourage curiosity by suggesting related topics or questions that Nikhil might explore further. Always tailor your assistance to support Nikhil's academic and personal growth in the field of engineering\"\n};\n\n// Create settings context\nconst SettingsContext = createContext();\n\n// Custom hook for using settings\nexport const useSettings = () => {\n  const context = useContext(SettingsContext);\n  if (context === undefined) {\n    throw new Error('useSettings must be used within a SettingsProvider');\n  }\n  return context;\n};\n\n// Settings provider component\nexport const SettingsProvider = ({ children }) => {\n  // Initialize settings state with defaults, persisted to localStorage\n  const [settings, setSettings] = useLocalStorage('appSettings', DEFAULT_SETTINGS);\n  \n  // Handle individual setting updates\n  const updateSetting = useCallback((key, value) => {\n    // Ensure the key is a valid setting we manage\n    if (key in DEFAULT_SETTINGS) {\n      setSettings(prev => ({\n        ...prev,\n        [key]: value\n      }));\n    }\n  }, [setSettings]);\n  \n  // Reset settings to defaults\n  const resetSettings = useCallback(() => {\n    setSettings(DEFAULT_SETTINGS);\n  }, [setSettings]);\n  \n  // Check if temperature should be restricted based on model name/series\n  const shouldRestrictTemperature = useCallback((model) => {\n    if (!model) return false;\n    \n    // More explicit flag checking for temperature restriction\n    // Check for specific model properties that indicate temperature restriction\n    return (\n      model.requiresFixedTemperature === true || \n      (model.properties && model.properties.includes('fixed_temperature')) ||\n      (model.id && model.id.toLowerCase().startsWith('o')) ||\n      (model.series && model.series.toLowerCase() === 'o-series')\n    );\n  }, []);\n  \n  // Get current settings with potential model-specific overrides\n  const getModelAdjustedSettings = useCallback((model) => {\n    if (shouldRestrictTemperature(model)) {\n      return {\n        ...settings,\n        temperature: 1.0\n      };\n    }\n    return settings;\n  }, [settings, shouldRestrictTemperature]);\n  \n  // Memoize context value to prevent unnecessary re-renders\n  const value = useMemo(() => ({\n    settings,\n    updateSetting,\n    resetSettings,\n    shouldRestrictTemperature,\n    getModelAdjustedSettings\n  }), [\n    settings,\n    updateSetting, \n    resetSettings, \n    shouldRestrictTemperature, \n    getModelAdjustedSettings\n  ]);\n  \n  return (\n    <SettingsContext.Provider value={value}>\n      {children}\n    </SettingsContext.Provider>\n  );\n}; ","import { createContext, useContext, useState, useEffect, useCallback, useMemo, useRef } from 'react';\nimport { useApi } from './ApiContext';\nimport { useLocalStorage } from '../hooks/useLocalStorage';\nimport { useAuth } from './AuthContext';\nimport { useCacheToggle } from '../hooks/useCacheToggle';\nimport { useToast } from './ToastContext';\nimport { useLoading } from './LoadingContext';\n\n// Cache expiry time in milliseconds (5 days)\nconst CACHE_EXPIRY_TIME = 5 * 24 * 60 * 60 * 1000;\n\n// Create separate contexts for models and filtering\nconst ModelContext = createContext();\nconst ModelFilterContext = createContext();\n\n// Custom hook for using model context\nexport const useModel = () => {\n  const context = useContext(ModelContext);\n  if (context === undefined) {\n    throw new Error('useModel must be used within a ModelProvider');\n  }\n  return context;\n};\n\n// Custom hook for using model filter context\nexport const useModelFilter = () => {\n  const context = useContext(ModelFilterContext);\n  if (context === undefined) {\n    throw new Error('useModelFilter must be used within a ModelProvider');\n  }\n  return context;\n};\n\n// Model provider component\nexport const ModelProvider = ({ children }) => {\n  const { cacheEnabled } = useCacheToggle();\n  const { apiUrl } = useApi();\n  const { idToken } = useAuth();\n  const { showToast } = useToast();\n  \n  // State for model data\n  const [allModels, setAllModels] = useState([]);\n  const [processedModels, setProcessedModels] = useState({});\n  const [experimentalModels, setExperimentalModels] = useState([]);\n  const [selectedModel, setSelectedModel] = useLocalStorage('selectedModel', null);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState(null);\n  \n  // Filter state - moved to separate context\n  const [showExperimental, setShowExperimental] = useLocalStorage('showExperimental', false);\n  const [modelFilter, setModelFilter] = useState({\n    search: '',\n    categories: {\n      'Chat': true,\n      'Image': true,\n      'Embedding': true\n    }\n  });\n  \n  // Sync with global loading context\n  const [, startModelsLoading, stopModelsLoading] = useLoading('models');\n  useEffect(() => {\n    if (isLoading) startModelsLoading();\n    else stopModelsLoading();\n  }, [isLoading, startModelsLoading, stopModelsLoading]);\n  \n  // Check if cache is valid\n  const isCacheValid = useCallback((cache) => {\n    return (\n      cache &&\n      cache.timestamp &&\n      Date.now() - cache.timestamp < CACHE_EXPIRY_TIME &&\n      cache.allModels &&\n      cache.processedModels &&\n      cache.experimentalModels\n    );\n  }, []);\n  \n  // Expose isCacheValid function for external access\n  useEffect(() => {\n    // Skip during server-side rendering\n    if (typeof window === 'undefined') return;\n    window.isCacheValid = isCacheValid;\n    \n    return () => {\n      delete window.isCacheValid;\n    };\n  }, [isCacheValid]);\n  \n  // Cache models to localStorage\n  const cacheModels = useCallback((data) => {\n    try {\n      const cache = {\n        allModels: data.allModels,\n        processedModels: data.processedModels,\n        experimentalModels: data.experimentalModels,\n        timestamp: Date.now()\n      };\n      \n      localStorage.setItem('modelDropdownCache', JSON.stringify(cache));\n    } catch (error) {\n      console.error('Error caching models:', error);\n    }\n  }, []);\n  \n  // Update category filter\n  const updateCategoryFilter = useCallback((category, isChecked) => {\n    setModelFilter(prev => ({\n      ...prev,\n      categories: {\n        ...prev.categories,\n        [category]: isChecked\n      }\n    }));\n  }, []);\n  \n  // Update search filter\n  const updateSearchFilter = useCallback((searchText) => {\n    setModelFilter(prev => ({\n      ...prev,\n      search: searchText\n    }));\n  }, []);\n  \n  // Select a model\n  const selectModel = useCallback((model) => {\n    // Check if the model is actually different to prevent unnecessary updates\n    if (selectedModel?.id !== model?.id) { \n      setSelectedModel(model);\n    }\n  }, [selectedModel, setSelectedModel]);\n  \n  // Fetch models from API, optionally using auth token or override token\n  const fetchModels = useCallback(async (authRequired = false, overrideToken = null) => {\n    setIsLoading(true);\n    setError(null);\n    \n    console.log(`Fetching models from API (auth: ${authRequired})...`);\n    try {\n      const headers = { 'Accept': 'application/json' };\n      if (authRequired) {\n        // Prefer overrideToken (cached) over current idToken\n        const tokenToUse = overrideToken || idToken;\n        if (tokenToUse) {\n          headers['Authorization'] = `Bearer ${tokenToUse}`;\n        }\n      }\n      const modelsUrl = new URL('/api/models/classified', apiUrl).toString();\n      const response = await fetch(modelsUrl, { headers });\n      console.log('Models response:', response);\n      \n      if (!response.ok) {\n        let errorMsg = `Error fetching models: ${response.status}`;\n        console.error(errorMsg);\n        throw new Error(errorMsg);\n      }\n      \n      const rawData = await response.json();\n      console.log(\"[ModelContext] Raw data:\", rawData);\n      console.log(\"[ModelContext] Spawning worker for model processing...\");\n      // Offload model processing to Web Worker\n      const worker = new Worker(new URL('../workers/modelProcessor.js', import.meta.url), { type: 'module' });\n      worker.postMessage(rawData);\n      worker.onmessage = ({ data: msg }) => {\n        if (msg.error) {\n          console.error('[ModelContext] Worker error:', msg.error);\n          setError(msg.error);\n          showToast({ type: 'error', message: msg.error });\n        } else {\n          const {\n            allModels: fetchedAllModels,\n            processedModels: fetchedProcessedModels,\n            experimentalModels: fetchedExperimentalModels\n          } = msg;\n          if (cacheEnabled) {\n            const rawPrev = localStorage.getItem('modelDropdownCache');\n            let prevCache;\n            try { prevCache = JSON.parse(rawPrev); } catch { prevCache = null; }\n            const changed = !prevCache ||\n              JSON.stringify(prevCache.allModels) !== JSON.stringify(fetchedAllModels) ||\n              JSON.stringify(prevCache.processedModels) !== JSON.stringify(fetchedProcessedModels) ||\n              JSON.stringify(prevCache.experimentalModels) !== JSON.stringify(fetchedExperimentalModels);\n            if (changed) {\n              setAllModels(fetchedAllModels);\n              setProcessedModels(fetchedProcessedModels);\n              setExperimentalModels(fetchedExperimentalModels);\n              cacheModels({ allModels: fetchedAllModels, processedModels: fetchedProcessedModels, experimentalModels: fetchedExperimentalModels });\n            }\n          } else {\n            setAllModels(fetchedAllModels);\n            setProcessedModels(fetchedProcessedModels);\n            setExperimentalModels(fetchedExperimentalModels);\n          }\n          // Initial model selection moved to a separate useEffect\n        }\n        setIsLoading(false);\n        worker.terminate();\n      };\n      worker.onerror = (err) => {\n        console.error('[ModelContext] Worker unexpected error:', err);\n        setError(err.message);\n        showToast({ type: 'error', message: err.message });\n        setIsLoading(false);\n        worker.terminate();\n      };\n    } catch (err) {\n      console.error('Failed to fetch or process models:', err);\n      setError(err.message || 'Failed to load model data');\n      showToast({ type: 'error', message: err.message || 'Failed to load model data' });\n      // Attempt to load from potentially expired cache as a last resort?\n    }\n  }, [apiUrl, cacheModels, idToken, cacheEnabled, showToast]);\n  \n  // Initial fetch once on mount\n  const initialFetchDoneRef = useRef(false);\n  // track if we've already fetched models with authentication\n  const didAuthFetchRef = useRef(false);\n\n  useEffect(() => {\n    if (!initialFetchDoneRef.current) {\n      if (cacheEnabled) {\n        const rawCache = localStorage.getItem('modelDropdownCache');\n        let parsedCache;\n        try { parsedCache = JSON.parse(rawCache); } catch { parsedCache = null; }\n        if (parsedCache && window.isCacheValid(parsedCache)) {\n          setAllModels(parsedCache.allModels);\n          setProcessedModels(parsedCache.processedModels);\n          setExperimentalModels(parsedCache.experimentalModels);\n          setIsLoading(false);\n        }\n      }\n      let cachedToken = null;\n      try { cachedToken = localStorage.getItem('idToken'); } catch {}\n      if (cachedToken) {\n        // initial authenticated fetch\n        didAuthFetchRef.current = true;\n        fetchModels(true, cachedToken);\n      } else {\n        // initial unauthenticated fetch\n        fetchModels(false);\n      }\n      initialFetchDoneRef.current = true;\n    }\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n  }, []);\n\n  // After login, fetch authenticated models\n  useEffect(() => {\n    // only fetch once after obtaining idToken if not already done\n    if (initialFetchDoneRef.current && idToken && !didAuthFetchRef.current) {\n      didAuthFetchRef.current = true;\n      fetchModels(true);\n    }\n  }, [idToken, fetchModels]);\n  \n  // Set initial model after models are loaded\n  useEffect(() => {\n    // Select first model if none selected and models are loaded\n    if (!selectedModel && allModels.length > 0) {\n      setSelectedModel(allModels[0]);\n    }\n  }, [allModels, selectedModel, setSelectedModel]);\n  \n  // Create toggleExperimentalModels callback at the top level\n  const toggleExperimentalModels = useCallback(() => {\n    setShowExperimental(prev => !prev);\n  }, [setShowExperimental]);\n  \n  // Main model context value - no filter state\n  const modelValue = useMemo(() => ({\n    allModels,\n    processedModels,\n    experimentalModels,\n    selectedModel,\n    isLoading,\n    error,\n    showExperimental,\n    isExperimentalModelsEnabled: showExperimental,\n    toggleExperimentalModels,\n    setShowExperimental,\n    selectModel,\n    refreshModels: fetchModels\n  }), [\n    allModels,\n    processedModels,\n    experimentalModels,\n    selectedModel,\n    isLoading,\n    error,\n    showExperimental,\n    toggleExperimentalModels,\n    setShowExperimental,\n    selectModel,\n    fetchModels\n  ]);\n  \n  // Filter context value - only filter-related state\n  const filterValue = useMemo(() => ({\n    modelFilter,\n    updateCategoryFilter,\n    updateSearchFilter\n  }), [\n    modelFilter,\n    updateCategoryFilter,\n    updateSearchFilter\n  ]);\n  \n  return (\n    <ModelContext.Provider value={modelValue}>\n      <ModelFilterContext.Provider value={filterValue}>\n        {children}\n      </ModelFilterContext.Provider>\n    </ModelContext.Provider>\n  );\n}; ","import React, { createContext, useContext, useState, useCallback, useMemo, useEffect } from 'react';\nimport { useChatHistory } from './ChatHistoryContext';\n\n// Create performance metrics context\nconst PerformanceMetricsContext = createContext();\n\n// Hook to use performance metrics context\nexport const usePerformanceMetrics = () => {\n  const context = useContext(PerformanceMetricsContext);\n  if (context === undefined) {\n    throw new Error('usePerformanceMetrics must be used within a PerformanceMetricsProvider');\n  }\n  return context;\n};\n\n// Provider component for performance metrics\nexport const PerformanceMetricsProvider = ({ children }) => {\n  const { setChatHistory } = useChatHistory();\n  const [currentMessageMetrics, setCurrentMessageMetrics] = useState({\n    startTime: null,\n    endTime: null,\n    elapsedTime: null,\n    tokenCount: null,\n    tokensPerSecond: null,\n    isComplete: false,\n    timeToFirstToken: null,\n    promptTokens: null,\n    completionTokens: null,\n    totalTokens: null,\n    finishReason: null\n  });\n\n  const resetPerformanceMetrics = useCallback(() => {\n    setCurrentMessageMetrics({\n      startTime: null,\n      endTime: null,\n      elapsedTime: null,\n      tokenCount: null,\n      tokensPerSecond: null,\n      isComplete: false,\n      timeToFirstToken: null,\n      promptTokens: null,\n      completionTokens: null,\n      totalTokens: null,\n      finishReason: null\n    });\n  }, []);\n\n  const startPerformanceTimer = useCallback(() => {\n    setCurrentMessageMetrics(prev => ({\n      ...prev,\n      startTime: Date.now(),\n      isComplete: false\n    }));\n  }, []);\n\n  // eslint-disable-next-line react-hooks/exhaustive-deps\n  const updatePerformanceMetrics = useCallback((newTokenCount, isComplete = false, tokenInfo = null, finishReason = null) => {\n    setCurrentMessageMetrics(prev => {\n      const endTime = Date.now();\n      const elapsedTime = prev.startTime ? endTime - prev.startTime : 0;\n      const tokensPerSecond = newTokenCount && elapsedTime ?\n        Math.round((newTokenCount / (elapsedTime / 1000)) * 10) / 10 :\n        prev.tokensPerSecond;\n      const timeToFirstToken = prev.timeToFirstToken ||\n        (newTokenCount > 0 ? elapsedTime : null);\n\n      const newMetrics = {\n        startTime: prev.startTime,\n        endTime,\n        elapsedTime,\n        tokenCount: newTokenCount,\n        tokensPerSecond,\n        isComplete,\n        timeToFirstToken,\n        promptTokens: tokenInfo?.promptTokens || prev.promptTokens,\n        completionTokens: tokenInfo?.completionTokens || prev.completionTokens,\n        totalTokens: tokenInfo?.totalTokens || prev.totalTokens,\n        finishReason: finishReason || prev.finishReason\n      };\n\n      return newMetrics;\n    });\n  }, []);\n\n  // Sync performance metrics into chat history after a metrics update\n  useEffect(() => {\n    if (currentMessageMetrics.endTime != null) {\n      setChatHistory(prevHistory => {\n        const newHistory = [...prevHistory];\n        const lastMsg = newHistory[newHistory.length - 1];\n        if (lastMsg && lastMsg.role === 'assistant') {\n          lastMsg.metrics = { ...currentMessageMetrics };\n        }\n        return newHistory;\n      });\n    }\n  }, [currentMessageMetrics, setChatHistory]);\n\n  // Direct function to set token metrics for the last message - for debugging/testing\n  const setTokenMetricsForLastMessage = useCallback((metrics) => {\n    setChatHistory(prevHistory => {\n      const newHistory = [...prevHistory];\n      const lastMsg = newHistory[newHistory.length - 1];\n      if (lastMsg && lastMsg.role === 'assistant') {\n        lastMsg.metrics = {\n          ...(lastMsg.metrics || {}),\n          ...metrics,\n          isComplete: true\n        };\n      }\n      return newHistory;\n    });\n  }, [setChatHistory]);\n\n  const value = useMemo(() => ({\n    currentMessageMetrics,\n    resetPerformanceMetrics,\n    startPerformanceTimer,\n    updatePerformanceMetrics,\n    setTokenMetricsForLastMessage\n  }), [currentMessageMetrics, resetPerformanceMetrics, startPerformanceTimer, updatePerformanceMetrics, setTokenMetricsForLastMessage]);\n\n  return (\n    <PerformanceMetricsContext.Provider value={value}>\n      {children}\n    </PerformanceMetricsContext.Provider>\n  );\n}; ","import { createContext, useContext, useState, useEffect, useCallback, useMemo } from 'react';\n\n// Create theme context\nconst ThemeContext = createContext();\n\n// Custom hook for using theme\nexport const useTheme = () => {\n  const context = useContext(ThemeContext);\n  if (context === undefined) {\n    throw new Error('useTheme must be used within a ThemeProvider');\n  }\n  return context;\n};\n\n// Theme provider component\nexport const ThemeProvider = ({ children }) => {\n  // Initialize theme from localStorage or default to 'dark'\n  const [theme, setTheme] = useState(() => {\n    const savedTheme = localStorage.getItem('theme');\n    return savedTheme || 'dark';\n  });\n\n  // Toggle between light and dark themes\n  const toggleTheme = useCallback(() => {\n    setTheme(prevTheme => {\n      const newTheme = prevTheme === 'dark' ? 'light' : 'dark';\n      localStorage.setItem('theme', newTheme);\n      return newTheme;\n    });\n  }, []);\n\n  // Apply theme class to body element\n  useEffect(() => {\n    document.body.classList.remove('light-mode', 'dark-mode');\n    document.body.classList.add(`${theme}-mode`);\n  }, [theme]);\n\n  // Context value - memoized to prevent unnecessary re-renders\n  const value = useMemo(() => ({\n    theme,\n    toggleTheme,\n    isDark: theme === 'dark'\n  }), [theme, toggleTheme]);\n\n  return (\n    <ThemeContext.Provider value={value}>\n      {children}\n    </ThemeContext.Provider>\n  );\n}; ","import React, { createContext, useContext, useReducer, useCallback } from 'react';\nimport ToastContainer from '../components/common/ToastNotification';\n\n// Create context for toast notifications\nconst ToastContext = createContext();\n\n// Hook to use toast context\nexport const useToast = () => {\n  const context = useContext(ToastContext);\n  if (!context) {\n    throw new Error('useToast must be used within a ToastProvider');\n  }\n  return context;\n};\n\n// Action types\nconst ADD_TOAST = 'ADD_TOAST';\nconst REMOVE_TOAST = 'REMOVE_TOAST';\n\n// Reducer to manage toast list\nfunction toastReducer(state, action) {\n  switch (action.type) {\n    case ADD_TOAST:\n      return [...state, action.payload];\n    case REMOVE_TOAST:\n      return state.filter(toast => toast.id !== action.payload);\n    default:\n      return state;\n  }\n}\n\n// Provider component that holds toast state and renders toasts\nexport const ToastProvider = ({ children }) => {\n  const [toasts, dispatch] = useReducer(toastReducer, []);\n\n  // Function to show a toast\n  const showToast = useCallback(({ type, message, duration = 3000 }) => {\n    const id = Date.now().toString() + Math.random().toString(36).substr(2, 9);\n    dispatch({ type: ADD_TOAST, payload: { id, type, message, duration } });\n    // Auto-dismiss toast after duration\n    setTimeout(() => dispatch({ type: REMOVE_TOAST, payload: id }), duration);\n    return id;\n  }, []);\n\n  // Function to manually dismiss a toast\n  const dismissToast = useCallback(id => {\n    dispatch({ type: REMOVE_TOAST, payload: id });\n  }, []);\n\n  return (\n    <ToastContext.Provider value={{ showToast, dismissToast }}>\n      {children}\n      <ToastContainer toasts={toasts} dismissToast={dismissToast} />\n    </ToastContext.Provider>\n  );\n}; ","import { createContext, useContext, useMemo, useEffect } from 'react';\nimport { ThemeProvider } from './ThemeContext';\nimport { ApiProvider } from './ApiContext';\nimport { ModelProvider } from './ModelContext';\nimport { SettingsProvider } from './SettingsContext';\nimport { ChatStatusProvider } from './ChatStatusContext';\nimport { ChatHistoryProvider } from './ChatHistoryContext';\nimport { PerformanceMetricsProvider } from './PerformanceMetricsContext';\nimport { StreamingEventsProvider } from './StreamingEventsContext';\nimport { ChatStateProvider } from './ChatStateContext';\nimport { ChatControlProvider } from './ChatControlContext';\n\n// Create a context for managing initialization state\nconst InitializationContext = createContext(null);\n\nexport const useInitialization = () => {\n  const context = useContext(InitializationContext);\n  if (!context) {\n    throw new Error('useInitialization must be used within an InitializationProvider');\n  }\n  return context;\n};\n\n/**\n * ContextManager component that handles all context providers\n * and their initialization states\n */\nexport const ContextManager = ({ children }) => {\n  // Memoize the initialization state to prevent unnecessary re-renders\n  const initializationState = useMemo(() => ({\n    isInitialized: false,\n    setInitialized: (value) => {\n      initializationState.isInitialized = value;\n    }\n  }), []);\n  // Mark as initialized once on mount\n  useEffect(() => {\n    initializationState.setInitialized(true);\n  }, [initializationState]);\n\n  return (\n    <InitializationContext.Provider value={initializationState}>\n      <ThemeProvider>\n        <ApiProvider>\n          <ModelProvider>\n            <SettingsProvider>\n              <ChatStatusProvider>\n                <ChatHistoryProvider>\n                  <PerformanceMetricsProvider>\n                    <StreamingEventsProvider>\n                      <ChatStateProvider>\n                        <ChatControlProvider>\n                          {children}\n                        </ChatControlProvider>\n                      </ChatStateProvider>\n                    </StreamingEventsProvider>\n                  </PerformanceMetricsProvider>\n                </ChatHistoryProvider>\n              </ChatStatusProvider>\n            </SettingsProvider>\n          </ModelProvider>\n        </ApiProvider>\n      </ThemeProvider>\n    </InitializationContext.Provider>\n  );\n}; "],"names":["LoadingContext","createContext","LoadingProvider","_ref","children","loadingMap","setLoadingMap","useState","setLoading","useCallback","tag","isLoading","prev","anyLoading","Object","values","some","val","_jsx","Provider","value","useLoading","context","useContext","Error","startLoading","stopLoading","StreamingEventsContext","useStreamingEvents","undefined","StreamingEventsProvider","apiUrl","useApi","selectedModel","useModel","getModelAdjustedSettings","useSettings","idToken","useAuth","chatHistoryRef","setChatHistory","addMessageToHistory","updateChatWithContent","useChatHistory","setIsWaitingForResponse","setError","useChatStatus","resetPerformanceMetrics","startPerformanceTimer","updatePerformanceMetrics","usePerformanceMetrics","streamingTextRef","useRef","currentRequestIdRef","abortControllerRef","isStreamingRef","firstTokenReceivedRef","debouncedUpdateChat","useMemo","debounce","content","streamWorkerRef","getOrCreateStreamWorker","current","StreamProcessorWorker","parseStreamChunk","chunk","Promise","resolve","reject","worker","onmessage","e","data","onerror","postMessage","streamMessageWithFetch","async","message","editIndex","arguments","length","requestId","crypto","randomUUID","Math","random","toString","substring","Date","now","isEditing","Number","isInteger","modelId","provider","id","userMessage","truncated","slice","original","timeoutId","setTimeout","_abortControllerRef$c","abort","abortController","AbortController","adjusted","historyForApi","map","_ref2","metrics","m","systemPrompt","role","unshift","timestamp","payload","model","messages","temperature","max_tokens","top_p","frequency_penalty","presence_penalty","headers","response","fetchWithRetry","URL","method","body","JSON","stringify","signal","cache","ok","status","reader","getReader","decoder","TextDecoder","accumulatedContent","done","read","clearTimeout","_abortControllerRef$c2","decode","stream","msgs","msg","_msg$rawChunk","_msg$usage$completion","_msg$usage","rawChunk","error","finishReason","_msg$rawChunk2","_msg$rawChunk2$error","errMsg","newHistory","lastMsg","isComplete","completionTokens","usage","isDone","flush","stopStreaming","reqId","isStreaming","DEFAULT_SETTINGS","streaming","SettingsContext","SettingsProvider","settings","setSettings","useLocalStorage","updateSetting","key","resetSettings","shouldRestrictTemperature","requiresFixedTemperature","properties","includes","toLowerCase","startsWith","series","ModelContext","ModelFilterContext","useModelFilter","ModelProvider","cacheEnabled","useCacheToggle","showToast","useToast","allModels","setAllModels","processedModels","setProcessedModels","experimentalModels","setExperimentalModels","setSelectedModel","setIsLoading","showExperimental","setShowExperimental","modelFilter","setModelFilter","search","categories","startModelsLoading","stopModelsLoading","useEffect","isCacheValid","window","cacheModels","localStorage","setItem","updateCategoryFilter","category","isChecked","updateSearchFilter","searchText","selectModel","fetchModels","authRequired","overrideToken","tokenToUse","modelsUrl","fetch","errorMsg","rawData","json","Worker","type","fetchedAllModels","fetchedProcessedModels","fetchedExperimentalModels","rawPrev","getItem","prevCache","parse","terminate","err","initialFetchDoneRef","didAuthFetchRef","rawCache","parsedCache","cachedToken","toggleExperimentalModels","modelValue","isExperimentalModelsEnabled","refreshModels","filterValue","PerformanceMetricsContext","PerformanceMetricsProvider","currentMessageMetrics","setCurrentMessageMetrics","startTime","endTime","elapsedTime","tokenCount","tokensPerSecond","timeToFirstToken","promptTokens","totalTokens","newTokenCount","tokenInfo","round","prevHistory","setTokenMetricsForLastMessage","ThemeContext","useTheme","ThemeProvider","theme","setTheme","toggleTheme","prevTheme","newTheme","document","classList","remove","add","isDark","ToastContext","ADD_TOAST","REMOVE_TOAST","toastReducer","state","action","filter","toast","ToastProvider","toasts","dispatch","useReducer","duration","substr","dismissToast","_jsxs","ToastContainer","InitializationContext","ContextManager","initializationState","isInitialized","setInitialized","ApiProvider","ChatStatusProvider","ChatHistoryProvider","ChatStateProvider","ChatControlProvider"],"sourceRoot":""}