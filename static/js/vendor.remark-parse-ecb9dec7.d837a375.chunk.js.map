{"version":3,"file":"static/js/vendor.remark-parse-ecb9dec7.d837a375.chunk.js","mappings":"sJAuBO,SAASA,EAAkBC,GAChC,OACW,OAATA,IACAC,EAAAA,EAAAA,IAA0BD,KAC1BE,EAAAA,EAAAA,IAAkBF,GAEX,GAELG,EAAAA,EAAAA,IAAmBH,GACd,OADT,CAGF,C,2CCnBO,MAAMI,EAAiB,CAC5B,UACA,UACA,QACA,OACA,WACA,aACA,OACA,UACA,SACA,MACA,WACA,KACA,UACA,SACA,MACA,MACA,KACA,KACA,WACA,aACA,SACA,SACA,OACA,QACA,WACA,KACA,KACA,KACA,KACA,KACA,KACA,OACA,SACA,KACA,OACA,SACA,SACA,KACA,OACA,OACA,OACA,WACA,MACA,WACA,KACA,WACA,SACA,IACA,QACA,SACA,UACA,UACA,QACA,QACA,KACA,QACA,KACA,QACA,QACA,KACA,QACA,MAeWC,EAAe,CAAC,MAAO,SAAU,QAAS,W,kBCzEhD,SAASC,EAAoBC,GAClC,OACEA,EAEGC,QAAQ,cAAe,KAEvBA,QAAQ,SAAU,IAOlBC,cACAC,aAEP,C,kEC1BA,MAAMC,EAAiB,CAAC,EAAEA,eAUnB,SAASC,EAAkBC,GAEhC,MAAMC,EAAM,CAAC,EACb,IAAIC,GAAS,EAEb,OAASA,EAAQF,EAAWG,QAC1BC,EAAgBH,EAAKD,EAAWE,IAGlC,OAAOD,CACT,CAWA,SAASG,EAAgBH,EAAKI,GAE5B,IAAIC,EAEJ,IAAKA,KAAQD,EAAW,CACtB,MAEME,GAFQT,EAAeU,KAAKP,EAAKK,GAAQL,EAAIK,QAAQG,KAEpCR,EAAIK,GAAQ,CAAC,GAE9BI,EAAQL,EAAUC,GAExB,IAAInB,EAEJ,GAAIuB,EACF,IAAKvB,KAAQuB,EAAO,CACbZ,EAAeU,KAAKD,EAAMpB,KAAOoB,EAAKpB,GAAQ,IACnD,MAAMO,EAAQgB,EAAMvB,GACpBwB,EAEEJ,EAAKpB,GACLyB,MAAMC,QAAQnB,GAASA,EAAQA,EAAQ,CAACA,GAAS,GAErD,CAEJ,CACF,CAUA,SAASiB,EAAWG,EAAUC,GAC5B,IAAIb,GAAS,EAEb,MAAMc,EAAS,GAEf,OAASd,EAAQa,EAAKZ,SAEE,UAApBY,EAAKb,GAAOe,IAAkBH,EAAWE,GAAQE,KAAKH,EAAKb,KAG/DiB,EAAAA,EAAAA,GAAOL,EAAU,EAAG,EAAGE,EACzB,C,uIC5EO,MCaMI,EAAaC,EAAW,YAcxBC,EAAoBD,EAAW,cAuB/BE,EAAaF,EAAW,uBAa9B,SAASG,EAAarC,GAC3B,OAGW,OAATA,IAAkBA,EAAO,IAAe,MAATA,EAEnC,CAaO,MAAMsC,EAAaJ,EAAW,MAoBxBK,EAAgBL,EAAW,cAe3BM,EAAmBN,EAAW,kBAiBpC,SAASO,EAAmBzC,GACjC,OAAgB,OAATA,GAAiBA,GAAQ,CAClC,CAWO,SAASC,EAA0BD,GACxC,OAAgB,OAATA,IAAkBA,EAAO,GAAc,KAATA,EACvC,CAiBO,SAAS0C,EAAc1C,GAC5B,OAAiB,IAAVA,IAAyB,IAAVA,GAAwB,KAATA,CACvC,CAuBO,MAAMG,EAAqB+B,ED9LhC,wwCCoNWhC,EAAoBgC,EAAW,MAQ5C,SAASA,EAAWS,GAClB,OAUA,SAAe3C,GACb,OAAgB,OAATA,GAAiB2C,EAAMC,KAAKC,OAAOC,aAAa9C,GACzD,CACF,C,kDCtOO,SAAS+C,EAAYC,GAE1B,MAAMC,EAAQ,CAAC,EACf,IAEIC,EAEAC,EAEAC,EAEAC,EAEAC,EAEAC,EAEAC,EAdAzC,GAAS,EAeb,OAASA,EAAQiC,EAAOhC,QAAQ,CAC9B,KAAOD,KAASkC,GACdlC,EAAQkC,EAAMlC,GAMhB,GAJAmC,EAAQF,EAAOjC,GAKbA,GACkB,cAAlBmC,EAAM,GAAGO,MACqB,mBAA9BT,EAAOjC,EAAQ,GAAG,GAAG0C,OAErBF,EAAYL,EAAM,GAAGQ,WAAWV,OAChCI,EAAa,EAEXA,EAAaG,EAAUvC,QACW,oBAAlCuC,EAAUH,GAAY,GAAGK,OAEzBL,GAAc,GAGdA,EAAaG,EAAUvC,QACW,YAAlCuC,EAAUH,GAAY,GAAGK,MAEzB,OAASL,EAAaG,EAAUvC,QACQ,YAAlCuC,EAAUH,GAAY,GAAGK,MAGS,cAAlCF,EAAUH,GAAY,GAAGK,OAC3BF,EAAUH,GAAY,GAAGO,6BAA8B,EACvDP,KAOR,GAAiB,UAAbF,EAAM,GACJA,EAAM,GAAGU,cACXC,OAAOC,OAAOb,EAAOc,EAAWf,EAAQjC,IACxCA,EAAQkC,EAAMlC,GACdyC,GAAO,QAIN,GAAIN,EAAM,GAAGc,WAAY,CAG5B,IAFAZ,EAAarC,EACboC,OAAY7B,EACL8B,MACLC,EAAaL,EAAOI,GAEK,eAAvBC,EAAW,GAAGI,MACS,oBAAvBJ,EAAW,GAAGI,OAEQ,UAAlBJ,EAAW,KACTF,IACFH,EAAOG,GAAW,GAAGM,KAAO,mBAE9BJ,EAAW,GAAGI,KAAO,aACrBN,EAAYC,GAMdD,IAEFD,EAAM,GAAGe,IAAMJ,OAAOC,OAAO,CAAC,EAAGd,EAAOG,GAAW,GAAGe,OAGtDZ,EAAaN,EAAOmB,MAAMhB,EAAWpC,GACrCuC,EAAWc,QAAQlB,IACnBlB,EAAAA,EAAAA,GAAOgB,EAAQG,EAAWpC,EAAQoC,EAAY,EAAGG,GAErD,CACF,CACA,OAAQE,CACV,CASA,SAASO,EAAWf,EAAQqB,GAC1B,MAAMC,EAAQtB,EAAOqB,GAAY,GAC3BE,EAAUvB,EAAOqB,GAAY,GACnC,IAAIG,EAAgBH,EAAa,EAEjC,MAAMI,EAAiB,GACjBC,EACJJ,EAAMZ,YAAca,EAAQI,OAAOL,EAAMV,aAAaU,EAAMJ,OACxDU,EAAcF,EAAU1B,OAExBC,EAAQ,GAER4B,EAAO,CAAC,EAEd,IAAIC,EAEAC,EACAhE,GAAS,EAETiE,EAAUV,EACVW,EAAS,EACTf,EAAQ,EACZ,MAAMgB,EAAS,CAAChB,GAIhB,KAAOc,GAAS,CAEd,KAAOhC,IAASwB,GAAe,KAAOQ,IAGtCP,EAAe1C,KAAKyC,GACfQ,EAAQtB,aACXoB,EAASP,EAAQY,YAAYH,GACxBA,EAAQI,MACXN,EAAO/C,KAAK,MAEVgD,GACFL,EAAUW,WAAWL,EAAQd,OAE3Bc,EAAQrB,8BACVe,EAAUY,oCAAqC,GAEjDZ,EAAUa,MAAMT,GACZE,EAAQrB,8BACVe,EAAUY,wCAAqChE,IAKnDyD,EAAWC,EACXA,EAAUA,EAAQI,IACpB,CAKA,IADAJ,EAAUV,IACDvD,EAAQ6D,EAAY5D,QAGC,SAA1B4D,EAAY7D,GAAO,IACW,UAA9B6D,EAAY7D,EAAQ,GAAG,IACvB6D,EAAY7D,GAAO,GAAG0C,OAASmB,EAAY7D,EAAQ,GAAG,GAAG0C,MACzDmB,EAAY7D,GAAO,GAAGmD,MAAMsB,OAASZ,EAAY7D,GAAO,GAAGkD,IAAIuB,OAE/DtB,EAAQnD,EAAQ,EAChBmE,EAAOnD,KAAKmC,GAEZc,EAAQtB,gBAAapC,EACrB0D,EAAQD,cAAWzD,EACnB0D,EAAUA,EAAQI,MAqBtB,IAhBAV,EAAU1B,OAAS,GAKfgC,GAEFA,EAAQtB,gBAAapC,EACrB0D,EAAQD,cAAWzD,GAEnB4D,EAAOO,MAKT1E,EAAQmE,EAAOlE,OACRD,KAAS,CACd,MAAMoD,EAAQS,EAAYT,MAAMe,EAAOnE,GAAQmE,EAAOnE,EAAQ,IACxDmD,EAAQO,EAAegB,MAC7BxC,EAAMmB,QAAQ,CAACF,EAAOA,EAAQC,EAAMnD,OAAS,KAC7CgB,EAAAA,EAAAA,GAAOgB,EAAQkB,EAAO,EAAGC,EAC3B,CAEA,IADApD,GAAS,IACAA,EAAQkC,EAAMjC,QACrB6D,EAAKI,EAAShC,EAAMlC,GAAO,IAAMkE,EAAShC,EAAMlC,GAAO,GACvDkE,GAAUhC,EAAMlC,GAAO,GAAKkC,EAAMlC,GAAO,GAAK,EAEhD,OAAO8D,CACT,C,kBCzMO,SAAS7C,EAAOJ,EAAMsC,EAAOwB,EAAQC,GAC1C,MAAM1B,EAAMrC,EAAKZ,OACjB,IAEIsC,EAFAsC,EAAa,EAajB,GAPE1B,EADEA,EAAQ,GACDA,EAAQD,EAAM,EAAIA,EAAMC,EAEzBA,EAAQD,EAAMA,EAAMC,EAE9BwB,EAASA,EAAS,EAAIA,EAAS,EAG3BC,EAAM3E,OAAS,IACjBsC,EAAa7B,MAAMoE,KAAKF,GACxBrC,EAAWc,QAAQF,EAAOwB,GAE1B9D,EAAKI,UAAUsB,QAMf,IAHIoC,GAAQ9D,EAAKI,OAAOkC,EAAOwB,GAGxBE,EAAaD,EAAM3E,QACxBsC,EAAaqC,EAAMxB,MAAMyB,EAAYA,EAAa,KAClDtC,EAAWc,QAAQF,EAAO,GAE1BtC,EAAKI,UAAUsB,GACfsC,GAAc,IACd1B,GAAS,GAGf,CAkBO,SAASnC,EAAKH,EAAM+D,GACzB,OAAI/D,EAAKZ,OAAS,GAChBgB,EAAOJ,EAAMA,EAAKZ,OAAQ,EAAG2E,GACtB/D,GAEF+D,CACT,C,0CC9DO,SAASG,EAAWtE,EAAYwB,EAAQuB,GAE7C,MAAMwB,EAAS,GACf,IAAIhF,GAAS,EAEb,OAASA,EAAQS,EAAWR,QAAQ,CAClC,MAAMgF,EAAUxE,EAAWT,GAAO+E,WAE9BE,IAAYD,EAAOE,SAASD,KAC9BhD,EAASgD,EAAQhD,EAAQuB,GACzBwB,EAAOhE,KAAKiE,GAEhB,CAEA,OAAOhD,CACT,C","sources":["../node_modules/remark-parse/node_modules/micromark-util-classify-character/index.js","../node_modules/remark-parse/node_modules/micromark-util-html-tag-name/index.js","../node_modules/remark-parse/node_modules/micromark-util-normalize-identifier/index.js","../node_modules/remark-parse/node_modules/micromark-util-combine-extensions/index.js","../node_modules/remark-parse/node_modules/micromark-util-character/lib/unicode-punctuation-regex.js","../node_modules/remark-parse/node_modules/micromark-util-character/index.js","../node_modules/remark-parse/node_modules/micromark-util-subtokenize/index.js","../node_modules/remark-parse/node_modules/micromark-util-chunked/index.js","../node_modules/remark-parse/node_modules/micromark-util-resolve-all/index.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Code} Code\n */\n\nimport {\n  markdownLineEndingOrSpace,\n  unicodePunctuation,\n  unicodeWhitespace\n} from 'micromark-util-character'\n/**\n * Classify whether a code represents whitespace, punctuation, or something\n * else.\n *\n * Used for attention (emphasis, strong), whose sequences can open or close\n * based on the class of surrounding characters.\n *\n * > üëâ **Note**: eof (`null`) is seen as whitespace.\n *\n * @param {Code} code\n *   Code.\n * @returns {typeof constants.characterGroupWhitespace | typeof constants.characterGroupPunctuation | undefined}\n *   Group.\n */\nexport function classifyCharacter(code) {\n  if (\n    code === null ||\n    markdownLineEndingOrSpace(code) ||\n    unicodeWhitespace(code)\n  ) {\n    return 1\n  }\n  if (unicodePunctuation(code)) {\n    return 2\n  }\n}\n","/**\n * List of lowercase HTML ‚Äúblock‚Äù tag names.\n *\n * The list, when parsing HTML (flow), results in more relaxed rules (condition\n * 6).\n * Because they are known blocks, the HTML-like syntax doesn‚Äôt have to be\n * strictly parsed.\n * For tag names not in this list, a more strict algorithm (condition 7) is used\n * to detect whether the HTML-like syntax is seen as HTML (flow) or not.\n *\n * This is copied from:\n * <https://spec.commonmark.org/0.30/#html-blocks>.\n *\n * > üëâ **Note**: `search` was added in `CommonMark@0.31`.\n */\nexport const htmlBlockNames = [\n  'address',\n  'article',\n  'aside',\n  'base',\n  'basefont',\n  'blockquote',\n  'body',\n  'caption',\n  'center',\n  'col',\n  'colgroup',\n  'dd',\n  'details',\n  'dialog',\n  'dir',\n  'div',\n  'dl',\n  'dt',\n  'fieldset',\n  'figcaption',\n  'figure',\n  'footer',\n  'form',\n  'frame',\n  'frameset',\n  'h1',\n  'h2',\n  'h3',\n  'h4',\n  'h5',\n  'h6',\n  'head',\n  'header',\n  'hr',\n  'html',\n  'iframe',\n  'legend',\n  'li',\n  'link',\n  'main',\n  'menu',\n  'menuitem',\n  'nav',\n  'noframes',\n  'ol',\n  'optgroup',\n  'option',\n  'p',\n  'param',\n  'search',\n  'section',\n  'summary',\n  'table',\n  'tbody',\n  'td',\n  'tfoot',\n  'th',\n  'thead',\n  'title',\n  'tr',\n  'track',\n  'ul'\n]\n\n/**\n * List of lowercase HTML ‚Äúraw‚Äù tag names.\n *\n * The list, when parsing HTML (flow), results in HTML that can include lines\n * without exiting, until a closing tag also in this list is found (condition\n * 1).\n *\n * This module is copied from:\n * <https://spec.commonmark.org/0.30/#html-blocks>.\n *\n * > üëâ **Note**: `textarea` was added in `CommonMark@0.30`.\n */\nexport const htmlRawNames = ['pre', 'script', 'style', 'textarea']\n","/**\n * Normalize an identifier (as found in references, definitions).\n *\n * Collapses markdown whitespace, trim, and then lower- and uppercase.\n *\n * Some characters are considered ‚Äúuppercase‚Äù, such as U+03F4 (`œ¥`), but if their\n * lowercase counterpart (U+03B8 (`Œ∏`)) is uppercased will result in a different\n * uppercase character (U+0398 (`Œò`)).\n * So, to get a canonical form, we perform both lower- and uppercase.\n *\n * Using uppercase last makes sure keys will never interact with default\n * prototypal values (such as `constructor`): nothing in the prototype of\n * `Object` is uppercase.\n *\n * @param {string} value\n *   Identifier to normalize.\n * @returns {string}\n *   Normalized identifier.\n */\nexport function normalizeIdentifier(value) {\n  return (\n    value\n      // Collapse markdown whitespace.\n      .replace(/[\\t\\n\\r ]+/g, ' ')\n      // Trim.\n      .replace(/^ | $/g, '')\n      // Some characters are considered ‚Äúuppercase‚Äù, but if their lowercase\n      // counterpart is uppercased will result in a different uppercase\n      // character.\n      // Hence, to get that form, we perform both lower- and uppercase.\n      // Upper case makes sure keys will not interact with default prototypal\n      // methods: no method is uppercase.\n      .toLowerCase()\n      .toUpperCase()\n  )\n}\n","/**\n * @typedef {import('micromark-util-types').Extension} Extension\n * @typedef {import('micromark-util-types').Handles} Handles\n * @typedef {import('micromark-util-types').HtmlExtension} HtmlExtension\n * @typedef {import('micromark-util-types').NormalizedExtension} NormalizedExtension\n */\n\nimport {splice} from 'micromark-util-chunked'\n\nconst hasOwnProperty = {}.hasOwnProperty\n\n/**\n * Combine multiple syntax extensions into one.\n *\n * @param {Array<Extension>} extensions\n *   List of syntax extensions.\n * @returns {NormalizedExtension}\n *   A single combined extension.\n */\nexport function combineExtensions(extensions) {\n  /** @type {NormalizedExtension} */\n  const all = {}\n  let index = -1\n\n  while (++index < extensions.length) {\n    syntaxExtension(all, extensions[index])\n  }\n\n  return all\n}\n\n/**\n * Merge `extension` into `all`.\n *\n * @param {NormalizedExtension} all\n *   Extension to merge into.\n * @param {Extension} extension\n *   Extension to merge.\n * @returns {void}\n */\nfunction syntaxExtension(all, extension) {\n  /** @type {keyof Extension} */\n  let hook\n\n  for (hook in extension) {\n    const maybe = hasOwnProperty.call(all, hook) ? all[hook] : undefined\n    /** @type {Record<string, unknown>} */\n    const left = maybe || (all[hook] = {})\n    /** @type {Record<string, unknown> | undefined} */\n    const right = extension[hook]\n    /** @type {string} */\n    let code\n\n    if (right) {\n      for (code in right) {\n        if (!hasOwnProperty.call(left, code)) left[code] = []\n        const value = right[code]\n        constructs(\n          // @ts-expect-error Looks like a list.\n          left[code],\n          Array.isArray(value) ? value : value ? [value] : []\n        )\n      }\n    }\n  }\n}\n\n/**\n * Merge `list` into `existing` (both lists of constructs).\n * Mutates `existing`.\n *\n * @param {Array<unknown>} existing\n * @param {Array<unknown>} list\n * @returns {void}\n */\nfunction constructs(existing, list) {\n  let index = -1\n  /** @type {Array<unknown>} */\n  const before = []\n\n  while (++index < list.length) {\n    // @ts-expect-error Looks like an object.\n    ;(list[index].add === 'after' ? existing : before).push(list[index])\n  }\n\n  splice(existing, 0, 0, before)\n}\n\n/**\n * Combine multiple HTML extensions into one.\n *\n * @param {Array<HtmlExtension>} htmlExtensions\n *   List of HTML extensions.\n * @returns {HtmlExtension}\n *   A single combined HTML extension.\n */\nexport function combineHtmlExtensions(htmlExtensions) {\n  /** @type {HtmlExtension} */\n  const handlers = {}\n  let index = -1\n\n  while (++index < htmlExtensions.length) {\n    htmlExtension(handlers, htmlExtensions[index])\n  }\n\n  return handlers\n}\n\n/**\n * Merge `extension` into `all`.\n *\n * @param {HtmlExtension} all\n *   Extension to merge into.\n * @param {HtmlExtension} extension\n *   Extension to merge.\n * @returns {void}\n */\nfunction htmlExtension(all, extension) {\n  /** @type {keyof HtmlExtension} */\n  let hook\n\n  for (hook in extension) {\n    const maybe = hasOwnProperty.call(all, hook) ? all[hook] : undefined\n    const left = maybe || (all[hook] = {})\n    const right = extension[hook]\n    /** @type {keyof Handles} */\n    let type\n\n    if (right) {\n      for (type in right) {\n        // @ts-expect-error assume document vs regular handler are managed correctly.\n        left[type] = right[type]\n      }\n    }\n  }\n}\n","// This module is generated by `script/`.\n//\n// CommonMark handles attention (emphasis, strong) markers based on what comes\n// before or after them.\n// One such difference is if those characters are Unicode punctuation.\n// This script is generated from the Unicode data.\n\n/**\n * Regular expression that matches a unicode punctuation character.\n */\nexport const unicodePunctuationRegex =\n  /[!-\\/:-@\\[-`\\{-~\\xA1\\xA7\\xAB\\xB6\\xB7\\xBB\\xBF\\u037E\\u0387\\u055A-\\u055F\\u0589\\u058A\\u05BE\\u05C0\\u05C3\\u05C6\\u05F3\\u05F4\\u0609\\u060A\\u060C\\u060D\\u061B\\u061D-\\u061F\\u066A-\\u066D\\u06D4\\u0700-\\u070D\\u07F7-\\u07F9\\u0830-\\u083E\\u085E\\u0964\\u0965\\u0970\\u09FD\\u0A76\\u0AF0\\u0C77\\u0C84\\u0DF4\\u0E4F\\u0E5A\\u0E5B\\u0F04-\\u0F12\\u0F14\\u0F3A-\\u0F3D\\u0F85\\u0FD0-\\u0FD4\\u0FD9\\u0FDA\\u104A-\\u104F\\u10FB\\u1360-\\u1368\\u1400\\u166E\\u169B\\u169C\\u16EB-\\u16ED\\u1735\\u1736\\u17D4-\\u17D6\\u17D8-\\u17DA\\u1800-\\u180A\\u1944\\u1945\\u1A1E\\u1A1F\\u1AA0-\\u1AA6\\u1AA8-\\u1AAD\\u1B5A-\\u1B60\\u1B7D\\u1B7E\\u1BFC-\\u1BFF\\u1C3B-\\u1C3F\\u1C7E\\u1C7F\\u1CC0-\\u1CC7\\u1CD3\\u2010-\\u2027\\u2030-\\u2043\\u2045-\\u2051\\u2053-\\u205E\\u207D\\u207E\\u208D\\u208E\\u2308-\\u230B\\u2329\\u232A\\u2768-\\u2775\\u27C5\\u27C6\\u27E6-\\u27EF\\u2983-\\u2998\\u29D8-\\u29DB\\u29FC\\u29FD\\u2CF9-\\u2CFC\\u2CFE\\u2CFF\\u2D70\\u2E00-\\u2E2E\\u2E30-\\u2E4F\\u2E52-\\u2E5D\\u3001-\\u3003\\u3008-\\u3011\\u3014-\\u301F\\u3030\\u303D\\u30A0\\u30FB\\uA4FE\\uA4FF\\uA60D-\\uA60F\\uA673\\uA67E\\uA6F2-\\uA6F7\\uA874-\\uA877\\uA8CE\\uA8CF\\uA8F8-\\uA8FA\\uA8FC\\uA92E\\uA92F\\uA95F\\uA9C1-\\uA9CD\\uA9DE\\uA9DF\\uAA5C-\\uAA5F\\uAADE\\uAADF\\uAAF0\\uAAF1\\uABEB\\uFD3E\\uFD3F\\uFE10-\\uFE19\\uFE30-\\uFE52\\uFE54-\\uFE61\\uFE63\\uFE68\\uFE6A\\uFE6B\\uFF01-\\uFF03\\uFF05-\\uFF0A\\uFF0C-\\uFF0F\\uFF1A\\uFF1B\\uFF1F\\uFF20\\uFF3B-\\uFF3D\\uFF3F\\uFF5B\\uFF5D\\uFF5F-\\uFF65]/\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n */\n\nimport {unicodePunctuationRegex} from './lib/unicode-punctuation-regex.js'\n\n/**\n * Check whether the character code represents an ASCII alpha (`a` through `z`,\n * case insensitive).\n *\n * An **ASCII alpha** is an ASCII upper alpha or ASCII lower alpha.\n *\n * An **ASCII upper alpha** is a character in the inclusive range U+0041 (`A`)\n * to U+005A (`Z`).\n *\n * An **ASCII lower alpha** is a character in the inclusive range U+0061 (`a`)\n * to U+007A (`z`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAlpha = regexCheck(/[A-Za-z]/)\n\n/**\n * Check whether the character code represents an ASCII alphanumeric (`a`\n * through `z`, case insensitive, or `0` through `9`).\n *\n * An **ASCII alphanumeric** is an ASCII digit (see `asciiDigit`) or ASCII alpha\n * (see `asciiAlpha`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAlphanumeric = regexCheck(/[\\dA-Za-z]/)\n\n/**\n * Check whether the character code represents an ASCII atext.\n *\n * atext is an ASCII alphanumeric (see `asciiAlphanumeric`), or a character in\n * the inclusive ranges U+0023 NUMBER SIGN (`#`) to U+0027 APOSTROPHE (`'`),\n * U+002A ASTERISK (`*`), U+002B PLUS SIGN (`+`), U+002D DASH (`-`), U+002F\n * SLASH (`/`), U+003D EQUALS TO (`=`), U+003F QUESTION MARK (`?`), U+005E\n * CARET (`^`) to U+0060 GRAVE ACCENT (`` ` ``), or U+007B LEFT CURLY BRACE\n * (`{`) to U+007E TILDE (`~`).\n *\n * See:\n * **\\[RFC5322]**:\n * [Internet Message Format](https://tools.ietf.org/html/rfc5322).\n * P. Resnick.\n * IETF.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiAtext = regexCheck(/[#-'*+\\--9=?A-Z^-~]/)\n\n/**\n * Check whether a character code is an ASCII control character.\n *\n * An **ASCII control** is a character in the inclusive range U+0000 NULL (NUL)\n * to U+001F (US), or U+007F (DEL).\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function asciiControl(code) {\n  return (\n    // Special whitespace codes (which have negative values), C0 and Control\n    // character DEL\n    code !== null && (code < 32 || code === 127)\n  )\n}\n\n/**\n * Check whether the character code represents an ASCII digit (`0` through `9`).\n *\n * An **ASCII digit** is a character in the inclusive range U+0030 (`0`) to\n * U+0039 (`9`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiDigit = regexCheck(/\\d/)\n\n/**\n * Check whether the character code represents an ASCII hex digit (`a` through\n * `f`, case insensitive, or `0` through `9`).\n *\n * An **ASCII hex digit** is an ASCII digit (see `asciiDigit`), ASCII upper hex\n * digit, or an ASCII lower hex digit.\n *\n * An **ASCII upper hex digit** is a character in the inclusive range U+0041\n * (`A`) to U+0046 (`F`).\n *\n * An **ASCII lower hex digit** is a character in the inclusive range U+0061\n * (`a`) to U+0066 (`f`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiHexDigit = regexCheck(/[\\dA-Fa-f]/)\n\n/**\n * Check whether the character code represents ASCII punctuation.\n *\n * An **ASCII punctuation** is a character in the inclusive ranges U+0021\n * EXCLAMATION MARK (`!`) to U+002F SLASH (`/`), U+003A COLON (`:`) to U+0040 AT\n * SIGN (`@`), U+005B LEFT SQUARE BRACKET (`[`) to U+0060 GRAVE ACCENT\n * (`` ` ``), or U+007B LEFT CURLY BRACE (`{`) to U+007E TILDE (`~`).\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/)\n\n/**\n * Check whether a character code is a markdown line ending.\n *\n * A **markdown line ending** is the virtual characters M-0003 CARRIAGE RETURN\n * LINE FEED (CRLF), M-0004 LINE FEED (LF) and M-0005 CARRIAGE RETURN (CR).\n *\n * In micromark, the actual character U+000A LINE FEED (LF) and U+000D CARRIAGE\n * RETURN (CR) are replaced by these virtual characters depending on whether\n * they occurred together.\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownLineEnding(code) {\n  return code !== null && code < -2\n}\n\n/**\n * Check whether a character code is a markdown line ending (see\n * `markdownLineEnding`) or markdown space (see `markdownSpace`).\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownLineEndingOrSpace(code) {\n  return code !== null && (code < 0 || code === 32)\n}\n\n/**\n * Check whether a character code is a markdown space.\n *\n * A **markdown space** is the concrete character U+0020 SPACE (SP) and the\n * virtual characters M-0001 VIRTUAL SPACE (VS) and M-0002 HORIZONTAL TAB (HT).\n *\n * In micromark, the actual character U+0009 CHARACTER TABULATION (HT) is\n * replaced by one M-0002 HORIZONTAL TAB (HT) and between 0 and 3 M-0001 VIRTUAL\n * SPACE (VS) characters, depending on the column at which the tab occurred.\n *\n * @param {Code} code\n *   Code.\n * @returns {boolean}\n *   Whether it matches.\n */\nexport function markdownSpace(code) {\n  return code === -2 || code === -1 || code === 32\n}\n\n// Size note: removing ASCII from the regex and using `asciiPunctuation` here\n// In fact adds to the bundle size.\n/**\n * Check whether the character code represents Unicode punctuation.\n *\n * A **Unicode punctuation** is a character in the Unicode `Pc` (Punctuation,\n * Connector), `Pd` (Punctuation, Dash), `Pe` (Punctuation, Close), `Pf`\n * (Punctuation, Final quote), `Pi` (Punctuation, Initial quote), `Po`\n * (Punctuation, Other), or `Ps` (Punctuation, Open) categories, or an ASCII\n * punctuation (see `asciiPunctuation`).\n *\n * See:\n * **\\[UNICODE]**:\n * [The Unicode Standard](https://www.unicode.org/versions/).\n * Unicode Consortium.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const unicodePunctuation = regexCheck(unicodePunctuationRegex)\n\n/**\n * Check whether the character code represents Unicode whitespace.\n *\n * Note that this does handle micromark specific markdown whitespace characters.\n * See `markdownLineEndingOrSpace` to check that.\n *\n * A **Unicode whitespace** is a character in the Unicode `Zs` (Separator,\n * Space) category, or U+0009 CHARACTER TABULATION (HT), U+000A LINE FEED (LF),\n * U+000C (FF), or U+000D CARRIAGE RETURN (CR) (**\\[UNICODE]**).\n *\n * See:\n * **\\[UNICODE]**:\n * [The Unicode Standard](https://www.unicode.org/versions/).\n * Unicode Consortium.\n *\n * @param code\n *   Code.\n * @returns\n *   Whether it matches.\n */\nexport const unicodeWhitespace = regexCheck(/\\s/)\n\n/**\n * Create a code check from a regex.\n *\n * @param {RegExp} regex\n * @returns {(code: Code) => boolean}\n */\nfunction regexCheck(regex) {\n  return check\n\n  /**\n   * Check whether a code matches the bound regex.\n   *\n   * @param {Code} code\n   *   Character code.\n   * @returns {boolean}\n   *   Whether the character code matches the bound regex.\n   */\n  function check(code) {\n    return code !== null && regex.test(String.fromCharCode(code))\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Token} Token\n */\n\nimport {splice} from 'micromark-util-chunked'\n/**\n * Tokenize subcontent.\n *\n * @param {Array<Event>} events\n *   List of events.\n * @returns {boolean}\n *   Whether subtokens were found.\n */\nexport function subtokenize(events) {\n  /** @type {Record<string, number>} */\n  const jumps = {}\n  let index = -1\n  /** @type {Event} */\n  let event\n  /** @type {number | undefined} */\n  let lineIndex\n  /** @type {number} */\n  let otherIndex\n  /** @type {Event} */\n  let otherEvent\n  /** @type {Array<Event>} */\n  let parameters\n  /** @type {Array<Event>} */\n  let subevents\n  /** @type {boolean | undefined} */\n  let more\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index]\n    }\n    event = events[index]\n\n    // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n    if (\n      index &&\n      event[1].type === 'chunkFlow' &&\n      events[index - 1][1].type === 'listItemPrefix'\n    ) {\n      subevents = event[1]._tokenizer.events\n      otherIndex = 0\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === 'lineEndingBlank'\n      ) {\n        otherIndex += 2\n      }\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === 'content'\n      ) {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === 'content') {\n            break\n          }\n          if (subevents[otherIndex][1].type === 'chunkText') {\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true\n            otherIndex++\n          }\n        }\n      }\n    }\n\n    // Enter.\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        Object.assign(jumps, subcontent(events, index))\n        index = jumps[index]\n        more = true\n      }\n    }\n    // Exit.\n    else if (event[1]._container) {\n      otherIndex = index\n      lineIndex = undefined\n      while (otherIndex--) {\n        otherEvent = events[otherIndex]\n        if (\n          otherEvent[1].type === 'lineEnding' ||\n          otherEvent[1].type === 'lineEndingBlank'\n        ) {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events[lineIndex][1].type = 'lineEndingBlank'\n            }\n            otherEvent[1].type = 'lineEnding'\n            lineIndex = otherIndex\n          }\n        } else {\n          break\n        }\n      }\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = Object.assign({}, events[lineIndex][1].start)\n\n        // Switch container exit w/ line endings.\n        parameters = events.slice(lineIndex, index)\n        parameters.unshift(event)\n        splice(events, lineIndex, index - lineIndex + 1, parameters)\n      }\n    }\n  }\n  return !more\n}\n\n/**\n * Tokenize embedded tokens.\n *\n * @param {Array<Event>} events\n * @param {number} eventIndex\n * @returns {Record<string, number>}\n */\nfunction subcontent(events, eventIndex) {\n  const token = events[eventIndex][1]\n  const context = events[eventIndex][2]\n  let startPosition = eventIndex - 1\n  /** @type {Array<number>} */\n  const startPositions = []\n  const tokenizer =\n    token._tokenizer || context.parser[token.contentType](token.start)\n  const childEvents = tokenizer.events\n  /** @type {Array<[number, number]>} */\n  const jumps = []\n  /** @type {Record<string, number>} */\n  const gaps = {}\n  /** @type {Array<Chunk>} */\n  let stream\n  /** @type {Token | undefined} */\n  let previous\n  let index = -1\n  /** @type {Token | undefined} */\n  let current = token\n  let adjust = 0\n  let start = 0\n  const breaks = [start]\n\n  // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n  while (current) {\n    // Find the position of the event for this token.\n    while (events[++startPosition][1] !== current) {\n      // Empty.\n    }\n    startPositions.push(startPosition)\n    if (!current._tokenizer) {\n      stream = context.sliceStream(current)\n      if (!current.next) {\n        stream.push(null)\n      }\n      if (previous) {\n        tokenizer.defineSkip(current.start)\n      }\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true\n      }\n      tokenizer.write(stream)\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined\n      }\n    }\n\n    // Unravel the next token.\n    previous = current\n    current = current.next\n  }\n\n  // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n  current = token\n  while (++index < childEvents.length) {\n    if (\n      // Find a void token that includes a break.\n      childEvents[index][0] === 'exit' &&\n      childEvents[index - 1][0] === 'enter' &&\n      childEvents[index][1].type === childEvents[index - 1][1].type &&\n      childEvents[index][1].start.line !== childEvents[index][1].end.line\n    ) {\n      start = index + 1\n      breaks.push(start)\n      // Help GC.\n      current._tokenizer = undefined\n      current.previous = undefined\n      current = current.next\n    }\n  }\n\n  // Help GC.\n  tokenizer.events = []\n\n  // If there‚Äôs one more token (which is the cases for lines that end in an\n  // EOF), that‚Äôs perfect: the last point we found starts it.\n  // If there isn‚Äôt then make sure any remaining content is added to it.\n  if (current) {\n    // Help GC.\n    current._tokenizer = undefined\n    current.previous = undefined\n  } else {\n    breaks.pop()\n  }\n\n  // Now splice the events from the subtokenizer into the current events,\n  // moving back to front so that splice indices aren‚Äôt affected.\n  index = breaks.length\n  while (index--) {\n    const slice = childEvents.slice(breaks[index], breaks[index + 1])\n    const start = startPositions.pop()\n    jumps.unshift([start, start + slice.length - 1])\n    splice(events, start, 2, slice)\n  }\n  index = -1\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1]\n    adjust += jumps[index][1] - jumps[index][0] - 1\n  }\n  return gaps\n}\n","/**\n * Like `Array#splice`, but smarter for giant arrays.\n *\n * `Array#splice` takes all items to be inserted as individual argument which\n * causes a stack overflow in V8 when trying to insert 100k items for instance.\n *\n * Otherwise, this does not return the removed items, and takes `items` as an\n * array instead of rest parameters.\n *\n * @template {unknown} T\n *   Item type.\n * @param {Array<T>} list\n *   List to operate on.\n * @param {number} start\n *   Index to remove/insert at (can be negative).\n * @param {number} remove\n *   Number of items to remove.\n * @param {Array<T>} items\n *   Items to inject into `list`.\n * @returns {void}\n *   Nothing.\n */\nexport function splice(list, start, remove, items) {\n  const end = list.length\n  let chunkStart = 0\n  /** @type {Array<unknown>} */\n  let parameters\n\n  // Make start between zero and `end` (included).\n  if (start < 0) {\n    start = -start > end ? 0 : end + start\n  } else {\n    start = start > end ? end : start\n  }\n  remove = remove > 0 ? remove : 0\n\n  // No need to chunk the items if there‚Äôs only a couple (10k) items.\n  if (items.length < 10000) {\n    parameters = Array.from(items)\n    parameters.unshift(start, remove)\n    // @ts-expect-error Hush, it‚Äôs fine.\n    list.splice(...parameters)\n  } else {\n    // Delete `remove` items starting from `start`\n    if (remove) list.splice(start, remove)\n\n    // Insert the items in chunks to not cause stack overflows.\n    while (chunkStart < items.length) {\n      parameters = items.slice(chunkStart, chunkStart + 10000)\n      parameters.unshift(start, 0)\n      // @ts-expect-error Hush, it‚Äôs fine.\n      list.splice(...parameters)\n      chunkStart += 10000\n      start += 10000\n    }\n  }\n}\n\n/**\n * Append `items` (an array) at the end of `list` (another array).\n * When `list` was empty, returns `items` instead.\n *\n * This prevents a potentially expensive operation when `list` is empty,\n * and adds items in batches to prevent V8 from hanging.\n *\n * @template {unknown} T\n *   Item type.\n * @param {Array<T>} list\n *   List to operate on.\n * @param {Array<T>} items\n *   Items to add to `list`.\n * @returns {Array<T>}\n *   Either `list` or `items`.\n */\nexport function push(list, items) {\n  if (list.length > 0) {\n    splice(list, list.length, 0, items)\n    return list\n  }\n  return items\n}\n","/**\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * Call all `resolveAll`s.\n *\n * @param {Array<{resolveAll?: Resolver | undefined}>} constructs\n *   List of constructs, optionally with `resolveAll`s.\n * @param {Array<Event>} events\n *   List of events.\n * @param {TokenizeContext} context\n *   Context used by `tokenize`.\n * @returns {Array<Event>}\n *   Changed events.\n */\nexport function resolveAll(constructs, events, context) {\n  /** @type {Array<Resolver>} */\n  const called = []\n  let index = -1\n\n  while (++index < constructs.length) {\n    const resolve = constructs[index].resolveAll\n\n    if (resolve && !called.includes(resolve)) {\n      events = resolve(events, context)\n      called.push(resolve)\n    }\n  }\n\n  return events\n}\n"],"names":["classifyCharacter","code","markdownLineEndingOrSpace","unicodeWhitespace","unicodePunctuation","htmlBlockNames","htmlRawNames","normalizeIdentifier","value","replace","toLowerCase","toUpperCase","hasOwnProperty","combineExtensions","extensions","all","index","length","syntaxExtension","extension","hook","left","call","undefined","right","constructs","Array","isArray","existing","list","before","add","push","splice","asciiAlpha","regexCheck","asciiAlphanumeric","asciiAtext","asciiControl","asciiDigit","asciiHexDigit","asciiPunctuation","markdownLineEnding","markdownSpace","regex","test","String","fromCharCode","subtokenize","events","jumps","event","lineIndex","otherIndex","otherEvent","parameters","subevents","more","type","_tokenizer","_isInFirstContentOfListItem","contentType","Object","assign","subcontent","_container","end","start","slice","unshift","eventIndex","token","context","startPosition","startPositions","tokenizer","parser","childEvents","gaps","stream","previous","current","adjust","breaks","sliceStream","next","defineSkip","_gfmTasklistFirstContentOfListItem","write","line","pop","remove","items","chunkStart","from","resolveAll","called","resolve","includes"],"sourceRoot":""}