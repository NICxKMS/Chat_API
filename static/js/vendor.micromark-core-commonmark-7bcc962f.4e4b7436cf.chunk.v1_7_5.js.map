{"version":3,"file":"static/js/vendor.micromark-core-commonmark-7bcc962f.4e4b7436cf.chunk.v1_7_5.js","mappings":"kKAWO,MAAMA,EAAa,CACxBC,KAAM,aACNC,SAWF,SAAiCC,EAASC,EAAIC,GAC5C,MAAMC,EAAOC,KACb,OAYA,SAAeC,GACb,GAAa,KAATA,EAAa,CACf,MAAMC,EAAQH,EAAKI,eAWnB,OAVKD,EAAME,OACTR,EAAQS,MAAM,aAAc,CAC1BC,YAAY,IAEdJ,EAAME,MAAO,GAEfR,EAAQS,MAAM,oBACdT,EAAQS,MAAM,oBACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,oBACNC,CACT,CACA,OAAOX,EAAIG,EACb,EAYA,SAASQ,EAAMR,GACb,OAAIS,EAAAA,EAAAA,IAAcT,IAChBL,EAAQS,MAAM,8BACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,8BACbZ,EAAQY,KAAK,oBACNX,IAETD,EAAQY,KAAK,oBACNX,EAAGI,GACZ,CACF,EA/DEU,aAAc,CACZhB,SA4EJ,SAAwCC,EAASC,EAAIC,GACnD,MAAMC,EAAOC,KACb,OAeA,SAAmBC,GACjB,IAAIS,EAAAA,EAAAA,IAAcT,GAGhB,OAAOW,EAAAA,EAAAA,GACLhB,EACAiB,EACA,aACAd,EAAKe,OAAOC,WAAWC,QAAQC,KAAKC,SAAS,qBACzCC,EACA,EANCP,CAOLX,GAEJ,OAAOY,EAAWZ,EACpB,EAeA,SAASY,EAAWZ,GAClB,OAAOL,EAAQwB,QAAQ3B,EAAYI,EAAIC,EAAhCF,CAAqCK,EAC9C,CACF,GA3HEO,KA8HF,SAAcZ,GACZA,EAAQY,KAAK,aACf,E,6DClIO,MAAMa,EAAqB,CAChC3B,KAAM,qBACNC,SAOF,SAAoCC,EAASC,EAAIC,GAC/C,MAAMC,EAAOC,KACb,IAEIsB,EAEAC,EAJAC,EAAO,EAKX,OAgBA,SAAevB,GAKb,OAJAL,EAAQS,MAAM,sBACdT,EAAQS,MAAM,4BACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,4BACNJ,CACT,EAiBA,SAASA,EAAKH,GACZ,OAAa,KAATA,GACFL,EAAQS,MAAM,mCACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,mCACNiB,IAET7B,EAAQS,MAAM,2BACdiB,EAAM,GACNC,EAAOG,EAAAA,GACAC,EAAM1B,GACf,CAcA,SAASwB,EAAQxB,GACf,OAAa,KAATA,GAAwB,MAATA,GACjBL,EAAQS,MAAM,uCACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,uCACbZ,EAAQS,MAAM,2BACdiB,EAAM,EACNC,EAAOK,EAAAA,GACAD,IAET/B,EAAQS,MAAM,2BACdiB,EAAM,EACNC,EAAOM,EAAAA,GACAF,EAAM1B,GACf,CAmBA,SAAS0B,EAAM1B,GACb,GAAa,KAATA,GAAeuB,EAAM,CACvB,MAAMM,EAAQlC,EAAQY,KAAK,2BAC3B,OACEe,IAASG,EAAAA,KACRK,EAAAA,EAAAA,GAA8BhC,EAAKiC,eAAeF,KAOrDlC,EAAQS,MAAM,4BACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,4BACbZ,EAAQY,KAAK,sBACNX,GATEC,EAAIG,EAUf,CACA,OAAIsB,EAAKtB,IAASuB,IAASF,GACzB1B,EAAQW,QAAQN,GACT0B,GAEF7B,EAAIG,EACb,CACF,E,kDC/IO,MAAMgC,EAAkB,CAC7BvC,KAAM,kBACNC,SAOF,SAAiCC,EAASC,EAAIC,GAC5C,OAYA,SAAeG,GAKb,OAJAL,EAAQS,MAAM,mBACdT,EAAQS,MAAM,gBACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,gBACN0B,CACT,EAYA,SAASA,EAAOjC,GAEd,OAAIkC,EAAAA,EAAAA,IAAiBlC,IACnBL,EAAQS,MAAM,wBACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,wBACbZ,EAAQY,KAAK,mBACNX,GAEFC,EAAIG,EACb,CACF,E,6DClDO,MAAMmC,EAAY,CACvBzC,SAQF,SAA2BC,EAASC,EAAIC,GACtC,OAgBA,SAAeG,GACb,OAAOS,EAAAA,EAAAA,IAAcT,IACjBW,EAAAA,EAAAA,GAAahB,EAASa,EAAO,aAA7BG,CAA2CX,GAC3CQ,EAAMR,EACZ,EAgBA,SAASQ,EAAMR,GACb,OAAgB,OAATA,IAAiBoC,EAAAA,EAAAA,IAAmBpC,GAAQJ,EAAGI,GAAQH,EAAIG,EACpE,CACF,EA/CEqC,SAAS,E,kDCEJ,MAAMC,EAAW,CACtB7C,KAAM,WACNC,SAOF,SAA0BC,EAASC,EAAIC,GACrC,IAAI0B,EAAO,EACX,OAcA,SAAevB,GAMb,OALAL,EAAQS,MAAM,YACdT,EAAQS,MAAM,kBACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,kBACbZ,EAAQS,MAAM,oBACPD,CACT,EAcA,SAASA,EAAKH,GACZ,OAAIuC,EAAAA,EAAAA,IAAWvC,IACbL,EAAQW,QAAQN,GACTwC,GAEFC,EAAWzC,EACpB,CAcA,SAASwC,EAAmBxC,GAE1B,OAAa,KAATA,GAAwB,KAATA,GAAwB,KAATA,IAAeyB,EAAAA,EAAAA,IAAkBzB,IAEjEuB,EAAO,EACAmB,EAAyB1C,IAE3ByC,EAAWzC,EACpB,CAcA,SAAS0C,EAAyB1C,GAChC,OAAa,KAATA,GACFL,EAAQW,QAAQN,GAChBuB,EAAO,EACAoB,IAKG,KAAT3C,GAAwB,KAATA,GAAwB,KAATA,IAAeyB,EAAAA,EAAAA,IAAkBzB,KAChEuB,IAAS,IAET5B,EAAQW,QAAQN,GACT0C,IAETnB,EAAO,EACAkB,EAAWzC,GACpB,CAYA,SAAS2C,EAAU3C,GACjB,OAAa,KAATA,GACFL,EAAQY,KAAK,oBACbZ,EAAQS,MAAM,kBACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,kBACbZ,EAAQY,KAAK,YACNX,GAII,OAATI,GAA0B,KAATA,GAAwB,KAATA,IAAe4C,EAAAA,EAAAA,IAAa5C,GACvDH,EAAIG,IAEbL,EAAQW,QAAQN,GACT2C,EACT,CAYA,SAASF,EAAWzC,GAClB,OAAa,KAATA,GACFL,EAAQW,QAAQN,GACT6C,IAELC,EAAAA,EAAAA,IAAW9C,IACbL,EAAQW,QAAQN,GACTyC,GAEF5C,EAAIG,EACb,CAYA,SAAS6C,EAAiB7C,GACxB,OAAOyB,EAAAA,EAAAA,IAAkBzB,GAAQ+C,EAAW/C,GAAQH,EAAIG,EAC1D,CAYA,SAAS+C,EAAW/C,GAClB,OAAa,KAATA,GACFL,EAAQW,QAAQN,GAChBuB,EAAO,EACAsB,GAEI,KAAT7C,GAEFL,EAAQY,KAAK,oBAAoByC,KAAO,gBACxCrD,EAAQS,MAAM,kBACdT,EAAQW,QAAQN,GAChBL,EAAQY,KAAK,kBACbZ,EAAQY,KAAK,YACNX,GAEFqD,EAAWjD,EACpB,CAcA,SAASiD,EAAWjD,GAElB,IAAc,KAATA,IAAeyB,EAAAA,EAAAA,IAAkBzB,KAAUuB,IAAS,GAAI,CAC3D,MAAM2B,EAAgB,KAATlD,EAAciD,EAAaF,EAExC,OADApD,EAAQW,QAAQN,GACTkD,CACT,CACA,OAAOrD,EAAIG,EACb,CACF,E,uEC1NO,MAAMmD,EAAY,CACvB1D,KAAM,YACNC,SA4KF,SAA2BC,EAASC,GAClC,MAAMwD,EAAmBrD,KAAKc,OAAOC,WAAWsC,iBAAiBpC,KAC3DqC,EAAWtD,KAAKsD,SAChBC,GAASC,EAAAA,EAAAA,GAAkBF,GAGjC,IAAIG,EACJ,OAYA,SAAexD,GAGb,OAFAwD,EAASxD,EACTL,EAAQS,MAAM,qBACP6B,EAAOjC,EAChB,EAYA,SAASiC,EAAOjC,GACd,GAAIA,IAASwD,EAEX,OADA7D,EAAQW,QAAQN,GACTiC,EAET,MAAMJ,EAAQlC,EAAQY,KAAK,qBAGrBC,GAAQ+C,EAAAA,EAAAA,GAAkBvD,GAI1BG,GACHK,GAAoB,IAAVA,GAAe8C,GAAWF,EAAiBnC,SAASjB,GAC3DyD,GACHH,GAAsB,IAAXA,GAAgB9C,GAAU4C,EAAiBnC,SAASoC,GAGlE,OAFAxB,EAAM6B,MAAQC,QAAmB,KAAXH,EAAgBrD,EAAOA,IAASmD,IAAWG,IACjE5B,EAAM+B,OAASD,QAAmB,KAAXH,EAAgBC,EAAQA,IAAUjD,IAAUL,IAC5DP,EAAGI,EACZ,CACF,EAlOE6D,WAQF,SAA6BC,EAAQC,GACnC,IAEI5D,EAEA6D,EAEAC,EAEAC,EAEAC,EAEAC,EAEAC,EAEAC,EAhBAC,GAAS,EAsBb,OAASA,EAAQT,EAAOU,QAEtB,GACuB,UAArBV,EAAOS,GAAO,IACY,sBAA1BT,EAAOS,GAAO,GAAGvB,MACjBc,EAAOS,GAAO,GAAGX,OAKjB,IAHAzD,EAAOoE,EAGApE,KAEL,GACsB,SAApB2D,EAAO3D,GAAM,IACY,sBAAzB2D,EAAO3D,GAAM,GAAG6C,MAChBc,EAAO3D,GAAM,GAAGuD,OAEhBK,EAAQhC,eAAe+B,EAAO3D,GAAM,IAAIsE,WAAW,KACjDV,EAAQhC,eAAe+B,EAAOS,GAAO,IAAIE,WAAW,GACtD,CAKA,IACGX,EAAO3D,GAAM,GAAGyD,QAAUE,EAAOS,GAAO,GAAGb,SAC3CI,EAAOS,GAAO,GAAGG,IAAIJ,OAASR,EAAOS,GAAO,GAAGI,MAAML,QAAU,MAE7DR,EAAO3D,GAAM,GAAGuE,IAAIJ,OACnBR,EAAO3D,GAAM,GAAGwE,MAAML,OACtBR,EAAOS,GAAO,GAAGG,IAAIJ,OACrBR,EAAOS,GAAO,GAAGI,MAAML,QACzB,GAGF,SAIFF,EACEN,EAAO3D,GAAM,GAAGuE,IAAIJ,OAASR,EAAO3D,GAAM,GAAGwE,MAAML,OAAS,GAC5DR,EAAOS,GAAO,GAAGG,IAAIJ,OAASR,EAAOS,GAAO,GAAGI,MAAML,OAAS,EAC1D,EACA,EACN,MAAMK,EAAQC,OAAOC,OAAO,CAAC,EAAGf,EAAO3D,GAAM,GAAGuE,KAC1CA,EAAME,OAAOC,OAAO,CAAC,EAAGf,EAAOS,GAAO,GAAGI,OAC/CG,EAAUH,GAAQP,GAClBU,EAAUJ,EAAKN,GACfF,EAAkB,CAChBlB,KAAMoB,EAAM,EAAI,iBAAmB,mBACnCO,QACAD,IAAKE,OAAOC,OAAO,CAAC,EAAGf,EAAO3D,GAAM,GAAGuE,MAEzCP,EAAkB,CAChBnB,KAAMoB,EAAM,EAAI,iBAAmB,mBACnCO,MAAOC,OAAOC,OAAO,CAAC,EAAGf,EAAOS,GAAO,GAAGI,OAC1CD,OAEFT,EAAO,CACLjB,KAAMoB,EAAM,EAAI,aAAe,eAC/BO,MAAOC,OAAOC,OAAO,CAAC,EAAGf,EAAO3D,GAAM,GAAGuE,KACzCA,IAAKE,OAAOC,OAAO,CAAC,EAAGf,EAAOS,GAAO,GAAGI,QAE1CX,EAAQ,CACNhB,KAAMoB,EAAM,EAAI,SAAW,WAC3BO,MAAOC,OAAOC,OAAO,CAAC,EAAGX,EAAgBS,OACzCD,IAAKE,OAAOC,OAAO,CAAC,EAAGV,EAAgBO,MAEzCZ,EAAO3D,GAAM,GAAGuE,IAAME,OAAOC,OAAO,CAAC,EAAGX,EAAgBS,OACxDb,EAAOS,GAAO,GAAGI,MAAQC,OAAOC,OAAO,CAAC,EAAGV,EAAgBO,KAC3DL,EAAa,GAGTP,EAAO3D,GAAM,GAAGuE,IAAIJ,OAASR,EAAO3D,GAAM,GAAGwE,MAAML,SACrDD,GAAaU,EAAAA,EAAAA,GAAKV,EAAY,CAC5B,CAAC,QAASP,EAAO3D,GAAM,GAAI4D,GAC3B,CAAC,OAAQD,EAAO3D,GAAM,GAAI4D,MAK9BM,GAAaU,EAAAA,EAAAA,GAAKV,EAAY,CAC5B,CAAC,QAASL,EAAOD,GACjB,CAAC,QAASG,EAAiBH,GAC3B,CAAC,OAAQG,EAAiBH,GAC1B,CAAC,QAASE,EAAMF,KAMlBM,GAAaU,EAAAA,EAAAA,GACXV,GACAR,EAAAA,EAAAA,GACEE,EAAQlD,OAAOC,WAAWkE,WAAWhE,KACrC8C,EAAOmB,MAAM9E,EAAO,EAAGoE,GACvBR,IAKJM,GAAaU,EAAAA,EAAAA,GAAKV,EAAY,CAC5B,CAAC,OAAQJ,EAAMF,GACf,CAAC,QAASI,EAAiBJ,GAC3B,CAAC,OAAQI,EAAiBJ,GAC1B,CAAC,OAAQC,EAAOD,KAIdD,EAAOS,GAAO,GAAGG,IAAIJ,OAASR,EAAOS,GAAO,GAAGI,MAAML,QACvDA,EAAS,EACTD,GAAaU,EAAAA,EAAAA,GAAKV,EAAY,CAC5B,CAAC,QAASP,EAAOS,GAAO,GAAIR,GAC5B,CAAC,OAAQD,EAAOS,GAAO,GAAIR,MAG7BO,EAAS,GAEXY,EAAAA,EAAAA,GAAOpB,EAAQ3D,EAAO,EAAGoE,EAAQpE,EAAO,EAAGkE,GAC3CE,EAAQpE,EAAOkE,EAAWG,OAASF,EAAS,EAC5C,KACF,CAMNC,GAAS,EACT,OAASA,EAAQT,EAAOU,QACQ,sBAA1BV,EAAOS,GAAO,GAAGvB,OACnBc,EAAOS,GAAO,GAAGvB,KAAO,QAG5B,OAAOc,CACT,GAyEA,SAASgB,EAAUK,EAAOb,GACxBa,EAAMC,QAAUd,EAChBa,EAAMb,QAAUA,EAChBa,EAAME,cAAgBf,CACxB,C","sources":["../node_modules/micromark-core-commonmark/lib/block-quote.js","../node_modules/micromark-core-commonmark/lib/character-reference.js","../node_modules/micromark-core-commonmark/lib/character-escape.js","../node_modules/micromark-core-commonmark/lib/blank-line.js","../node_modules/micromark-core-commonmark/lib/autolink.js","../node_modules/micromark-core-commonmark/lib/attention.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Exiter} Exiter\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownSpace} from 'micromark-util-character'\n/** @type {Construct} */\nexport const blockQuote = {\n  name: 'blockQuote',\n  tokenize: tokenizeBlockQuoteStart,\n  continuation: {\n    tokenize: tokenizeBlockQuoteContinuation\n  },\n  exit\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeBlockQuoteStart(effects, ok, nok) {\n  const self = this\n  return start\n\n  /**\n   * Start of block quote.\n   *\n   * ```markdown\n   * > | > a\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (code === 62) {\n      const state = self.containerState\n      if (!state.open) {\n        effects.enter('blockQuote', {\n          _container: true\n        })\n        state.open = true\n      }\n      effects.enter('blockQuotePrefix')\n      effects.enter('blockQuoteMarker')\n      effects.consume(code)\n      effects.exit('blockQuoteMarker')\n      return after\n    }\n    return nok(code)\n  }\n\n  /**\n   * After `>`, before optional whitespace.\n   *\n   * ```markdown\n   * > | > a\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    if (markdownSpace(code)) {\n      effects.enter('blockQuotePrefixWhitespace')\n      effects.consume(code)\n      effects.exit('blockQuotePrefixWhitespace')\n      effects.exit('blockQuotePrefix')\n      return ok\n    }\n    effects.exit('blockQuotePrefix')\n    return ok(code)\n  }\n}\n\n/**\n * Start of block quote continuation.\n *\n * ```markdown\n *   | > a\n * > | > b\n *     ^\n * ```\n *\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeBlockQuoteContinuation(effects, ok, nok) {\n  const self = this\n  return contStart\n\n  /**\n   * Start of block quote continuation.\n   *\n   * Also used to parse the first block quote opening.\n   *\n   * ```markdown\n   *   | > a\n   * > | > b\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function contStart(code) {\n    if (markdownSpace(code)) {\n      // Always populated by defaults.\n\n      return factorySpace(\n        effects,\n        contBefore,\n        'linePrefix',\n        self.parser.constructs.disable.null.includes('codeIndented')\n          ? undefined\n          : 4\n      )(code)\n    }\n    return contBefore(code)\n  }\n\n  /**\n   * At `>`, after optional whitespace.\n   *\n   * Also used to parse the first block quote opening.\n   *\n   * ```markdown\n   *   | > a\n   * > | > b\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function contBefore(code) {\n    return effects.attempt(blockQuote, ok, nok)(code)\n  }\n}\n\n/** @type {Exiter} */\nfunction exit(effects) {\n  effects.exit('blockQuote')\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {decodeNamedCharacterReference} from 'decode-named-character-reference'\nimport {\n  asciiAlphanumeric,\n  asciiDigit,\n  asciiHexDigit\n} from 'micromark-util-character'\n/** @type {Construct} */\nexport const characterReference = {\n  name: 'characterReference',\n  tokenize: tokenizeCharacterReference\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCharacterReference(effects, ok, nok) {\n  const self = this\n  let size = 0\n  /** @type {number} */\n  let max\n  /** @type {(code: Code) => boolean} */\n  let test\n  return start\n\n  /**\n   * Start of character reference.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *      ^\n   * > | a&#123;b\n   *      ^\n   * > | a&#x9;b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('characterReference')\n    effects.enter('characterReferenceMarker')\n    effects.consume(code)\n    effects.exit('characterReferenceMarker')\n    return open\n  }\n\n  /**\n   * After `&`, at `#` for numeric references or alphanumeric for named\n   * references.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *       ^\n   * > | a&#123;b\n   *       ^\n   * > | a&#x9;b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (code === 35) {\n      effects.enter('characterReferenceMarkerNumeric')\n      effects.consume(code)\n      effects.exit('characterReferenceMarkerNumeric')\n      return numeric\n    }\n    effects.enter('characterReferenceValue')\n    max = 31\n    test = asciiAlphanumeric\n    return value(code)\n  }\n\n  /**\n   * After `#`, at `x` for hexadecimals or digit for decimals.\n   *\n   * ```markdown\n   * > | a&#123;b\n   *        ^\n   * > | a&#x9;b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function numeric(code) {\n    if (code === 88 || code === 120) {\n      effects.enter('characterReferenceMarkerHexadecimal')\n      effects.consume(code)\n      effects.exit('characterReferenceMarkerHexadecimal')\n      effects.enter('characterReferenceValue')\n      max = 6\n      test = asciiHexDigit\n      return value\n    }\n    effects.enter('characterReferenceValue')\n    max = 7\n    test = asciiDigit\n    return value(code)\n  }\n\n  /**\n   * After markers (`&#x`, `&#`, or `&`), in value, before `;`.\n   *\n   * The character reference kind defines what and how many characters are\n   * allowed.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *       ^^^\n   * > | a&#123;b\n   *        ^^^\n   * > | a&#x9;b\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function value(code) {\n    if (code === 59 && size) {\n      const token = effects.exit('characterReferenceValue')\n      if (\n        test === asciiAlphanumeric &&\n        !decodeNamedCharacterReference(self.sliceSerialize(token))\n      ) {\n        return nok(code)\n      }\n\n      // To do: `markdown-rs` uses a different name:\n      // `CharacterReferenceMarkerSemi`.\n      effects.enter('characterReferenceMarker')\n      effects.consume(code)\n      effects.exit('characterReferenceMarker')\n      effects.exit('characterReference')\n      return ok\n    }\n    if (test(code) && size++ < max) {\n      effects.consume(code)\n      return value\n    }\n    return nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {asciiPunctuation} from 'micromark-util-character'\n/** @type {Construct} */\nexport const characterEscape = {\n  name: 'characterEscape',\n  tokenize: tokenizeCharacterEscape\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeCharacterEscape(effects, ok, nok) {\n  return start\n\n  /**\n   * Start of character escape.\n   *\n   * ```markdown\n   * > | a\\*b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('characterEscape')\n    effects.enter('escapeMarker')\n    effects.consume(code)\n    effects.exit('escapeMarker')\n    return inside\n  }\n\n  /**\n   * After `\\`, at punctuation.\n   *\n   * ```markdown\n   * > | a\\*b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    // ASCII punctuation.\n    if (asciiPunctuation(code)) {\n      effects.enter('characterEscapeValue')\n      effects.consume(code)\n      effects.exit('characterEscapeValue')\n      effects.exit('characterEscape')\n      return ok\n    }\n    return nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding, markdownSpace} from 'micromark-util-character'\n/** @type {Construct} */\nexport const blankLine = {\n  tokenize: tokenizeBlankLine,\n  partial: true\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeBlankLine(effects, ok, nok) {\n  return start\n\n  /**\n   * Start of blank line.\n   *\n   * > 👉 **Note**: `␠` represents a space character.\n   *\n   * ```markdown\n   * > | ␠␠␊\n   *     ^\n   * > | ␊\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    return markdownSpace(code)\n      ? factorySpace(effects, after, 'linePrefix')(code)\n      : after(code)\n  }\n\n  /**\n   * At eof/eol, after optional whitespace.\n   *\n   * > 👉 **Note**: `␠` represents a space character.\n   *\n   * ```markdown\n   * > | ␠␠␊\n   *       ^\n   * > | ␊\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {\n  asciiAlpha,\n  asciiAlphanumeric,\n  asciiAtext,\n  asciiControl\n} from 'micromark-util-character'\n/** @type {Construct} */\nexport const autolink = {\n  name: 'autolink',\n  tokenize: tokenizeAutolink\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeAutolink(effects, ok, nok) {\n  let size = 0\n  return start\n\n  /**\n   * Start of an autolink.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *      ^\n   * > | a<user@example.com>b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter('autolink')\n    effects.enter('autolinkMarker')\n    effects.consume(code)\n    effects.exit('autolinkMarker')\n    effects.enter('autolinkProtocol')\n    return open\n  }\n\n  /**\n   * After `<`, at protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *       ^\n   * > | a<user@example.com>b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return schemeOrEmailAtext\n    }\n    return emailAtext(code)\n  }\n\n  /**\n   * At second byte of protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *        ^\n   * > | a<user@example.com>b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function schemeOrEmailAtext(code) {\n    // ASCII alphanumeric and `+`, `-`, and `.`.\n    if (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) {\n      // Count the previous alphabetical from `open` too.\n      size = 1\n      return schemeInsideOrEmailAtext(code)\n    }\n    return emailAtext(code)\n  }\n\n  /**\n   * In ambiguous protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *        ^\n   * > | a<user@example.com>b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function schemeInsideOrEmailAtext(code) {\n    if (code === 58) {\n      effects.consume(code)\n      size = 0\n      return urlInside\n    }\n\n    // ASCII alphanumeric and `+`, `-`, and `.`.\n    if (\n      (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) &&\n      size++ < 32\n    ) {\n      effects.consume(code)\n      return schemeInsideOrEmailAtext\n    }\n    size = 0\n    return emailAtext(code)\n  }\n\n  /**\n   * After protocol, in URL.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *             ^\n   * ```\n   *\n   * @type {State}\n   */\n  function urlInside(code) {\n    if (code === 62) {\n      effects.exit('autolinkProtocol')\n      effects.enter('autolinkMarker')\n      effects.consume(code)\n      effects.exit('autolinkMarker')\n      effects.exit('autolink')\n      return ok\n    }\n\n    // ASCII control, space, or `<`.\n    if (code === null || code === 32 || code === 60 || asciiControl(code)) {\n      return nok(code)\n    }\n    effects.consume(code)\n    return urlInside\n  }\n\n  /**\n   * In email atext.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *              ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailAtext(code) {\n    if (code === 64) {\n      effects.consume(code)\n      return emailAtSignOrDot\n    }\n    if (asciiAtext(code)) {\n      effects.consume(code)\n      return emailAtext\n    }\n    return nok(code)\n  }\n\n  /**\n   * In label, after at-sign or dot.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *                 ^       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailAtSignOrDot(code) {\n    return asciiAlphanumeric(code) ? emailLabel(code) : nok(code)\n  }\n\n  /**\n   * In label, where `.` and `>` are allowed.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *                   ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailLabel(code) {\n    if (code === 46) {\n      effects.consume(code)\n      size = 0\n      return emailAtSignOrDot\n    }\n    if (code === 62) {\n      // Exit, then change the token type.\n      effects.exit('autolinkProtocol').type = 'autolinkEmail'\n      effects.enter('autolinkMarker')\n      effects.consume(code)\n      effects.exit('autolinkMarker')\n      effects.exit('autolink')\n      return ok\n    }\n    return emailValue(code)\n  }\n\n  /**\n   * In label, where `.` and `>` are *not* allowed.\n   *\n   * Though, this is also used in `emailLabel` to parse other values.\n   *\n   * ```markdown\n   * > | a<user.name@ex-ample.com>b\n   *                    ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailValue(code) {\n    // ASCII alphanumeric or `-`.\n    if ((code === 45 || asciiAlphanumeric(code)) && size++ < 63) {\n      const next = code === 45 ? emailValue : emailLabel\n      effects.consume(code)\n      return next\n    }\n    return nok(code)\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {push, splice} from 'micromark-util-chunked'\nimport {classifyCharacter} from 'micromark-util-classify-character'\nimport {resolveAll} from 'micromark-util-resolve-all'\n/** @type {Construct} */\nexport const attention = {\n  name: 'attention',\n  tokenize: tokenizeAttention,\n  resolveAll: resolveAllAttention\n}\n\n/**\n * Take all events and resolve attention to emphasis or strong.\n *\n * @type {Resolver}\n */\nfunction resolveAllAttention(events, context) {\n  let index = -1\n  /** @type {number} */\n  let open\n  /** @type {Token} */\n  let group\n  /** @type {Token} */\n  let text\n  /** @type {Token} */\n  let openingSequence\n  /** @type {Token} */\n  let closingSequence\n  /** @type {number} */\n  let use\n  /** @type {Array<Event>} */\n  let nextEvents\n  /** @type {number} */\n  let offset\n\n  // Walk through all events.\n  //\n  // Note: performance of this is fine on an mb of normal markdown, but it’s\n  // a bottleneck for malicious stuff.\n  while (++index < events.length) {\n    // Find a token that can close.\n    if (\n      events[index][0] === 'enter' &&\n      events[index][1].type === 'attentionSequence' &&\n      events[index][1]._close\n    ) {\n      open = index\n\n      // Now walk back to find an opener.\n      while (open--) {\n        // Find a token that can open the closer.\n        if (\n          events[open][0] === 'exit' &&\n          events[open][1].type === 'attentionSequence' &&\n          events[open][1]._open &&\n          // If the markers are the same:\n          context.sliceSerialize(events[open][1]).charCodeAt(0) ===\n            context.sliceSerialize(events[index][1]).charCodeAt(0)\n        ) {\n          // If the opening can close or the closing can open,\n          // and the close size *is not* a multiple of three,\n          // but the sum of the opening and closing size *is* multiple of three,\n          // then don’t match.\n          if (\n            (events[open][1]._close || events[index][1]._open) &&\n            (events[index][1].end.offset - events[index][1].start.offset) % 3 &&\n            !(\n              (events[open][1].end.offset -\n                events[open][1].start.offset +\n                events[index][1].end.offset -\n                events[index][1].start.offset) %\n              3\n            )\n          ) {\n            continue\n          }\n\n          // Number of markers to use from the sequence.\n          use =\n            events[open][1].end.offset - events[open][1].start.offset > 1 &&\n            events[index][1].end.offset - events[index][1].start.offset > 1\n              ? 2\n              : 1\n          const start = Object.assign({}, events[open][1].end)\n          const end = Object.assign({}, events[index][1].start)\n          movePoint(start, -use)\n          movePoint(end, use)\n          openingSequence = {\n            type: use > 1 ? 'strongSequence' : 'emphasisSequence',\n            start,\n            end: Object.assign({}, events[open][1].end)\n          }\n          closingSequence = {\n            type: use > 1 ? 'strongSequence' : 'emphasisSequence',\n            start: Object.assign({}, events[index][1].start),\n            end\n          }\n          text = {\n            type: use > 1 ? 'strongText' : 'emphasisText',\n            start: Object.assign({}, events[open][1].end),\n            end: Object.assign({}, events[index][1].start)\n          }\n          group = {\n            type: use > 1 ? 'strong' : 'emphasis',\n            start: Object.assign({}, openingSequence.start),\n            end: Object.assign({}, closingSequence.end)\n          }\n          events[open][1].end = Object.assign({}, openingSequence.start)\n          events[index][1].start = Object.assign({}, closingSequence.end)\n          nextEvents = []\n\n          // If there are more markers in the opening, add them before.\n          if (events[open][1].end.offset - events[open][1].start.offset) {\n            nextEvents = push(nextEvents, [\n              ['enter', events[open][1], context],\n              ['exit', events[open][1], context]\n            ])\n          }\n\n          // Opening.\n          nextEvents = push(nextEvents, [\n            ['enter', group, context],\n            ['enter', openingSequence, context],\n            ['exit', openingSequence, context],\n            ['enter', text, context]\n          ])\n\n          // Always populated by defaults.\n\n          // Between.\n          nextEvents = push(\n            nextEvents,\n            resolveAll(\n              context.parser.constructs.insideSpan.null,\n              events.slice(open + 1, index),\n              context\n            )\n          )\n\n          // Closing.\n          nextEvents = push(nextEvents, [\n            ['exit', text, context],\n            ['enter', closingSequence, context],\n            ['exit', closingSequence, context],\n            ['exit', group, context]\n          ])\n\n          // If there are more markers in the closing, add them after.\n          if (events[index][1].end.offset - events[index][1].start.offset) {\n            offset = 2\n            nextEvents = push(nextEvents, [\n              ['enter', events[index][1], context],\n              ['exit', events[index][1], context]\n            ])\n          } else {\n            offset = 0\n          }\n          splice(events, open - 1, index - open + 3, nextEvents)\n          index = open + nextEvents.length - offset - 2\n          break\n        }\n      }\n    }\n  }\n\n  // Remove remaining sequences.\n  index = -1\n  while (++index < events.length) {\n    if (events[index][1].type === 'attentionSequence') {\n      events[index][1].type = 'data'\n    }\n  }\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeAttention(effects, ok) {\n  const attentionMarkers = this.parser.constructs.attentionMarkers.null\n  const previous = this.previous\n  const before = classifyCharacter(previous)\n\n  /** @type {NonNullable<Code>} */\n  let marker\n  return start\n\n  /**\n   * Before a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    marker = code\n    effects.enter('attentionSequence')\n    return inside(code)\n  }\n\n  /**\n   * In a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === marker) {\n      effects.consume(code)\n      return inside\n    }\n    const token = effects.exit('attentionSequence')\n\n    // To do: next major: move this to resolver, just like `markdown-rs`.\n    const after = classifyCharacter(code)\n\n    // Always populated by defaults.\n\n    const open =\n      !after || (after === 2 && before) || attentionMarkers.includes(code)\n    const close =\n      !before || (before === 2 && after) || attentionMarkers.includes(previous)\n    token._open = Boolean(marker === 42 ? open : open && (before || !close))\n    token._close = Boolean(marker === 42 ? close : close && (after || !open))\n    return ok(code)\n  }\n}\n\n/**\n * Move a point a bit.\n *\n * Note: `move` only works inside lines! It’s not possible to move past other\n * chunks (replacement characters, tabs, or line endings).\n *\n * @param {Point} point\n * @param {number} offset\n * @returns {void}\n */\nfunction movePoint(point, offset) {\n  point.column += offset\n  point.offset += offset\n  point._bufferIndex += offset\n}\n"],"names":["blockQuote","name","tokenize","effects","ok","nok","self","this","code","state","containerState","open","enter","_container","consume","exit","after","markdownSpace","continuation","factorySpace","contBefore","parser","constructs","disable","null","includes","undefined","attempt","characterReference","max","test","size","numeric","asciiAlphanumeric","value","asciiHexDigit","asciiDigit","token","decodeNamedCharacterReference","sliceSerialize","characterEscape","inside","asciiPunctuation","blankLine","markdownLineEnding","partial","autolink","asciiAlpha","schemeOrEmailAtext","emailAtext","schemeInsideOrEmailAtext","urlInside","asciiControl","emailAtSignOrDot","asciiAtext","emailLabel","type","emailValue","next","attention","attentionMarkers","previous","before","classifyCharacter","marker","close","_open","Boolean","_close","resolveAll","events","context","group","text","openingSequence","closingSequence","use","nextEvents","offset","index","length","charCodeAt","end","start","Object","assign","movePoint","push","insideSpan","slice","splice","point","column","_bufferIndex"],"sourceRoot":""}